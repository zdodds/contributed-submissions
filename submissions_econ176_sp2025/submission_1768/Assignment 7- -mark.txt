# Linear Models and Neural Nets Lab (Econ 176 '25)

This lab will guide you through a _modeling_ task, inspired by the I&RE module:
+ it's based on a widely-studied French third-party-liability dataset [here on Kaggle](https://www.kaggle.com/datasets/floser/french-motor-claims-datasets-fremtpl2freq)
+ this variation has seven features and is available from [OpenML](https://openml.org/). (It's also widely studied: Cited below.)
+ of the seven features, six are used as predictive features and one is the target (to be predicted from the other six)
+ the target (to be predicted) is the _number of claims filed_ &nbsp; ``claim_nb`` by an individual. We'll call these _claims_ or _incidents_.
+ the features are
  + the ``year`` &nbsp;&nbsp; (there are only years 2018 and 2019)
  + whether the driver lives in a ``town`` <font size="-1">``town == 1.0``</font> or in a more rural area <font size="-1">``town == 0.0``</font>
  + the _driver's_ age (in years) &nbsp;&nbsp; ``driver_age``
  + the car's _weight_ (in kg) &nbsp;&nbsp; ``car_weight``
  + the car's engine _power_ (in hp) &nbsp;&nbsp; ``car_power``
  + the _car's_ age (in years) &nbsp;&nbsp; ``car_age``

<br>

You'll model the
The notebook will guide you through
+ loading the data and inspecting it, a bit
+ modeling the data with linear models (linear regression)## Loading and inspecting data   

&nbsp;&nbsp; <font color="Coral">there are two tasks here...</font>These two cells grab and extract the data - one millon rows and seven features - from OpenML:Here are the brief descriptions of each of the features:
+ the first six are the features we will use to _make_ predictions
  + the ``year`` &nbsp;&nbsp; (there are only years 2018 and 2019)
  + whether the driver lives in a ``town`` <font size="-1">``town == 1.0``</font> or in a more rural area <font size="-1">``town == 0.0``</font>
  + the _driver's_ age (in years) &nbsp;&nbsp; ``driver_age``
  + the car's _weight_ (in kg) &nbsp;&nbsp; ``car_weight``
  + the car's engine _power_ (in hp) &nbsp;&nbsp; ``car_power``
  + the _car's_ age (in years) &nbsp;&nbsp; ``car_age``
+ the seventh <b><tt>claim_nb</tt></b>, the number of claims files during that year, is the target to _be predicted_#### <font color="Coral"><b>Task 1</b></font>

With full encouragement to use the built-in Colab AI -- or another of your choice, create five specific visualizations and an additional one:
+ create a histogram of all the drivers' ages, and
+ a histogram of all the the cars' ages, and
+ a histogram of the claim numbers, `claim_nb`
+ create a scatter plot of how the car's age varies with the driver's age
+ create a scatter plot of how the `claim_nb` varies with the driver's age
+ <font color="Coral"><b>also</b></font>, create one more - different - scatter plot of your choice, using this data

<br>

<font color="DodgerBlue">Below for task 2, write a short reflection</font> on the results of these data-visualizations. One sentence on what you see in each is perfect.  <br> <font size="-1">(There's another cell below reminding you of this!)</font>#### <font color="Coral"><b>Task 2</b></font>

<font color="DodgerBlue">Here, write a short reflection</font> -- a sentence or two for each of these is wonderful -- that describes the data-trends you see in the visualizations above.

As a reminder, they were
+ histograms for the drivers' ages and the cars' ages and the claim numbers, `claim_nb`
+ a scatter plot of how the car's age varies with the driver's age
+ a scatter plot of how the `claim_nb` varies with the driver's age
+ <font color="Coral"><b>and</b></font>, one other - different - scatter plot that visualizes some of this data

<br>
<hr>
<br>

Feel free to use a new cell or the space below:


*   Drivers' age histogram: The highest number of drivers fall under 40, and the large majority of drivers are between the ages 30-50.
*   Cars' age histogram: The histogram is almost exponentially decaying, with the majority of cars being about a year old and decreasing exponentially.
*   Claim numbers histogram: The majority of people have not made a claim, with significantly less people making a claim.
*   Car age and driver age scatterplot: The correlation of car age and driver age is rather random, not showing any tendancy for an older car or newer car for older or younger drivers.
*  Claim number and driver age scatter plot: This scatter plot is not a perfet representation of the data as it is a random sample, but it seems to show that the majority of claims are under the age of 50.
*    Claim number and town: This scatter plot shows that overall, people in towns, not rural areas make more claims.







<br>
<br>
<br>
<br>## Modeling

You will build two models for the <b><tt>claim_nb</tt></b> target:
+ a **linear-regression** model &nbsp;&nbsp; <font size="-2">since the target is a "number of occurrences" over a span of time, we use a _Poisson_ model</font>
+ a **neural-network** model &nbsp;&nbsp;  <font size="-2">of the same sort</font>

You'll experiment with
+ interpreting the models
+ then, building some "deeper" neural networks
+ seeing how the two modeling approaches differ in the relationships they can express### Part 1: &nbsp;&nbsp; Data splitting

The dataset has a million rows.
+ For speed of training, we will use only 100,000 of them.
+ At the end, you'll try changing at least three model parameters. This is one of those options! ðŸ˜ƒ### Part 2: &nbsp; A (Generalized) Linear Model (GLM)

Here, we build a linear-regression model of the data.

We'll use [Glum](https://glum.readthedocs.io/en/latest/), a high-performance implementation in Python. <br> <font size="-2"><tt>glum</tt> stands for _generalized linear modeling" ... not sure about the <tt>u</tt></font>In Colab, you are likely to need to install `glum` once:
We can use that library to build a linear model:We did it!  &nbsp;&nbsp; But what _is_ it?!#### As an absolute model, this is <u>not</u> very useful!

**Everyone** has a very high likelihood of NOT having an auto incident/filing a claim. <i>This is good!</i>

This means _everyone's_ expected number of incidents is 0 &nbsp; (Well, very close to it.)#### In comparing the ***relative*** impact of a feature, the model <u>is</u> useful.

Here is a full description of the ***relative*** relationships expressed by those coefficients [(cite)](https://ademos.people.uic.edu/Chapter19.html#:~:text=Rather%20than%20odds%20ratios%20(which,variable%5D%20is%20%5Bcoefficient%5D.):


> <font color="DodgerBlue">The expected log count for each unit increase/decrease (depending on the sign of the coefficient) in [outcome variable] given [predictor variable] is [coefficient].</font>


Wow!  &nbsp;&nbsp; This needs some unpacking...

<hr>
<br>



<font size="+1" color="Blue">Interpreting</font> <font size="+1" > coefficients, part one: &nbsp;&nbsp; <tt><b>town</b></tt> example</font>


In practice, it's more straightforward than this suggests:

Suppose your coefficient for `town` is 0.36. &nbsp; <font size="-2">That was one of my test-run values.</font>

This means that "one unit" of `town` increases the <u>log of the claim count</u> by 0.36.  <br> <i><font color="Blue">But log-counts aren't very intuitive!</font></i> &nbsp; Let's _undo_ the log:


`exp(0.36)` is about `1.43` &nbsp;&nbsp;&nbsp; Let's see that this is true:
This means that "one unit" of `town` ***multiplies*** &nbsp; the frequency of incidents by 1.43

Since `town` only has values 0 and 1, this means that

**when `town` is 1, the likelihood of an incident is 1.43 times higher then when it's 0**

<br>

<font color="Coral"><b>Aha!</b></font>

<br>

This ***incident-rate ratio*** is really useful!
+ for assessing the threat of an event that is relatively rare and/or
+ the _value_ of small changes to an individual's particular situation.

In theory, the multiplier can be used many times:This means, if `town == 2`, the expected claims for those individuals would be 2.05x higher:
+ because, as above, `1.433 ** 2 == 1.433*1.433 == 2.05`

There _isn't_ such a value in the dataset...
+ ... but models will allow this kind of extrapolation. Be careful!
<font size="+1" color="Blue">Interpreting</font> <font size="+1"> coefficients, part two: &nbsp;&nbsp; <tt><b>driver_age</b></tt> example</font>

Let's try an example where there are multiple values, for example, for <b><tt>driver_age</tt></b> :
+ My coefficient for <tt><b>driver_age</b></tt> was <tt>-0.003272</tt>
+ And <tt>exp(-0.003272) == 0.9967</tt> &nbsp;&nbsp; <font size="-2">Let's confirm:</font>
This means that, for this model, the number of claims is multiplied by <tt>0.9967</tt> ***for each additional year of age***

<br>

What if an individual is fifteen years older?the model expects the number of claims to be 95% with that "additional experience"

<br>

What if we compare the oldest (88) and youngest (18) in the dataset:
Which states that our octogenerians will make 0.79 the claims as our 18-year-olds.

Taking the reciprocal, the model is saying that moving across the dataset's full age-span, from old to young, multiplies the number of claims by 1.25:
There is definitely room for skepticism here! ðŸ˜€

But we've successfully interpreted the model coefficients!   

Next, try two of your own:#### <font color="Coral"><b>Task 3</b></font> &nbsp; Two more model-interpretations:  

Following the approach of the two examples above, choose **two more** features from the coefficients and:  
+ compute the _per-unit_ incident-rate multiplier for that feature
+ decide on a "reasonable" number of units (years, kg, hp, ...)
+ compute the incident-rate multiplier for _that many units_
+ find the "full span" of units in the dataset (it's printed above ...)
+ compute the incident-rate multiplier for _that full span_
+ and reflect on what this is saying about the incidents in this data.

Specifically, share how well does these _match your intution_ about these factors for auto incidents/insurance claims? Reasonable? Skeptical? Other?

<br>
<hr>
<br>

Feel free to use this cell or new ones just below:

<br>
<br>For car power, measured in horse power, the per-unit multiplier is 1.004125486486792. For a car with 200 horsepower (what the internet considers normal...) the expected number of claims raises by 2.278232675354985. For the full span incident-rate multiplier, from high to low, multiplies the number of claims by 0.3017830189910322. This makes sense overall, the higher the horse power, we would expect an increase in claims, and as we move to the lower horsepower, there should be less claims.For car weight, measured in pounds, the per-unit multiplier is 0.9999320023119476. For a car that is 1300 pounds, the expected number of claims decreases by 0.9153946456237033. For the full span incident-rate multiplier, from high to low multiplies the number of claims by 1.1590028229130385. This makes sense overall, as the weight of the car decreases, it would make more sense if it might get a little more damaged making a claim necessary. However, it makes sense that this number is small as it really probaly shouldn't be a huge factor.
<br>
<hr>
<br>### Part 3. &nbsp; **Automatic** model-interpretation

A technique called SHAP, short for SHapley Additive exPlanation, is able to estimate the feature-by-feature effects of _any_ model.

It _should_ be here already:SHAP works by sampling the model at several points and then surveying the space around those points to see how the model is changing. It integrates all of this information in order to be able to compare the influence of all of the variables with the same units, known as SHAP values. They are again relative values, and they indicate how the target varies with changes to each feature -- in light of _all_ the features in the model.

Linear models like the one above are already interpretable. However, other models - like neural nets - are much less so.

To get started, let's run SHAP for our linear model:Let's see one of the explained individuals:and, let's see their SHAP values:Ok!

These numbers are (the sign and) relative weight of each of this individual's **per-feature contributions** to their risk (their expected number of claims).

For example, in this model,
+ their age makes a claim less likely
+ their car's age make a claim more likely

Plus, the <tt><b>SHAPvalue</b></tt> units are commensurate:
+ the impact of the driver's age carries almost three times the weight of their car's age

<br>

Better to plot all of them. &nbsp; Let's do that next:#### <font color="Coral"><b>Task 4</b></font> &nbsp; How did SHAP do?

In Task 3, you chose two features and examined their effects on the target value, the number of incidents.

Here, revisit those two features, and in a couple of sentences, describe whether the effects you measured match the plots above.

<br>

**Note/Hints**  There are lots of dimensions here! And lots of information! The x-axis of each plot shows the feature values. The y-axis is the SHAP value (the relative impact on the number of claims).

The red/blue coloring of datapoints shows how the _most influential **other** feature_ overlays onto the current plot. That **other** feature is the most influential for the one labeled on the x-axis, and so it will often be different for different plots.  

<br>

As an example of this feature-comparison, remember that one <tt><b>town</b></tt> unit multiplied the claims by 1.4, and the full span of <tt><b>driver_age</b></tt> multiplied the claims by 1.25.

This matches well!  In the above plot, the span for <tt><b>town</b></tt> is a little bit larger than the span for <tt><b>driver_age</b></tt>.

The SHAP units are not the same, and SHAP takes into account more than linear dependencies, but it has captured the sign and the magnitude of the model it was interpreting.
  

<br>
<hr>
<br>

For your two reflections, feel free to use this cell or new ones just below this one:

<br>
<br>Looking at car weight and car power, we can see that the span for car power is much larger than car weight. We knew this would be the case because we observed that units of horse power made a much more significant increase in change as opposed to how much units of pounds changed. This aligns with what the model was interpreting.

### Part 4: &nbsp;&nbsp; A Neural Network model

Here, we TensorFlow to fit a "shallow" neural net.

Your task is to improve the results -- by adding more layers and retraining...

Plus, the resulting layered network will be able to extract nonlinear relationships among the features <br> <font size="-1">(in exchange for much more training time...)</font>Neurons work best when all their data is ***roughly the same magnitude***

Our brains handle this at the sensor level -- our hearing and vision systems continually try to re-establish the ambient baseline to help convert their inputs into computable magnitudes:
+ light sensitivity increases in the dark and decreases in bright light
+ for sound, loud repetitive even soft sounds are heightened when in a quiet place.

<br>

For neural nets, we can scale each feature to be between -1 and 1:Above, you see the artictecture of the network.

This includes the total number of neuron-connections (parameters) to train.

Let's train!And, let's see how the model does... using `shap`#### Next, let's add a "hidden" layer to our network...

Here, we add a middle, "hidden," layer to our network in line 14, below. Notice that
+ the value 7 is the number of neurons
+ the inputs from the initial layer are, in fact, the inputs to this middle layer
+ the variable z holds the outputs of this layer.
+ the output layer uses z as its input (and then estimates the goal, the number of claims from there)

Additional layers are able to continue this pattern (one example is commented out on line 17):Let's see the neurons!

At least as a heatmap of the weights:Next layer!Let's run `shap` to see if it does better...Notice that these features do not _yet_ match the ones computed by the linear regression model we interpreted above.

Thus far, the NNet is too primitive to be able to learn the real relationships among those dataset features.

<font color="Coral">Your task</font> is to experiment below, in order to create a larger, more faithful NNet model.### The "Real" data model

Usually datasets do not have a "real" model. At least not one that's known!

This dataset, however, does have a _real_ underlying model! (It was inspired by the real data and then used to generate this dataset.)

Here is the real model:`shap` is not specific to NNets or linear regression models. It supports the interpretation of _any_ model, including the real one.

Here is `shap`'s interpretation of this real model:Things to notice:
+ the relationship between driver_age and the number of claims is "highly non-linear!"
+ there are also _two slopes_ for the linear car_power feature (so, officially, it's "not linear")
+ note, too, that car_weight has no impact on the output...
  + Challenge question (not really a hw task): <br>  _**Why** do the modeling techniques above observe an impact of the car_weight feature?_## Final challenge: <font color="DodgerBlue">_Improve the NNet_</font>

#### <font color="Coral"><b>Task Finale</b></font>

From here, your task is to
+ create a more-capable neural network... with the goal of representing the actual data interactions ***better*** than the linear-regression model
+ consider using more layers (but not too many)
+ consider the "step-down" architecture, where
  + the first post-input layer has the most neurons ("feature building")
  + then, subsequent layers have fewer...
  + tapering into the output layer

You'll find that the NNet won't represent the "real" model perfectly, but it will
+ find its own features
+ represent the non-linear relationship (for driver_age)
+ and, for me, it could _start_ to represent the dependence of car_power on town

<br>

### Use the cells below to experiment with NNet building...

Use the above `2layer` example as a template, and then - below -
+ experiment and create a new model -- and
+ show its `shap` interpretation... -- and
+ be sure to include a <font color="DodgerBlue">3-5 sentence <b>reflection</b> on</font> your experimentation (how long it took!) and how well the resulting NNet does at capturing the feature relationships of the actual, underlying "reality" ...

<br>

Worth remembering:  _We're **all** neural nets!_
+ It would seem we're always "keeping this in mind" ðŸ˜€