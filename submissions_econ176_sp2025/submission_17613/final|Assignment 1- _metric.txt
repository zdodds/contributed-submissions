# we assign the url and obtain the api-call result into result
#    note that result will be an object that contains many fields (not a simple string)
#

import requests

url = "http://api.open-notify.org/iss-now.json"   # this is sometimes called an "endpoint" ...
result = requests.get(url)

# if it succeeds, you should see <response [200]>


#
# in this case, we know the result is a json file, and we can obtain it that way:

json_contents = result.json()      # needs to convert the text to a json dictionary...
print(f"json_contents is {json_contents}")     # aha!  let's re/introduce f-strings...

# take a look... remember that a json object is a python dictionary:


#
# let's remind ourselves how dictionaries work:

lat = json_contents['iss_position']['latitude']
lat = float(lat)
print("lat: ", lat)


#
# let's make sure we "unpack the process" w/o ai
#
from math import *

lat = json_contents['iss_position']['latitude']
lat = float(lat)

long = json_contents['iss_position']['longitude']
long = float(long)

def haversine(lat1, long1, lat2, long2):
    """
    calculate the great circle distance in kilometers between two points
    on the earth (specified in decimal degrees)
    """
    # convert decimal degrees to radians
    long1, lat1, long2, lat2 = map(radians, [long1, lat1, long2, lat2])

    # haversine formula
    dlong = long2 - long1
    dlat = lat2 - lat1
    trig = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlong/2)**2
    # radius of earth. use 3956 for miles. 6371 for km.
    radius = 3956  # we'll use miles!
    return radius * 2 * asin(sqrt(trig))

print(haversine(lat, long, 34.1007, -117.7065))


#
# then, let's compare with ai's result...
#

from geopy.distance import geodesic

def calculate_distance(coord1, coord2):
    """
    calculates the geodesic distance between two latitude/longitude pairs.

    parameters:
    coord1 (tuple): a tuple containing (latitude, longitude) of the first location.
    coord2 (tuple): a tuple containing (latitude, longitude) of the second location.

    returns:
    float: distance in kilometers between the two points.
    """
    return geodesic(coord1, coord2).kilometers

lat = json_contents['iss_position']['latitude']
lat = float(lat)

long = json_contents['iss_position']['longitude']
long = float(long)

coord1 = (lat, long)
coord2 = (34.1007, -117.7065)
print(calculate_distance(coord1, coord2))


#
# we assign the url and use requests.get to obtain the result into result_astro
#
#    remember, result_astro will be an object that contains many fields (not a simple string)
#

import requests

url = "http://api.open-notify.org/astros.json"   # this is sometimes called an "endpoint" ...
result_astro = requests.get(url)
result_astro

# if it succeeded, you should see <response [200]>


# if the request succeeded, we know the result is a json file, and we can obtain it that way.
# let's call our dictionary something more specific:

astronauts = result_astro.json()
d = astronauts   # a shorter variable for convenience..


# remember:  astronauts will be a _dictionary_
note = """ here's yesterday evening's result - it _should_ be the same this morning!

{"people": [{"craft": "iss", "name": "oleg kononenko"}, {"craft": "iss", "name": "nikolai chub"},
{"craft": "iss", "name": "tracy caldwell dyson"}, {"craft": "iss", "name": "matthew dominick"},
{"craft": "iss", "name": "michael barratt"}, {"craft": "iss", "name": "jeanette epps"},
{"craft": "iss", "name": "alexander grebenkin"}, {"craft": "iss", "name": "butch wilmore"},
{"craft": "iss", "name": "sunita williams"}, {"craft": "tiangong", "name": "econ176_participant_6 guangsu"},
{"craft": "tiangong", "name": "econ176_participant_6 cong"}, {"craft": "tiangong", "name": "ye guangfu"}], "number": 12, "message": "success"}
"""
print(d)


d['people']


#
# try it - from a browser or from here...

import requests

url = "https://fvcjsw-5000.csb.app/econ176_mystery0?x=1&y=3"    # perhaps try from browser first!
result_ft = requests.get(url)
print(result_ft)              # prints the status_code

d = result_ft.json()            # here are the _contents_



#
# a larger api call to the same codesandbox server

import requests

url = "https://fvcjsw-5000.csb.app/fintech"    # try this from your browser first!
result_ft = requests.get(url)
result_ft


#
# let's view ... then parse and interpret!

# d = result_ft.json()                  # try .text, as well...
# print(f"the resulting data is {d}")

d = {'number': 176, 'initials': ['ac', 'al', 'an', 'ap', 'az', 'cl', 'cm', 'cw', 'cz', 'ds', 'ec', 'ed', 'eg', 'es', 'hv', 'ic', 'ig', 'jb', 'jn', 'jt', 'kr', 'la', 'lg', 'ls', 'lw', 'md', 'nd', 'nm', 'nv', 'nw', 'ob', 'rk', 'rl', 'rp', 'sb', 'sc', 'sd', 'sf', 'ss', 'tc', 'ts', 'vn', 'vvp', 'ym', 'zd', 'zy'], 'departments': ['econ', 'cs']}



#
# see if you can extract only your initials from d

print(d['initials'][5])

# we're not finished yet! :)


#
# let's request!   just using the demo, for now:

import requests

url = "https://www.alphavantage.co/query?function=time_series_daily&symbol=msft&apikey=demo"    # demo version
result = requests.get(url)



#
# let's view ... then parse and interpret!

d = result.json()
print(d)


#
# let's look at all of the keys...

for k in d['time series (daily)']:
    print(k)

# aha! they are dates... let's create a function to compare two dates


#
# here is one way to make a list of all of the dates:

dates = list(d['time series (daily)'].keys())

# notice, they're backwards!


#
# let's flip the dates around:
dates.reverse()

# yay!


# oooh... now let's see what's in each key (date)

val = float(d['time series (daily)']['2025-01-21']['4. close'])  # aha! it's a dictionary again!  we will need to index again!!



# a small function to get the closing price on a date (date) using data (dictionary) d
def get_closing(date, d):
    close = float(d['time series (daily)'][date]['4. close'])
    return close


# a loop to find the minimum closing price
#

min_price = 10000000
min_key = "nothing"

for date in d['time series (daily)']:
    closing =  get_closing(date, d)
    # print(f"date is {date} and closing is {closing}")
    if closing < min_price:
        min_price = closing
        min_price_date = date

print(f"min_price_date is {min_price_date} and {min_price = }")


import requests
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import pandas as pd


# api is working

# url with my api key
# doing analysis on disney stock
url = "https://www.alphavantage.co/query?function=time_series_daily&symbol=dis&outputsize=compact&apikey=1umwvtkbkegljkqn"

result = requests.get(url)



# get data

d = result.json()
# print(d)

# compact data with last 100 days

# print(len(d["time series (daily)"]))

# extract 100 closing prices and create a list with them

closing_prices = []

sorted_dates = sorted(d["time series (daily)"].keys())

dates = [pd.to_datetime(date) for date in sorted_dates]

for date in sorted_dates:
    closing_prices.append(float(d["time series (daily)"][date]["4. close"]))

print(closing_prices)

# find the maximum and minimum closing prices

max_price = max(closing_prices)
date_max = sorted_dates[closing_prices.index(max_price)]
min_price = min(closing_prices)
date_min = sorted_dates[closing_prices.index(min_price)]

print((max_price, date_max), (min_price, date_min))


# plot closing prices against dates

plt.plot(dates, closing_prices)

plt.gca().xaxis.set_major_locator(mdates.weekdaylocator())
plt.gca().xaxis.set_major_formatter(mdates.dateformatter('%b %d, %y'))
plt.xticks(rotation=90)

plt.xlabel('date(weekly)')
plt.ylabel('closing price(usd)')
plt.title('disney closing prices in the last 100 days')

# highlight max and min
plt.scatter(pd.to_datetime(date_max), max_price, color='green', label=f'max: {max_price}')
plt.scatter(pd.to_datetime(date_min), min_price, color='red', label=f'min: {min_price}')

plt.text(pd.to_datetime(date_max), max_price, f"  max: {max_price}", color='green', verticalalignment='bottom')
plt.text(pd.to_datetime(date_min), min_price, f"  min: {min_price}", color='red', verticalalignment='top')


plt.show()


# single share analysis

max_profit = 0
best_profit = ()

for i in range(len(closing_prices)):
  for j in range(i+1, len(closing_prices)):
    if (closing_prices[j] - closing_prices[i]) > max_profit:
      max_profit = (closing_prices[j] - closing_prices[i])
      best_profit = (closing_prices[i], closing_prices[j])

buy_date = sorted_dates[closing_prices.index(best_profit[0])]
sell_date = sorted_dates[closing_prices.index(best_profit[1])]
print("buy on " + buy_date + " for $" + str(best_profit[0]) + ", and sell on " + sell_date + " for $" + str(best_profit[1]) + ".")
profit = round(best_profit[1]-best_profit[0], 2)
print("you will make $" + str(profit) + ".")


# regraph based on calculated results

plt.plot(dates, closing_prices)

plt.gca().xaxis.set_major_locator(mdates.weekdaylocator())
plt.gca().xaxis.set_major_formatter(mdates.dateformatter('%b %d, %y'))
plt.xticks(rotation=90)

plt.xlabel('date(weekly)')
plt.ylabel('closing price(usd)')
plt.title('disney closing prices in the last 100 days')

plt.scatter(pd.to_datetime(sell_date), best_profit[1], color='green', label=f'sell: {best_profit[1]}')
plt.scatter(pd.to_datetime(buy_date), best_profit[0], color='red', label=f'buy: {best_profit[0]}')

plt.text(pd.to_datetime(sell_date), best_profit[1], f'  sell: {best_profit[1]}', color='green', verticalalignment='bottom')
plt.text(pd.to_datetime(buy_date), best_profit[0], f'  buy: {best_profit[0]}', color='red', verticalalignment='top')

plt.show()


# function that takes in stock symbol and finds best times to buy and sell


def highest_stock_profit(stock_symbol):
  url = "https://www.alphavantage.co/query?function=time_series_daily&symbol=" + stock_symbol + "&outputsize=compact&apikey=1umwvtkbkegljkqn"

  result = requests.get(url)
  d = result.json()

  closing_prices = []

  sorted_dates = sorted(d["time series (daily)"].keys())

  dates = [pd.to_datetime(date) for date in sorted_dates]

  for date in sorted_dates:
      closing_prices.append(float(d["time series (daily)"][date]["4. close"]))

  # single share analysis

  max_profit = 0
  best_profit = ()

  for i in range(len(closing_prices)):
    for j in range(i+1, len(closing_prices)):
      if (closing_prices[j] - closing_prices[i]) > max_profit:
        max_profit = (closing_prices[j] - closing_prices[i])
        best_profit = (closing_prices[i], closing_prices[j])

  buy_date = sorted_dates[closing_prices.index(best_profit[0])]
  sell_date = sorted_dates[closing_prices.index(best_profit[1])]
  print("buy on " + buy_date + " for $" + str(best_profit[0]) + ", and sell on " + sell_date + " for $" + str(best_profit[1]) + ".")
  profit = round(best_profit[1]-best_profit[0], 2)
  print("you will make $" + str(profit) + ".")

  # graph based on calculated results

  plt.plot(dates, closing_prices)

  plt.gca().xaxis.set_major_locator(mdates.weekdaylocator())
  plt.gca().xaxis.set_major_formatter(mdates.dateformatter('%b %d, %y'))
  plt.xticks(rotation=90)

  plt.xlabel('date(weekly)')
  plt.ylabel('closing price(usd)')
  plt.title(stock_symbol + ' closing prices in the last 100 days')

  plt.scatter(pd.to_datetime(sell_date), best_profit[1], color='green', label=f'sell: {best_profit[1]}')
  plt.scatter(pd.to_datetime(buy_date), best_profit[0], color='red', label=f'buy: {best_profit[0]}')

  plt.text(pd.to_datetime(sell_date), best_profit[1], f'  sell: {best_profit[1]}', color='green', verticalalignment='bottom')
  plt.text(pd.to_datetime(buy_date), best_profit[0], f'  buy: {best_profit[0]}', color='red', verticalalignment='top')

  plt.show()

highest_stock_profit("mnst")


import requests
from datetime import datetime


# getting data on the global price of sugar

url = "https://www.alphavantage.co/query?function=sugar&symbol=dis&apikey=1umwvtkbkegljkqn"
result = requests.get(url)
d = result.json()

# find the average price of sugar each year for the past 10 years

# filter data for last 10 years

current_year = datetime.now().year

sugar_prices = []

for i in d["data"]:
    year = int(i["date"][:4])
    if current_year - year < 11:
        sugar_prices.append(i)

# calculate yearly averages

def average(year):
  adding = 0
  for entry in sugar_prices:
    if int(entry["date"][0:4]) == year:
      adding += float(entry["value"])

  return round(adding/12, 2)

years = [2024, 2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016, 2015]

averages_list = []

for year in years:
  averages_list.append((year, average(year)))

print(averages_list)


import pandas as pd
from darts import timeseries
import requests
from darts.metrics import rmse


# used the monthly stock series instead of daily to match sugar
stock_url = "https://www.alphavantage.co/query?function=time_series_monthly&symbol=dis&apikey=1umwvtkbkegljkqn"
sugar_url = "https://www.alphavantage.co/query?function=sugar&symbol=dis&apikey=1umwvtkbkegljkqn"
stock_result = requests.get(stock_url)
sugar_result = requests.get(sugar_url)

stock_data = stock_result.json()
sugar_data = sugar_result.json()


# find stock averages

def stock_average(year, dataset):
    adding = 0
    for date, values in dataset["monthly time series"].items():
        if int(date[:4]) == year:
            adding += float(values["4. close"])
    return round(adding / 12, 2)

years = [2024, 2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016, 2015]

stock_averages_list = [(stock_average(year, stock_data)) for year in years]

# finding sugar averages

sugar_averages_list = []

for year in years:
  sugar_averages_list.append((average(year)))

date_index = pd.date_range(start=f"{years[-1]}-01-01", periods=len(years), freq="ye")

stock_series = timeseries.from_times_and_values(date_index, stock_averages_list)
sugar_series = timeseries.from_times_and_values(date_index, sugar_averages_list)


root_mean_squared_error = rmse(stock_series, sugar_series)
print(round(root_mean_squared_error, 2))



# disney stock vs monster stock

mnst_stock_url = "https://www.alphavantage.co/query?function=time_series_monthly&symbol=mnst&apikey=1umwvtkbkegljkqn"

mnst_result = requests.get(mnst_stock_url)

mnst_data = mnst_result.json()

mnst_averages_list = [(stock_average(year, mnst_data)) for year in years]

mnst_series = timeseries.from_times_and_values(date_index, mnst_averages_list)

stock_rmse = rmse(stock_series, mnst_series)
print(round(stock_rmse, 2))


