## Here's our _one-cell_ version of the ML workflow <font color="Coral"><b>let's start here</b></font> &nbsp;&nbsp; <font size="-2">"amoeba version," maybe</font>

This is for iris classification.

You'll need to upload the ``iris_cleaned.csv`` file to this notebook's folder icon, at left.### Iris classification via Nearest Neighbors

+ Section 1: Libraries
+ Section 2: Read the already-cleaned data  (+ view, if you wish)
+ Section 3:  Drop any columns we don't want to use
+ Section 4:  create COLUMNS and SPECIES variables to show we're organized + know what's happening...
+ Section 5:  convert from pandas (spreadsheet) to numpy (array)
+ Section 6:  define our features (X_all) and our target-to-predict (y_all)
+ Section 7:  80/20 split into training and testing sets:  X_train and y_train, X_test and y_test
+ Section 8:  Here's where the model-building happens!  First, we guess at the parameters (k=84)
+ Section 9:  Let's see how our model does on the TEST data...
+ Section 10:  Let's cross-validate to find the "best" value of k, best_k### Optional:  Let's format things more carefully...### <b><font color="DodgerBlue">Optional</font></b>:  Use the predictive model!

We can use the predictive model to make predictions and try it out!### This feels like an excuse to plot with seaborn...### Let's use the "correct value" of k

It will not always be the same, because cross-validation is randomized...### We've made a (better!) model

Let's see how it does...### To make a FINAL predictive model, we use <b>all</b> the data -- with the <u>tuned</u> parameter <tt>k</tt>

That is, we
+ use the best value of <tt>k</tt>, as computed above by cross-validation
+ then, we train on _all_ of the data!

Notice that this next cell uses X_all and y_all:### We're ready to deploy our "final + best" predictive model!### Predictive models aren't perfect!
+ Notice that the last prediction above the [0,0,0,0] is (probably) wrong
  + It probably predicted _versicolor_, but it was actually a _virginica_
  + In essence, it was a _virginica_ iris that "looked more like" a _versicolor_ ... ***from these four features!***
  + A botanist would use more than these four features to classify difference species...

+ **Key**: Even when the modeling process runs "perfectly," the models are likely to be imperfect...
+ ... it's just that we won't know where the imperfections are -- until future observations arrive!### That's it! Our model is complete...

... not perfect, but **complete**

What does this mean?

It means that the model -- the function (above) -- is ***already*** prepared to provide an output for every possible input!

We can see this in a plot of the outputs for every input in the "sepal" plane (length vs. width) as well as the "petal" plane:**# Homework 7: Births**

<br>

**Mohammed IST341_Participant_4 & IST341_Participant_2**

<br># Reading for hw7...   
This week's reading is a 2020 Economist article (pdf) on the pitfalls and promise of the data-driven era of AI we now inhabit. The article takes a "data-based" view on recent developments and concerns in AI, especially machine-learning (or "statistical learning"). original

One of the newest ideas in this article is the possibility -- and possible importance -- of generating data to improve model-training, when available data is inequitable, inflexible, or insufficient in another way.

Using the article and your own experience, what are your thoughts on artificially generating data to assist AI/ML training? Possible jumping-off points include

(1) echo-chamber effects: can generated data yield more fairness -- or only reinforce existing biases?, or
(2) implementation concerns: what process would artificially generate the data?, or
(3) a specific example you've encountered, where a computational system generated data, but "got things obviously wrong" (there may be lots of these examples!)
In this last case, the generated data made the world's "data-landscape" worse, not better. Alternative directions on artificially-generated data more than welcome!

As with each week's reading, responses should be thoughtful, but need not be long: a 4-5 sentence paragraph is wonderful.Reading response

<br>

Creating artificial (or synthetic) data to train AI models can be very helpful, especially when real-world data is limited, biased, or hard to get. As the Economist article explains, companies like Amazon used synthetic data to improve their systems when real data wasn’t enough. However, there are risks. If the synthetic data is based on biased real-world examples, it may repeat or even increase those biases. I’ve seen this in health AI systems, where models trained on data from mostly one group don’t work well for others. A similar issue can happen in education, for example, an AI tutor trained mostly on data from English-speaking students might not respond well to students who speak other languages or have different learning styles. So, while artificial data can support fairness and protect privacy, it must be created carefully to reflect real-world diversity and avoid reinforcing existing problems.


<br>


<br>
<hr>
<br>