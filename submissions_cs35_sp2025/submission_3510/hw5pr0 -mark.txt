<br>

### cs35 Week5: Reading and response 

_More data!_   &nbsp;&nbsp; (hw5pr0.ipynb)

In fact, can we _generate_ our own?!

<hr><br>

#### Reading for hw5...     (hw5pr0.ipynb)

This week's reading is an [Economist article](https://www.economist.com/technology-quarterly/2020/06/11/for-ai-data-are-harder-to-come-by-than-you-think) (here is a [pdf version](https://drive.google.com/file/d/1tJC3jLjk_ZNzA1UTxREJGqzZg5pg2N24/view)) on the pitfalls and promise of the data-driven era we now inhabit.  

The article takes a "data-based" view on the developments and concerns in AI. It's from about 5 years ago, and you'll notice that this is a _long_ time ago, AI-wise!

One of the more durable ideas in this article is the possibility -- and possible importance -- of ***generating*** data to improve model-training, when available data is inequitable, inflexible, or insufficient in another way. (Amazon Go, on the other hand? [Gone.](https://foodinstitute.com/focus/rise-and-stall-of-amazon-go-illustrates-limits-of-ai/))   

Using the article and your own experience, what are <font color="Coral"><b>your thoughts on artificially generating data to assist AI/ML training</b></font>?  Possible jumping-off points include 
+ (1) echo-chamber effects: &nbsp; Can generated data yield more fairness -- or only reinforce existing biases?, or 
+ (2) implementation concerns: &nbsp; What process would artificially generate the data?, or 
+ (3) a specific example you've encountered, &nbsp; where a computational system generated data, but "got things obviously wrong" (you may have experiences several of these examples!) 

In the last case, the automatically-generated data may have made the world's data-landscape worse, not better.  

Alternative and additional perspectives about artificially-generated data are more than welcome... &nbsp; .

As with each week's reading, responses should be thoughtful, but need not be CS35_Participant_2: a 4-5 sentence paragraph is wonderful.

<hr>#### Reading response

(Feel free to use this cell for your response.)I don't think that using artificially generating data to assist AI/ML training is the best way, but at this stage, it's hard to gather our desired data from people's daily lives, so artificially generated data is a more suitable way for us to assist AI/ML training at this point.
I think it's hard to ensure the fairness of the data generated. For instance, the example of AI does better in identifying white faces than black faces in the article shows that even in the real life, the training data can create bias. If people generate data, they need to concern multiple aspects of the data, and maybe it would be better to invite people from diverse backgrounds to participate in the data generation.
Since I have no knowledge in the process of generating data artificially, I guess people may either let AI's generating such datas or recruiting volunteers and collect the datas from the volunteers.But both process can create bias. First, AI itself is a black box, so there may be too many uncertainties to train an AI using AI generated datas. Recruiting volunteers may reduce the uncertainties, but the recruters need to consider carfully about the targeted volunteers to avoid bias.
One "not-so-suitable" example for me might be generated pictures with different types of characters using ChatGPT. If you let ChatGPT generating a picture with english words inside, it may generate english words with letters readable, but if you let ChatGPT generating a picture with east Asian languages like Chinese and Japanese, then all these characters are unreadable. Maybe this reflects that the training data for ChatGPT are mostly in english, and ChatGPT needs to encorporate more training datas from other languages, or this happens simply because it's harder to capture the characteristics in east Asian languages to generate correct characters and words.