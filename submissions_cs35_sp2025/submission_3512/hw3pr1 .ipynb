{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3:  Web-as-Output!\n",
    "\n",
    "Last week was dedicated to _consuming_ (or, perhaps, _gathering_) content **from** the web.\n",
    "\n",
    "This week and this notebook invites you into the world of _producing_ content for the web. The nice thing is\n",
    "  + the actual _producing_ happens in a scripting language\n",
    "  + and then the _formatting_ for the web can be done automatically\n",
    "  + whew!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font style=\"color:rgb(180,120,10);\"><b>hw3pr1, parts (a) and (b)</b>:  &nbsp; \"real\" webscraping...</font>\n",
    "\n",
    "This problem bridges input from the web with output to the web. Last week's use of APIs found and interpreted **structured** data, mostly JSON.  (For pre-defined APIs, JSON is what's used, most of the time!)\n",
    "\n",
    "What if a site has information you'd like to use, but only has HTML, but not JSON? In this case, <tt>requests</tt> will provide the raw HTML (as a string) and it'll be up to us to extract the information we want! We'll use \n",
    "  + Python string-handling and <tt>string</tt> libraries, and\n",
    "  + Python's _regular expression_ <tt>re</tt> library, a mini-language for string-matching and -manipulating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, an example.  We want to programmatically access the _best snacks_ on the <u>definitive snacks page</u>, which is [here at this url](https://www.cs.hmc.edu/~dodds/demo.html)\n",
    "\n",
    "Alas, this snack-centric web service seems not to have a JSON API! We will have to grab the whole HTML text. HTML is always sent over as a huge string..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.cs.hmc.edu/~dodds/demo.html\"\n",
    "result = requests.get(url)\n",
    "print(f\"{result = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "  <head>\n",
      "    <title>My streamlined website</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1> Welcome! </h1>\n",
      "    <h2> The best numbers </h2>\n",
      "\n",
      "    <div id=\"numberlist\">\n",
      "      <ol>\n",
      "\t<li class=\"number\"> 35 </li>\n",
      "\t<li class=\"number\"> 42 </li>\n",
      "\t<li class=\"number\"> <a href=\"https://en.wikipedia.org/wiki/Rayo%27s_number\">Rayo's number</a> </li>\n",
      "      </ol>\n",
      "    </div>\n",
      "\n",
      "    <img src=\"./spam.jpg\" height=\"84px\">\n",
      "    <br><br>\n",
      "\n",
      "    <h2> The <s>only</s> best snacks </h2>\n",
      "\n",
      "    <div id=\"snacklist\">\n",
      "      <ul>\n",
      "\t<li class=\"snack\"> Poptarts </li>\n",
      "\t<li class=\"snack\"> Chocolate </li>\n",
      "\t<li class=\"snack\"> Coffee </li>\n",
      "      </ul>\n",
      "    </div>\n",
      "\n",
      "<!--    <a href=\"./demo_cat.html\">Aliens <3 cats!</a>  -->\n",
      "\n",
      "    <img src=\"./alien.png\" height=\"101px\">\n",
      "\n",
      "  </body>\n",
      "</html>\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's print the text we just grabbed:\n",
    "snack_page = result.text\n",
    "print(snack_page)\n",
    "\n",
    "text = snack_page         # ok to have many names..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font style=\"color:rgb(180,120,10);\"><b>hw3pr1a</b>:  &nbsp; snack-scraping, _an example to run_ </font>\n",
    "\n",
    "For this part, follow the cells below to scrape all of the snacks from the above string.\n",
    "\n",
    "Notice that all of the snacks have a _common context_ - namely, the HTML ``<li>`` and ``</li>`` tags in which they're embedded. In addition, they are all of _class_ ``\"snack\"``\n",
    "\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooh... we notice that all of the snacks are inside ``li`` tags:\n",
    "+ These are _list items_ within an _unordered list_ \n",
    "+ Here is an example of one: ``<li class=\"snack\"> Poptarts </li>``\n",
    "+ Notice, too, that the ``class`` in each case is ``\"snack\"``\n",
    "\n",
    "There are three ways to grab all of these snacks!\n",
    "1. We can use the ``.find`` method all strings have! (We'll do this.)\n",
    "1. We can use regular expressions. See part (c)!\n",
    "1. We can use a library such as [BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/)  [[Good choice for a **final** project, if you'd like...]]\n",
    "\n",
    "For now, let's show how ``.find`` can work:\n",
    "\n",
    "First, let's see/remember what the <tt>find</tt> method does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#    0         1         2             # ten's place\n",
    "#    0123456789012345678901234567      # one's place\n",
    "s = \"abcdefghijklmnopqrstuvwxy&jk\"\n",
    "s.find(\"a\", 10)                            # try 'a', 'j', 'hi', 'hit', and 'z' ! jk!\n",
    "\n",
    "                                       # s.find(\"a\",15)   # try (\"j\",15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! Now we can create a plan...\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "Let's \n",
    "  + find each instance of ``<li class=\"snack\">``\n",
    "  + print their indices and\n",
    "  + print the string between them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snack_slice = '<li class=\"snack\"> Poptarts </li>\\n\\t<li cla'\n",
      "snack_slice = '<li class=\"snack\"> Coffee </li>\\n      </ul'\n",
      "\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "end = 0\n",
    "\n",
    "while True:\n",
    "    start = snack_page.find('<li class=\"snack\">', end)\n",
    "    if start == -1: break     # stop if we're done!\n",
    "    end = start +42          # 42 characters!\n",
    "    \n",
    "    snack_slice = snack_page[ start:end ]\n",
    "    print(f\"{snack_slice = }\")\n",
    "\n",
    "print(\"\\nComplete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aargh!  We only got two snacks. &nbsp; ***Do you see why?***\n",
    "\n",
    "It's because we started the next ``find`` 42 characters after the first one, at ``end``, and it <u>ate into</u> the next snack. <br> So, it could only find the first and third snacks.\n",
    "\n",
    "<br>\n",
    "\n",
    "Let's repeat the process, more carefully\n",
    "  + We should find the following ``</li>``\n",
    "  + and then continue from there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snack_slice = '<li class=\"snack\"> Poptarts </li>'\n",
      "snack_slice = '<li class=\"snack\"> Chocolate </li>'\n",
      "snack_slice = '<li class=\"snack\"> Coffee </li>'\n",
      "\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "end = 0\n",
    "\n",
    "while True:\n",
    "    start = snack_page.find('<li class=\"snack\">', end)\n",
    "    if start == -1: break     # stop if we're done!\n",
    "    end = snack_page.find('</li>', start)  # find the correct ending!\n",
    "    \n",
    "    snack_slice = snack_page[ start:end+5 ]\n",
    "    print(f\"{snack_slice = }\")\n",
    "\n",
    "print(\"\\nComplete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We have our snacks!</b>\n",
    "\n",
    "Let's show how to get ***only*** the snacks, not the HTML and CSS...\n",
    "\n",
    "What's needed is the offset to the front of the snack, here in the variable ``FRONT``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snack_slice = ' Poptarts '\n",
      "snack_slice = ' Chocolate '\n",
      "snack_slice = ' Coffee '\n",
      "\n",
      "Yay!!!\n"
     ]
    }
   ],
   "source": [
    "# we need the length of the search string!\n",
    "FRONT = len('<li class=\"snack\">')\n",
    "\n",
    "end = 0\n",
    "\n",
    "while True:\n",
    "    start = snack_page.find('<li class=\"snack\">', end)\n",
    "    if start == -1: break     # stop if we're done!\n",
    "    end = snack_page.find('</li>', start)  # find the correct ending!\n",
    "    \n",
    "    snack_slice = snack_page[ start+FRONT:end ]\n",
    "    print(f\"{snack_slice = }\")\n",
    "\n",
    "print(\"\\nYay!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping Success!  \n",
    "\n",
    "We have \n",
    "+ scraped a superior snack page that, alas, did not have a JSON API...\n",
    "+ written a special-purpose script that extracted the superior snacks from the page\n",
    "+ and shown that we have them (by printing them, but we could put them in a ~~fridge~~ list for future snack-use!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font style=\"color:rgb(180,120,10);\"><b>hw3pr1b</b>:  &nbsp; Scrape another page and extract specific data - your choice -  from it ... </font>\n",
    "\n",
    "For this part, find another page - as large and complicated as you'd like - and scrape one or more pieces of information -- your choice -- from it...\n",
    "  + Be sure that your information-extraction involves some use of the function <tt>find</tt>  \n",
    "  + _or_ some use of the ``re`` regular expression library, which is introduced and used below.\n",
    "  + The other details are up to you...\n",
    "\n",
    "Ideas? Possibilities include\n",
    "+ Any page that allows you to scrape it will work -- in the past, students have used The Student Life, and then compared which college is mentioned the most...\n",
    "+ or the NYTimes, and see which of two cities/states/nation is mentioned the most\n",
    "+ Perhaps one or two Wikipedia page(s), or a landing page for an organization...\n",
    "+ With patience, you _can_ use ``find`` and/or ``re`` to extract arbitrary information... and this is a powerful foundation \n",
    "  + worth bragging about... 🍰 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food = 'Bacon and cabbage'\n",
      "food = 'Chocolate milk'\n",
      "food = 'Duck à l&#39;orange'\n",
      "food = 'Ham and eggs'\n",
      "food = 'Hawaiian pizza'\n",
      "food = 'Liver and onions'\n",
      "food = 'Peanut butter and jelly'\n",
      "food = 'Pork chops and applesauce'\n",
      "\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "# hw3pr1, part (b) \n",
    "# find the list of most popular food pairings from the food pairing wikipedia\n",
    "#\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Food_pairing\"\n",
    "result = requests.get(url)\n",
    "#print(f\"{result = }\")\n",
    "\n",
    "food_pairing = result.text\n",
    "#print(food_pairing)\n",
    "\n",
    "text = food_pairing \n",
    "\n",
    "end = 0\n",
    "\n",
    "while True:\n",
    "    start = food_pairing.find('<li>', end)   # search for lists within the page\n",
    "    if start == -1: break                    # stop if we're done!\n",
    "    end = food_pairing.find('</li>', start)  \n",
    "    \n",
    "\n",
    "    list_slice = food_pairing[start:end]    \n",
    "    startl = list_slice.find('title=\"')      # within lists, extract the titles (actual text making up the list)\n",
    "    if startl == -1: continue                # if no title found, skip to next sliced list\n",
    "    startl += len('title=\"')                 # cut out title= from desired slices\n",
    "    endl = list_slice.find('\"', startl)  \n",
    "\n",
    "    titles = list_slice[startl:endl]         # cuts out lists that are not food pairings, such as wiki page categories and related pages\n",
    "    if 'Category:' in titles:\n",
    "        continue  \n",
    "\n",
    "    if 'Bread' in titles:                    # extra bread item from list of common foods instead of list of food pairings... probably a better way to skip this\n",
    "        continue  \n",
    "\n",
    "    if 'Flavor' in titles:\n",
    "        break\n",
    "\n",
    "    food = titles\n",
    "    print(f\"{food = }\")\n",
    "    \n",
    "\n",
    "print(\"\\nComplete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for <b>hw3pr1</b>, parts (a) and (b) ...\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "Onward to <b>hw3pr1</b>, part (c): &nbsp; _Writing your own web-engine_ &nbsp; (with regular expressions) \n",
    "  + We'll start by introducing _regular expressions_ - we'll see they provide a nice way to \"grab\" the <tt>&lt;li&gt;</tt> items from HTML...\n",
    "  + In fact, they're a great toolset for pretty much ***any*** text-extraction at all!\n",
    "\n",
    "  <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font style=\"color:rgb(180,120,10);\"><b>hw3pr2</b>  &nbsp; Regular Expressions: &nbsp;  A _better_ approach to list-item finding and extracting...</font>\n",
    "\n",
    "The list-item example above used one function to find the items and another to \"clearn them up.\"\n",
    "  + This is great! And, will work for absolutely anything you need (adding functions as you go...)\n",
    "\n",
    "**However**, there is a very powerful \"mini\" pattern-matching language that can help with many text-processing tasks: ***regular expressions***\n",
    "  + Sometimes called <tt>regex</tt>'es or <tt>re</tt>'s,\n",
    "  + regular expressions are a very compact languages for matching text patterns.\n",
    "  + the Python library is <tt>re</tt>\n",
    "\n",
    "Before unpacking the regex language, let's see it in action for the \"handle list-item tags\" challenge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the regular expression library (it should be built-in)\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = [' Poptarts ', ' Chocolate ', ' Coffee ']\n"
     ]
    }
   ],
   "source": [
    "# REs are a whole language! \n",
    "# Let's see a strategic use, to get our snacks from the snack_page above:\n",
    "import re\n",
    "\n",
    "m = re.findall(r'<li class=\"snack\">(.*)</li>', snack_page )      # Yikes!    Common functions: findall, sub, search, match  \n",
    "\n",
    "print(f\"{m = }\")                                                 # Wow!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A nice example of RE's, _Regular Expressions_!  &nbsp;&nbsp; \n",
    "\n",
    "No turning back now...  😊\n",
    "\n",
    "<br>\n",
    "\n",
    "As a goal, let's build up to that large example above.  However, we won't use ``findall`` .\n",
    "\n",
    "It's more informative to use ``sub`` (for _substitution_), so we can see what's found -- and what it becomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mildred Mudd'"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try some smaller examples to build up to the snack_page example:\n",
    "\n",
    "# fundamental capabilities:  regex matching and substitution  \n",
    "#\n",
    "#    the regex:\n",
    "#      matcher:    replacer:   in this string:\n",
    "re.sub(r\"Harvey\",  \"Mildred\",  \"Harvey Mudd\")           # the 'r' is for 'raw' strings. They're best for re's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This cat is cateful!'"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"car\", \"cat\",  \"This car is careful!\")          # we'll stick with substitution for now...  uh oh!  space or ,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harvey Mudd'"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"d\", \"dd\", \"Harvey Mud\")          # try \"Mildred Mudd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mildred Mudd'"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANCHORS:  Patterns can be anchored:   $ meand the _end_\n",
    "re.sub(r\"d$\", \"dd\", \"Mildred Mud\" )   # $ signifies (matches) the END of the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ℳildred Mudd'"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANCHORS:  Patterns can be anchored:   ^  means the _start_ \n",
    "re.sub(r\"^M\", \"ℳ\", \"Mildred Mudd\" )   # ^ signifies (matches) the START of the line  (unicode M :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Isn't the alien sking this weekend? AiIIIiIIIeee!\""
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLUS  +   means one or more:\n",
    "re.sub(r\"i+\", \"i\", \"Isn't the aliiien skiing this weekend? AiiiIIIiiiiIIIeee!\" )   # try replacing with \"\" or \"I\" or \"𝒾\" or \"ⓘ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"isn't the alien sking this weekend? Aieee!\""
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SquareBrackets  [iI]  mean any from that character group:\n",
    "re.sub(r\"[Ii]+\", \"i\", \"Isn't the aliiien skiing this weekend? AiiiIIIiiiiIIIeee!\" )   # it can vary within the group!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A**! Y**'** FOUND ** ******: 42!\""
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SquareBrackets allow ranges, e.g., [a-z]\n",
    "re.sub(r\"[a-z]\", \"*\", \"Aha! You've FOUND my secret: 42!\")       # use a +,  add A-Z, show \\w, for \"word\" character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aliens <3 pets! They have 42 cats, 42 lemurs, and 42 manatees!'"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try the range [0-9] and +\n",
    "re.sub(r\" [0-9]+\", \" 42\",  \"Aliens <3 pets! They have 45 cats, 6 lemurs, and 789 manatees!\")   # DISCUSS!  no +? How to fix?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! &nbsp;&nbsp; Let's expand our thought experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-S'"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub( r\"or\", \"and\", \"words or phrases\" )\n",
    "re.sub( r\"s\", \"-\", \"words or phrases\" )\n",
    "re.sub( r\"[aeiou]\", \"-\", \"words or phrases\" )\n",
    "\n",
    "re.sub( r\"$\", \" [end]\", \"words or phrases\" )\n",
    "re.sub( r\"^\", \"[start] \", \"words or phrases\" )\n",
    "\n",
    "# # Challenge! The dot . matches _any_ single character:  \n",
    "re.sub( r\".\", \"-\", \"words or phrases\" )   # What will this do?\n",
    "\n",
    "re.sub( r\".s\", \"-S\", \"words or phrases\" )  # And this one?!\n",
    "\n",
    "re.sub( r\".+s\", \"-S\", \"words or phrases\" )  # And this one?!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one more \"common\" regular expression element. &nbsp;&nbsp; The star * means \"zero or more\" of what precedes it...\n",
    "\n",
    "It's similar to the plus + (which means 1 or more), _but * also allows for 0 times_ !  &nbsp;&nbsp; This can be mind-bending..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Favorite #'s:  47 47 47 47 47 47\""
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The star (asterisk) matches ZERO or more times...\n",
    "re.sub(r\"42*\", \"47\", \"Favorite #'s:  4 42 422 4222 42222 422222\")       # try + {2}  {1,3}   (42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####   Ok!  Let's break out, to a more <font color=\"DodgerBlue\"><b>hands-on</b></font> medium...\n",
    "\n",
    "... to try out our ``\"alabama\"`` and ``\"Google\"`` regular-expression challenges... :) \n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have ***almost*** everything in that list-item-handling example from a while back. \n",
    "\n",
    "Let's take a look -- and add the idea of a _capture group_   &nbsp;&nbsp; (using parens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-G--g-l-e-'"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"o*\", \"-\", \"Google\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = [' Poptarts ', ' Chocolate ', ' Coffee ']\n"
     ]
    }
   ],
   "source": [
    "m = re.findall(r'<li class=\"snack\">(.*)</li>', snack_page )   # parens are a \"capture group\"   # try w/o it  # try search & sub\n",
    "                                                   # each set of parents \"captures\" the text inside it\n",
    "print(f\"{m = }\")                                   # it can even be used later, as \\1, \\2, \\3, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font style=\"color:rgb(180,120,10);\"><b>hw3pr1, part(c)</b> &nbsp;&nbsp; Writing your own Web Engine &nbsp; _with Regular Expressions_ ... </font>\n",
    "\n",
    "A **web engine** is an informal term for software that makes content visible in a browser. For example,\n",
    "+ In Jupyter notebooks, we write _markdown_ and then VSCode renders it as _markup_\n",
    "+ Similarly, this happens in Google Colab and _anywhere_ markdown is used! \n",
    "  + to do this, the syntax <tt>_italic_</tt> gets transformed into <tt><i>italic</i></tt> by a \"markdown-to-markup\" web engine\n",
    "  + from there, the browser can render the latter using its markup: &nbsp; <i>italic</i>\n",
    "  + (in fact, it uses another web engine to go from markup to visible content)  \n",
    "  \n",
    "+ We will focus on implementing the **markdown-to-markup** step - and extending it, by adding a few features of your own design \n",
    "\n",
    "<b><font color=\"DodgerBlue\">Side note</font></b>: &nbsp;&nbsp; This is an example of _meta-programming_ for software! That is, writing programs that transform one sort of programs into another, more useful sort!\n",
    "+ Often, with strategic transformations along the way...\n",
    "+ Metaprogramming is poised to be a much larger part of the next two decades than it was in the last two...!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell has the _starting markdown_ for our **markdown-to-markup** web engine.  \n",
    "\n",
    "Because the next cell ***is*** markdown -- and it's in a notebook _with_ a markdown engine -- you'll see the markup, as usual!\n",
    "+ As usual, you can see the markdown by double-clicking the cell\n",
    "+ It's also available as a Python string in the following cell..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claremont's Colleges - MARKDOWN version\n",
    "\n",
    "The Claremont Colleges are a *consortium* of **five** SoCal institutions. <br>\n",
    "We list them here.\n",
    "\n",
    "## The 5Cs: a list\n",
    "+ [Pomona](https://www.pomona.edu/)\n",
    "+ [CMC](https://www.cmc.edu/)\n",
    "+ [Pitzer](https://www.pitzer.edu/)\n",
    "+ [Scripps](https://www.scrippscollege.edu/)\n",
    "+ [HMC](https://www.hmc.edu/)\n",
    "\n",
    "The above's an _unordered_ list.  <br>\n",
    "At the 5Cs, we all agree there's __no__ order!\n",
    "\n",
    "---\n",
    "\n",
    "## Today's featured college: [CMC](https://coloradomtn.edu/)\n",
    "\n",
    "<img src=\"https://ygzm5vgh89zp-u4384.pressidiumcdn.com/wp-content/uploads/2017/06/GWS_campusview_1000x627.jpg\" height=160>\n",
    "\n",
    "---\n",
    "\n",
    "### Also featured: &nbsp; Scripps and Pitzer and Mudd and Pomona\n",
    "\n",
    "<img src=\"https://i0.wp.com/tsl.news/wp-content/uploads/2018/09/scripps.png?w=1430&ssl=1\" height=100px> &nbsp; \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f9/Brant_Clock_Tower%2C_Pitzer_College%2C_2016_%28cropped%29.jpg\" height=100px> &nbsp; \n",
    "<img src=\"https://www.hmc.edu/about/wp-content/uploads/sites/2/2020/02/campus-gv.jpg\" height=100px> &nbsp;\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/46/Smith_Tower_and_the_San_Gabriel_Mountains.jpg\" height=100px>\n",
    "\n",
    "Are there _other_ schools in Claremont?\n",
    "\n",
    "### Claremont destinations\n",
    "+ _Pepo Melo_, a fantastic font of fruit!\n",
    "+ **Starbucks**, the center of Claremont's \"city,\" not as good as Scripps's _Motley_ \n",
    "+ ***Sancho's Tacos***, the village's newest establishment\n",
    "+ ~~In-and-out CS35_Participant_3~~ (not in Claremont, alas, but close! CMC-supported!)\n",
    "+ `42`nd Street Bagel, an HMC fave, definitely _well-numbered_\n",
    "+ Trader Joe's, providing fuel for the walk back to Pitzer _from Trader Joe's_\n",
    "\n",
    "---\n",
    "\n",
    "#### Regular Expression Code-of-the-Day \n",
    "`import re`               \n",
    "`pet_statement = re.sub(r'dog', 'cat', 'I <3 dogs')`\n",
    "\n",
    "#### New Construction of the ~~Day~~ _Decade_!\n",
    "\n",
    "<img src=\"https://www.cs.hmc.edu/~dodds/roberts_uc.png\" height=150> <br><br>\n",
    "\n",
    "CMC's **_Roberts Science Center_, also known as _\"The Rubiks Cube\"_** <br>\n",
    "Currently under construction, under deadline, and undeterred by SoCal sun, or rain... \n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Here is a code cell, with the entire first-draft markdown of the previous cell \n",
    "# \n",
    "# stored in the Python variable      original_markdown\n",
    "#\n",
    "\n",
    "original_markdown = \"\"\"\n",
    "\n",
    "# Claremont's Colleges - MARKDOWN version\n",
    "\n",
    "The Claremont Colleges are a *consortium* of **five** SoCal institutions. <br>\n",
    "We list them here.\n",
    "\n",
    "## The 5Cs: a list\n",
    "+ [Pomona](https://www.pomona.edu/)\n",
    "+ [CMC](https://www.cmc.edu/)\n",
    "+ [Pitzer](https://www.pitzer.edu/)\n",
    "+ [Scripps](https://www.scrippscollege.edu/)\n",
    "+ [HMC](https://www.hmc.edu/)\n",
    "\n",
    "The above's an _unordered_ list.  <br>\n",
    "At the 5Cs, we all agree there's __no__ order!\n",
    "\n",
    "---\n",
    "\n",
    "## Today's featured college: [CMC](https://coloradomtn.edu/)\n",
    "\n",
    "<img src=\"https://ygzm5vgh89zp-u4384.pressidiumcdn.com/wp-content/uploads/2017/06/GWS_campusview_1000x627.jpg\" height=160>\n",
    "\n",
    "---\n",
    "\n",
    "### Also featured: &nbsp; Scripps and Pitzer and Mudd and Pomona\n",
    "\n",
    "<img src=\"https://i0.wp.com/tsl.news/wp-content/uploads/2018/09/scripps.png?w=1430&ssl=1\" height=100px> &nbsp; \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f9/Brant_Clock_Tower%2C_Pitzer_College%2C_2016_%28cropped%29.jpg\" height=100px> &nbsp; \n",
    "<img src=\"https://www.hmc.edu/about/wp-content/uploads/sites/2/2020/02/campus-gv.jpg\" height=100px> &nbsp;\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/46/Smith_Tower_and_the_San_Gabriel_Mountains.jpg\" height=100px>\n",
    "\n",
    "Are there _other_ schools in Claremont?\n",
    "\n",
    "### Claremont destinations\n",
    "+ _Pepo Melo_, a fantastic font of fruit!\n",
    "+ **Starbucks**, the center of Claremont's \"city,\" not as good as Scripps's _Motley_ \n",
    "+ ***Sancho's Tacos***, the village's newest establishment\n",
    "+ ~~In-and-out CS35_Participant_3~~ (not in Claremont, alas, but close! CMC-supported!)\n",
    "+ `42`nd Street Bagel, an HMC fave, definitely _well-numbered_\n",
    "+ Trader Joe's, providing fuel for the walk back to Pitzer _from Trader Joe's_\n",
    "\n",
    "---\n",
    "\n",
    "#### Regular Expression Code-of-the-Day \n",
    "`import re`               \n",
    "`pet_statement = re.sub(r'dog', 'cat', 'I <3 dogs')`\n",
    "\n",
    "#### New Construction of the ~~Day~~ _Decade_!\n",
    "\n",
    "<img src=\"https://www.cs.hmc.edu/~dodds/roberts_uc.png\" height=150> <br><br>\n",
    "\n",
    "CMC's ** _Roberts Science Center_, also known as _\"The Rubiks Cube\"_** <br>\n",
    "Currently under construction, under deadline, and undeterred by SoCal sun, or rain... \n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# here is a function to write a string to a file (default name: output.html)\n",
    "#\n",
    "\n",
    "def write_to_file(contents, filename=\"output.html\"):\n",
    "    \"\"\" writes the string final_contents to the file filename \"\"\"\n",
    "    f = open(filename,\"w\")\n",
    "    print(contents, file=f)\n",
    "    print(f\"{filename = } written. Try opening it in a browser!\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename = 'output.html' written. Try opening it in a browser!\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Let's write our original_markdown to file...\n",
    "#\n",
    "\n",
    "write_to_file(original_markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"Goldenrod\"><b>Your hw3pr1c task</b></font> is to create a set of functions that create a markdown-to-markup transformer!\n",
    "+ <b>including</b> at least these existing markdown features: headers, bold, italic, strikethrough (for Toby!), url-links, and item-lists\n",
    "+ <b>and you should design</b> at least three new markdown-features of your own. <font size=\"-2\">(This is ***modern*** markdown, not that stodgy markdown from the 90's!)</font>\n",
    "+ The assignment page has several suggestions. You'll add to the markdown source to show off your new features (and customize)\n",
    "\n",
    "<hr>\n",
    "\n",
    "To get started, the following cells have a couple of example transformations: \n",
    "+ how to convert the word ``MARKDOWN`` to the word ``MARKUP``\n",
    "+ how to convert all of the newlines to <tt>&lt;br&gt;</tt>\n",
    "+ how to handle the <tt># </tt>  top-level headers, which use <tt>&lt;h1&gt;</tt> and  <tt>&lt;/h1&gt;</tt> around their contents\n",
    "+ how to handle fixed-width (<tt>code-type</tt>) text, which converts backticks <tt>`</tt> to <tt>&lt;tt&gt;</tt>, e.g., <tt>&#96;code&#96;</tt> to <tt>&lt;tt&gt;code&lt;/tt&gt;</tt>\n",
    "\n",
    "It writes out the result to a file. \n",
    "+ Reload it directly in a browser to see how well it's doing.\n",
    "+ Then, dive into the other changes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename = 'output.html' written. Try opening it in a browser!\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# overall mardown-to-markup transformer\n",
    "#\n",
    "\n",
    "contents_v0 = original_markdown              # here is the input - be sure to run the functions, below:\n",
    "\n",
    "contents_v1 = handle_down_to_up(contents_v0)   #   blank lines to <br>\n",
    "contents_v2 = handle_newlines(contents_v1)   #   blank lines to <br>\n",
    "contents_v3 = handle_headers(contents_v2)    #   # title to <h1>title</h1>  (more needed: ## to <h2>, ... up to <h6>)\n",
    "contents_v4 = handle_code(contents_v3)       #   `code` to <tt>code</tt>\n",
    "\n",
    "final_contents = contents_v4                 # here is the output - be sure it's the version you want!\n",
    "\n",
    "write_to_file(final_contents, \"output.html\") # now, written to file:  Reload it in your browser!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<br>\n",
      "<br>\n",
      "<h1> Claremont's Colleges - MARKUP version</h1>\n",
      "<br>\n",
      "The Claremont Colleges are a *consortium* of **five** SoCal institutions. <br>\n",
      "We list them here.\n",
      "<br>\n",
      "<h2> The 5Cs: a list</h2>\n",
      "+ [Pomona](https://www.pomona.edu/)\n",
      "+ [CMC](https://www.cmc.edu/)\n",
      "+ [Pitzer](https://www.pitzer.edu/)\n",
      "+ [Scripps](https://www.scrippscollege.edu/)\n",
      "+ [HMC](https://www.hmc.edu/)\n",
      "<br>\n",
      "The above's an _unordered_ list.  <br>\n",
      "At the 5Cs, we all agree there's __no__ order!\n",
      "<br>\n",
      "---\n",
      "<br>\n",
      "<h2> Today's featured college: [CMC](https://coloradomtn.edu/)</h2>\n",
      "<br>\n",
      "<img src=\"https://ygzm5vgh89zp-u4384.pressidiumcdn.com/wp-content/uploads/2017/06/GWS_campusview_1000x627.jpg\" height=160>\n",
      "<br>\n",
      "---\n",
      "<br>\n",
      "<h3> Also featured: &nbsp; Scripps and Pitzer and Mudd and Pomona</h3>\n",
      "<br>\n",
      "<img src=\"https://i0.wp.com/tsl.news/wp-content/uploads/2018/09/scripps.png?w=1430&ssl=1\" height=100px> &nbsp; \n",
      "<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f9/Brant_Clock_Tower%2C_Pitzer_College%2C_2016_%28cropped%29.jpg\" height=100px> &nbsp; \n",
      "<img src=\"https://www.hmc.edu/about/wp-content/uploads/sites/2/2020/02/campus-gv.jpg\" height=100px> &nbsp;\n",
      "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/46/Smith_Tower_and_the_San_Gabriel_Mountains.jpg\" height=100px>\n",
      "<br>\n",
      "Are there _other_ schools in Claremont?\n",
      "<br>\n",
      "<h3> Claremont destinations</h3>\n",
      "+ _Pepo Melo_, a fantastic font of fruit!\n",
      "+ **Starbucks**, the center of Claremont's \"city,\" not as good as Scripps's _Motley_ \n",
      "+ ***Sancho's Tacos***, the village's newest establishment\n",
      "+ ~~In-and-out CS35_Participant_3~~ (not in Claremont, alas, but close! CMC-supported!)\n",
      "+ <tt>42</tt>nd Street Bagel, an HMC fave, definitely _well-numbered_\n",
      "+ Trader Joe's, providing fuel for the walk back to Pitzer _from Trader Joe's_\n",
      "<br>\n",
      "---\n",
      "<br>\n",
      "<h4> Regular Expression Code-of-the-Day </h4>\n",
      "<tt>import re</tt>               \n",
      "<tt>pet_statement = re.sub(r'dog', 'cat', 'I <3 dogs')</tt>\n",
      "<br>\n",
      "<h4> New Construction of the ~~Day~~ _Decade_!</h4>\n",
      "<br>\n",
      "<img src=\"https://www.cs.hmc.edu/~dodds/roberts_uc.png\" height=150> <br><br>\n",
      "<br>\n",
      "CMC's ** _Roberts Science Center_, also known as _\"The Rubiks Cube\"_** <br>\n",
      "Currently under construction, under deadline, and undeterred by SoCal sun, or rain... \n",
      "<br>\n",
      "<br><br>\n",
      "<br>\n",
      "<br>\n",
      "<br>\n"
     ]
    }
   ],
   "source": [
    "# we can also print the final output's source - this should show the HTML (so far)\n",
    "print(final_contents)    \n",
    "# in addition, _do_ open up output.html in your browser and then View Source to see the same HTML (so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is MARKUP text\n"
     ]
    }
   ],
   "source": [
    "# here is a function to change MARKDOWN to MARKUP\n",
    "#\n",
    "import re\n",
    "\n",
    "def handle_down_to_up(contents):\n",
    "    \"\"\" replace all instances of MARKDOWN with MARKUP \"\"\"\n",
    "    new_contents = re.sub(r\"MARKDOWN\", r\"MARKUP\", contents)  # simple substitution\n",
    "    return new_contents\n",
    "\n",
    "# Let's test this!\n",
    "if True:\n",
    "    old_contents = \"This is MARKDOWN text\"\n",
    "    new_contents = handle_down_to_up(old_contents) \n",
    "    print(new_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<br>\n",
      "# Title\n",
      "<br>\n",
      "# Another title\n"
     ]
    }
   ],
   "source": [
    "# here is a function to handle blank lines (making them <br>)\n",
    "#\n",
    "import re\n",
    "\n",
    "def handle_newlines(contents):\n",
    "    \"\"\" replace all of the just-newline characters \\n with HTML newlines <br> \"\"\"\n",
    "    NewLines = []\n",
    "    OldLines = contents.split(\"\\n\")\n",
    "\n",
    "    for line in OldLines:\n",
    "        new_line = re.sub(r\"^\\s*$\", r\"<br>\", line)  # if a line has only space characters, \\s, we make an HTML newline <br>\n",
    "        NewLines.append(new_line)\n",
    "\n",
    "    new_contents = \"\\n\".join(NewLines)   # join with \\n characters so it's readable by humans\n",
    "    return new_contents\n",
    "\n",
    "\n",
    "# Let's test this!\n",
    "if True:\n",
    "    old_contents = \"\"\"\n",
    "# Title\n",
    "    \n",
    "# Another title\"\"\"\n",
    "    new_contents = handle_newlines(old_contents)\n",
    "    print(new_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<h1>Title</h1>\n",
      "<br>\n",
      "<h1>Another title</h1>\n"
     ]
    }
   ],
   "source": [
    "# here is a function to handle headers - right now only h1 (top-level)\n",
    "#\n",
    "import re\n",
    "\n",
    "def handle_headers(contents):\n",
    "    \"\"\" replace all of the #, ##, ###, ... ###### headers with <h1>, <h2>, <h3>, ... <h6> \"\"\"\n",
    "    NewLines = []\n",
    "    OldLines = contents.split(\"\\n\")\n",
    "\n",
    "    for line in OldLines:\n",
    "        new_line = re.sub(r\"^# (.*)$\", r\"<h1>\\1</h1>\", line)  # capture the contents and wrap with <h1> and </h1>\n",
    "                                                              # Aha! You will be able to handle the other headers here!\n",
    "        NewLines.append(new_line)\n",
    "\n",
    "    new_contents = \"\\n\".join(NewLines)   # join with \\n characters so it's readable by humans\n",
    "    return new_contents\n",
    "\n",
    "# Let's test this!\n",
    "if True:\n",
    "    old_contents = \"\"\"\n",
    "# Title\n",
    "<br>\n",
    "# Another title\"\"\"\n",
    "    new_contents = handle_headers(old_contents)\n",
    "    print(new_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is <tt>42</tt>   \n",
      "<br> \n",
      "Our regex library:  <tt>import re</tt>\n"
     ]
    }
   ],
   "source": [
    "# here is a function to handle code - using markdown backticks\n",
    "#\n",
    "import re\n",
    "\n",
    "def handle_code(contents):\n",
    "    \"\"\" replace all of the backtick content with <code> </code> \"\"\"\n",
    "    NewLines = []\n",
    "    OldLines = contents.split(\"\\n\")\n",
    "\n",
    "    for line in OldLines:\n",
    "        new_line = re.sub(r\"`(.*)`\", r\"<tt>\\1</tt>\", line)  # capture the contents and wrap with <code> and </code>\n",
    "        NewLines.append(new_line)\n",
    "\n",
    "    new_contents = \"\\n\".join(NewLines)   # join with \\n characters so it's readable by humans\n",
    "    return new_contents\n",
    "\n",
    "# Let's test this!\n",
    "if True:\n",
    "    old_contents = \"\"\"\\\n",
    "This is `42`   \n",
    "<br> \n",
    "Our regex library:  `import re`\"\"\"\n",
    "    new_contents = handle_code(old_contents)\n",
    "    print(new_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font style=\"color:rgb(180,120,10);\"><b>hw3pr1 part(c)</b>  &nbsp;&nbsp; More transformations!</font>\n",
    "\n",
    "Your task is to make sure you can run the above transformations:\n",
    "+ For each one, one at a time, try it on the small example\n",
    "+ Then, uncomment it from the large (overall) example\n",
    "+ Be **sure** to change the final ``final_contents`` variable\n",
    "  + Forgetting this is the most common bug (not really a bug - just not running!)\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "From there, implement the other markdown-to-markup transformations as noted in [HW3's gdocs page](https://docs.google.com/document/d/17bJfQIeuNGVh5vP8Y2BjRbVSDyDUNTpIrH0lgYubiUU/edit?tab=t.0) :\n",
    "+ add new functions and cells -- or reuse other ones -- as you prefer\n",
    "  + do keep things organized, either way!\n",
    "+ handle all six levels of headers ``<h1>`` through ``<h6>``\n",
    "+ handle at least the five word-stylings noted, including _italic_, **bold**, ~~strikethrough~~, unordered lists, and [urls](https://docs.google.com/document/d/1IKZk9mbVkvsf9tl14EZD2CuNYhy3lQvO4Lnk89RmA-0/edit)\n",
    "+ and, handle, at least <b><font color=\"DodgerBlue\">three more features-or-stylings</font></b> of your own design. (See that gdocs hw page for several possibilities...)\n",
    "  + Note that you're welcome to _add prose to the original markdown page_ to show of your creative transformations\n",
    "  + Please don't _remove_ any of the original markdown, however -- that is for testing the various transformations, as well...\n",
    "\n",
    "<br>\n",
    "\n",
    "Lots of room for creativity, for sure...   \n",
    "\n",
    "<br>\n",
    "\n",
    "#### <font style=\"color:rgb(180,120,10);\"><b>Be sure your <u>final output HTML</u> is present!</b></font>\n",
    "+ This should show the result of _all_ the transformations:\n",
    "+ both the starting ones (such as strikethrough, bold, etc.)\n",
    "+ and your own creations :)\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "<font color=\"DodgerBlue\"><b>Meta-programming</b></font> -- that is, writing programs to help you write programs -- is mind-bending, for sure. \n",
    "+ As AI rises, there's no avoiding it: &nbsp;&nbsp; We have definitively entered the era of meta-programming ...\n",
    "\n",
    "Once your neurons are suitably _\"bent\"_ ... you'll find ***lots*** of uses for it! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<h6> Title</h6>\n",
      "<h2> Title</h2>\n",
      "<h1> Title</h1>\n",
      "<br>\n",
      "<h1> Another title</h1>\n"
     ]
    }
   ],
   "source": [
    "# here is a function to handle headers 1-6\n",
    "#\n",
    "import re\n",
    "\n",
    "def handle_headers(contents):\n",
    "    \"\"\" replace all of the #, ##, ###, ... ###### headers with <h1>, <h2>, <h3>, ... <h6> \"\"\"\n",
    "    NewLines = []\n",
    "    OldLines = contents.split(\"\\n\")\n",
    "\n",
    "    for line in OldLines:\n",
    "        hashtag_count = re.search(r\"(^#{1,6})([^#]+)\", line)          # looks for 1-6 hashtags in each line\n",
    "        if hashtag_count == None: \n",
    "            new_line = line\n",
    "            NewLines.append(new_line)\n",
    "            continue                            # if none are found, skip!\n",
    "        else: hashtag_count_num = len(hashtag_count.group(1))         # if some ARE found, count how many were found\n",
    "\n",
    "        hashtag_string = '#' * hashtag_count_num                      # I initially tried just having it be in the f-string, but ran into issues with {}\n",
    "                                                                      # so I stored it in a separate string\n",
    "                                                                      # there's probably a way to integrate this though....\n",
    "\n",
    "        new_line = re.sub(rf\"^{hashtag_string}([^#]+)\", rf\"<h{hashtag_count_num}>{hashtag_count.group(2)}</h{hashtag_count_num}>\", line)\n",
    "\n",
    "        # new_line = re.sub(r\"^#{2}([^#]+)$\", r\"<h2>\\1</h2>\", line)             # I originally tried this and it didn't work\n",
    "        # new_line = re.sub(r\"^#{3}([^#]+)$\", r\"<h3>\\1</h3>\", line)             # but rf string from class + asking AI what the re module could do\n",
    "        # new_line = re.sub(r\"^#{4}([^#]+)$\", r\"<h4>\\1</h4>\", line)             # helped me a lot :)\n",
    "        # new_line = re.sub(r\"^#{5}([^#]+)$\", r\"<h5>\\1</h5>\", line)\n",
    "        # new_line = re.sub(r\"^#{6}([^#]+)$\", r\"<h6>\\1</h6>\", line)\n",
    "        # new_line = re.sub(r\"^#{1}([^#]+)\", r\"<h1>\\1</h1>\", line)                                                      \n",
    "        NewLines.append(new_line)\n",
    "\n",
    "    new_contents = \"\\n\".join(NewLines)   # join with \\n characters so it's readable by humans\n",
    "    return new_contents\n",
    "\n",
    "# Let's test this!\n",
    "if True:\n",
    "    old_contents = \"\"\"\n",
    "###### Title\n",
    "## Title\n",
    "# Title\n",
    "<br>\n",
    "# Another title\"\"\"\n",
    "    new_contents = handle_headers(old_contents)\n",
    "    print(new_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is <s>42</s>   \n",
      "<br> \n",
      "Our regex library:  <s>import re</s>\n"
     ]
    }
   ],
   "source": [
    "def handle_strike(contents):\n",
    "    NewLines = []\n",
    "    OldLines = contents.split(\"\\n\")\n",
    "\n",
    "    for line in OldLines:\n",
    "        new_line = re.sub(r\"~~(.*)~~\", r\"<s>\\1</s>\", line)  # capture the contents and wrap with <code> and </code>\n",
    "        NewLines.append(new_line)\n",
    "\n",
    "    new_contents = \"\\n\".join(NewLines)   # join with \\n characters so it's readable by humans\n",
    "    return new_contents\n",
    "\n",
    "# Let's test this!\n",
    "if True:\n",
    "    old_contents = \"\"\"\\\n",
    "This is ~~42~~   \n",
    "<br> \n",
    "Our regex library:  ~~import re~~\"\"\"\n",
    "    new_contents = handle_strike(old_contents)\n",
    "    print(new_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is <b>42</b> \n",
      "this is <i>42</i> also\n",
      " <i><b>bold and italic</b></i>\n",
      "<br> \n",
      "Our regex library:  <b>import re</b>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def handle_ast(contents):\n",
    "    NewLines = []\n",
    "    OldLines = contents.split(\"\\n\")\n",
    "\n",
    "    for line in OldLines:\n",
    "        line = re.sub(r\"\\*\\*\\*([^\\*]+?)\\*\\*\\*\", r\"<i><b>\\1</b></i>\", line)   # moves down from 3-1\n",
    "        line = re.sub(r\"\\*\\*([^\\*]+?)\\*\\*\", r\"<b>\\1</b>\", line)\n",
    "        line = re.sub(r\"\\*([^\\*]+?)\\*\", r\"<i>\\1</i>\", line)\n",
    "\n",
    "        NewLines.append(line)\n",
    "\n",
    "    return \"\\n\".join(NewLines)\n",
    "\n",
    "# Test the function\n",
    "old_contents = \"\"\"\\\n",
    "This is **42** \n",
    "this is *42* also\n",
    " ***bold and italic***\n",
    "<br> \n",
    "Our regex library:  **import re**\n",
    "\n",
    "\"\"\"\n",
    "new_contents = handle_ast(old_contents)\n",
    "print(new_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is <sup>2</sup>   \n",
      "and <b>bold</b>\n",
      "<br> \n",
      "Our regex library:  <sup>import re</sup>\n"
     ]
    }
   ],
   "source": [
    "def handle_undl(contents):\n",
    "    NewLines = []\n",
    "    OldLines = contents.split(\"\\n\")\n",
    "\n",
    "    for line in OldLines:\n",
    "        undl_search = re.search(r\"(\\_{2})([^_]+)\", line) \n",
    "        if undl_search == None:\n",
    "            new_line = re.sub(r\"\\s\\_([^_]+)\\_\", r\" <sup>\\1</sup>\", line)  # capture the contents and wrap with <code> and </code>\n",
    "            NewLines.append(new_line)\n",
    "            continue\n",
    "        else: new_line = re.sub(r\"\\_{2}([^_]+)\\_{2}\", r\"<b>\\1</b>\", line)\n",
    "        NewLines.append(new_line)\n",
    "\n",
    "    new_contents = \"\\n\".join(NewLines)   # join with \\n characters so it's readable by humans\n",
    "    return new_contents\n",
    "\n",
    "# Let's test this!\n",
    "if True:\n",
    "    old_contents = \"\"\"\\\n",
    "This is _2_   \n",
    "and __bold__\n",
    "<br> \n",
    "Our regex library:  _import re_\"\"\"\n",
    "    new_contents = handle_undl(old_contents)\n",
    "    print(new_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is <li> 2   </li>\n",
      "and <li> bold</li>\n",
      "<br> \n",
      "Our regex library:  _import re_\n"
     ]
    }
   ],
   "source": [
    "def handle_plus(contents):\n",
    "    \"\"\" replace all of the backtick content with <code> </code> \"\"\"\n",
    "    NewLines = []\n",
    "    OldLines = contents.split(\"\\n\")\n",
    "\n",
    "    for line in OldLines:\n",
    "        new_line = re.sub(r\"\\+(.*)\", r\"<li>\\1</li>\", line)\n",
    "        NewLines.append(new_line)\n",
    "\n",
    "    new_contents = \"\\n\".join(NewLines)   # join with \\n characters so it's readable by humans\n",
    "    return new_contents\n",
    "\n",
    "# Let's test this!\n",
    "if True:\n",
    "    old_contents = \"\"\"\\\n",
    "This is + 2   \n",
    "and + bold\n",
    "<br> \n",
    "Our regex library:  _import re_\"\"\"\n",
    "    new_contents = handle_plus(old_contents)\n",
    "    print(new_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "This is <a href=https://www.pomona.edu/>Pomona</a>  \n",
      "<br> \n",
      "Our regex library:  _import re_\n"
     ]
    }
   ],
   "source": [
    "def handle_links(contents):\n",
    "    \"\"\" replace all of the backtick content with <code> </code> \"\"\"\n",
    "    NewLines = []\n",
    "    OldLines = contents.split(\"\\n\")\n",
    "\n",
    "    for line in OldLines:\n",
    "        new_line = re.sub(r\"\\[(.+)\\]\\((.+)\\)\", r\"<a href=\\2>\\1</a>\", line)\n",
    "        NewLines.append(new_line)\n",
    "\n",
    "    new_contents = \"\\n\".join(NewLines)   # join with \\n characters so it's readable by humans\n",
    "    return new_contents\n",
    "\n",
    "# Let's test this!\n",
    "if True:\n",
    "    old_contents = \"\"\"\\\n",
    "    \n",
    "This is [Pomona](https://www.pomona.edu/)  \n",
    "<br> \n",
    "Our regex library:  _import re_\"\"\"\n",
    "    new_contents = handle_links(old_contents)\n",
    "    print(new_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "This is [<font color=\"color:DodgerBlue;\">Pomona</font>](https://www.pomona.edu/)  \n",
      "<br> \n",
      "Our regex library:  _import re_\n"
     ]
    }
   ],
   "source": [
    "def handle_pomona(contents):\n",
    "    \"\"\" replace all of the backtick content with <code> </code> \"\"\"\n",
    "    NewLines = []\n",
    "    OldLines = contents.split(\"\\n\")\n",
    "\n",
    "    Scripps_color = '\"color:ShamrockGreen;\"'\n",
    "    Pomona_color = '\"color:DodgerBlue;\"'\n",
    "\n",
    "    for line in OldLines:\n",
    "        line = re.sub(r\"(Scripps)\", rf\"<font color={Scripps_color}>\\1</font>\", line)\n",
    "        line = re.sub(r\"(Pomona)\", rf\"<font color={Pomona_color}>\\1</font>\", line)\n",
    "        NewLines.append(line)\n",
    "\n",
    "    new_contents = \"\\n\".join(NewLines)   # join with \\n characters so it's readable by humans\n",
    "    return new_contents\n",
    "\n",
    "# Let's test this!\n",
    "if True:\n",
    "    old_contents = \"\"\"\\\n",
    "    \n",
    "This is [Pomona](https://www.pomona.edu/)  \n",
    "<br> \n",
    "Our regex library:  _import re_\"\"\"\n",
    "    new_contents = handle_pomona(old_contents)\n",
    "    print(new_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_gif(contents):\n",
    "    \"\"\" replace all of the backtick content with <code> </code> \"\"\"\n",
    "    NewLines = []\n",
    "    OldLines = contents.split(\"\\n\")\n",
    "\n",
    "    mb = '<marquee behavior=\"scroll\" direction=\"up\">'\n",
    "    picture = '<img src=\"https://ygzm5vgh89zp-u4384.pressidiumcdn.com/wp-content/uploads/2017/06/GWS_campusview_1000x627.jpg\" height=160>'\n",
    "    \n",
    "    for line in OldLines:\n",
    "        line = re.sub(rf\"{picture}\", rf\"{mb}{picture}</marquee>\", line)\n",
    "        NewLines.append(line)\n",
    "\n",
    "    new_contents = \"\\n\".join(NewLines)   # join with \\n characters so it's readable by humans\n",
    "    return new_contents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename = 'output.html' written. Try opening it in a browser!\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# overall mardown-to-markup transformer\n",
    "#\n",
    "\n",
    "contents_v0 = original_markdown              # here is the input - be sure to run the functions, below:\n",
    "\n",
    "contents_v1 = handle_down_to_up(contents_v0)   #   blank lines to <br>\n",
    "contents_v2 = handle_newlines(contents_v1)   #   blank lines to <br>\n",
    "contents_v3 = handle_headers(contents_v2)    #   # title to <h1>title</h1>  (more needed: ## to <h2>, ... up to <h6>)\n",
    "contents_v4 = handle_code(contents_v3)       #   `code` to <tt>code</tt>\n",
    "contents_v5 = handle_strike(contents_v4) \n",
    "contents_v6 = handle_ast(contents_v5) \n",
    "contents_v7 = handle_undl(contents_v6) \n",
    "contents_v8 = handle_plus(contents_v7) \n",
    "contents_v9 = handle_links(contents_v8)\n",
    "contents_v10 = handle_pomona(contents_v9)\n",
    "contents_v11 = handle_gif(contents_v10)\n",
    "\n",
    "\n",
    "final_contents = contents_v11                 # here is the output - be sure it's the version you want!\n",
    "\n",
    "write_to_file(final_contents, \"output.html\") # now, written to file:  Reload it in your browser!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<br>\n",
      "<br>\n",
      "<h1> Claremont's Colleges - MARKUP version</h1>\n",
      "<br>\n",
      "The Claremont Colleges are a <i>consortium</i> of <b>five</b> SoCal institutions. <br>\n",
      "We list them here.\n",
      "<br>\n",
      "<h2> The 5Cs: a list</h2>\n",
      "<li> <a href=https://www.pomona.edu/><font color=\"color:DodgerBlue;\">Pomona</font></a></li>\n",
      "<li> <a href=https://www.cmc.edu/>CMC</a></li>\n",
      "<li> <a href=https://www.pitzer.edu/>Pitzer</a></li>\n",
      "<li> <a href=https://www.scrippscollege.edu/><font color=\"color:ShamrockGreen;\">Scripps</font></a></li>\n",
      "<li> <a href=https://www.hmc.edu/>HMC</a></li>\n",
      "<br>\n",
      "The above's an <sup>unordered</sup> list.  <br>\n",
      "At the 5Cs, we all agree there's <b>no</b> order!\n",
      "<br>\n",
      "---\n",
      "<br>\n",
      "<h2> Today's featured college: <a href=https://coloradomtn.edu/>CMC</a></h2>\n",
      "<br>\n",
      "<marquee behavior=\"scroll\" direction=\"up\"><img src=\"https://ygzm5vgh89zp-u4384.pressidiumcdn.com/wp-content/uploads/2017/06/GWS_campusview_1000x627.jpg\" height=160></marquee>\n",
      "<br>\n",
      "---\n",
      "<br>\n",
      "<h3> Also featured: &nbsp; <font color=\"color:ShamrockGreen;\">Scripps</font> and Pitzer and Mudd and <font color=\"color:DodgerBlue;\">Pomona</font></h3>\n",
      "<br>\n",
      "<img src=\"https://i0.wp.com/tsl.news/wp-content/uploads/2018/09/scripps.png?w=1430&ssl=1\" height=100px> &nbsp; \n",
      "<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f9/Brant_Clock_Tower%2C_Pitzer_College%2C_2016_%28cropped%29.jpg\" height=100px> &nbsp; \n",
      "<img src=\"https://www.hmc.edu/about/wp-content/uploads/sites/2/2020/02/campus-gv.jpg\" height=100px> &nbsp;\n",
      "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/46/Smith_Tower_and_the_San_Gabriel_Mountains.jpg\" height=100px>\n",
      "<br>\n",
      "Are there <sup>other</sup> schools in Claremont?\n",
      "<br>\n",
      "<h3> Claremont destinations</h3>\n",
      "<li> <sup>Pepo Melo</sup>, a fantastic font of fruit!</li>\n",
      "<li> <b>Starbucks</b>, the center of Claremont's \"city,\" not as good as <font color=\"color:ShamrockGreen;\">Scripps</font>'s <sup>Motley</sup> </li>\n",
      "<li> <i><b>Sancho's Tacos</b></i>, the village's newest establishment</li>\n",
      "<li> <s>In-and-out CS35_Participant_3</s> (not in Claremont, alas, but close! CMC-supported!)</li>\n",
      "<li> <tt>42</tt>nd Street Bagel, an HMC fave, definitely <sup>well-numbered</sup></li>\n",
      "<li> Trader Joe's, providing fuel for the walk back to Pitzer <sup>from Trader Joe's</sup></li>\n",
      "<br>\n",
      "---\n",
      "<br>\n",
      "<h4> Regular Expression Code-of-the-Day </h4>\n",
      "<tt>import re</tt>               \n",
      "<tt>pet_statement = re.sub(r'dog', 'cat', 'I <3 dogs')</tt>\n",
      "<br>\n",
      "<h4> New Construction of the <s>Day</s> <sup>Decade</sup>!</h4>\n",
      "<br>\n",
      "<img src=\"https://www.cs.hmc.edu/~dodds/roberts_uc.png\" height=150> <br><br>\n",
      "<br>\n",
      "CMC's <b> <sup>Roberts Science Center</sup>, also known as <sup>\"The Rubiks Cube\"</sup></b> <br>\n",
      "Currently under construction, under deadline, and undeterred by SoCal sun, or rain... \n",
      "<br>\n",
      "<br><br>\n",
      "<br>\n",
      "<br>\n",
      "<br>\n"
     ]
    }
   ],
   "source": [
    "# we can also print the final output's source - this should show the HTML (so far)\n",
    "print(final_contents)    \n",
    "# in addition, _do_ open up output.html in your browser and then View Source to see the same HTML (so far)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflections\n",
    "This assignment was pretty fun! I did have a lot of trouble with the regex at first, and figuring out how it can be implemented in loops/getting around its built in weirdness but it was nice to see our coding immediately processed into a webpage (seeing the colors, animations, fonts styles slowly come into the page). \n",
    "\n",
    "I did notice that the color changing code wouldn't be processed quite right though? My Shamrock Green turned out Orange, and my Dodger Blue came out light green. I don't know how that could even happen.....\n",
    "\n",
    "If I had more time I would've loved to figure out more animation substitutions such as blinking text!\n",
    "\n",
    "Three extra changes:\n",
    "+ Animated CMC image\n",
    "+ Superscript \"_\"\n",
    "+ Changing colors of Pomona and Scripps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
