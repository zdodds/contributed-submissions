#
# computing-styling trick of the day     (or, of the minute...)
#
# the setting for word-wrapping on the output is
#     "notebook.output.wordwrap": true,   (in your settings.json file or from code ... settings ...) 

print( list(range(100)) )



#
# see if we have the requests library...
#

import requests





#
# if you _don't_ have the requests library, let's install it!
#

# for me, it worked to uncomment and run this command, here in this cell:
# #3 install requests  or   # install requests

# an alternative is to run, in a terminal, the command would be 
#  #3 install requests  or    # install requests      (the ! is needed only if inside python)

# it's very system-dependent how much you have to "restart" in order to use
# the new library (the notebook, vscode, the jupyter extension, etc.)

# troubles?  let us know!  we'll work on it with you...


#
# hopefully, this now works! (if so, running will succeed silently)
#

import requests


#
# let's try it on a simple webpage
#

#
# we assign the url and obtain the api-call result into result
#    note that result will be an object that contains many fields (not a simple string)
# 

url = "https://www.cs.hmc.edu/~dodds/demo.html"
result = requests.get(url)
result    

# if it succeeded, you should see <response [200]>
# see the list of http reponse codes for the full set!


#
# when exploring, you'll often obtain an unfamiliar object. 
# here, we'll ask what type it is 
type(result)


# here is one of the data members within the result
# it "remembers" (keeps track of) the url requested:
result.url


# we can print all of the data members in an object with dir
# since dir returns a list, we will grab that list and loop over it:
all_fields = dir(result)

for field in all_fields:
    if "_" not in field: 
        print(field)


#
# let's try printing a few of those fields (data members): 
print(f"result.url         is {result.url}")  # the original url
print(f"result.raw         is {result.raw}")  # another object!
print(f"result.encoding    is {result.encoding}")  # utf-8 is very common
print(f"result.status_code is {result.status_code}")  # 200 is success!


# in this case, the result is a text file (html) let's see it!
contents = result.text
print(contents)


# yay!  
# this shows that you are able to "scrape" an arbitrary html page... 

# now, we're off to more _structured_ data-gathering...


#
# we assign the url and obtain the api-call result into result
#    note that result will be an object that contains many fields (not a simple string)
# 

import requests

url = "http://api.open-notify.org/iss-now.json"   # this is sometimes called an "endpoint" ...
result = requests.get(url)
result    

# if it succeeds, you should see <response [200]>


#
# let's try printing those shorter fields from before:
print(f"result.url         is {result.url}")  # the original url
print(f"result.raw         is {result.raw}")  # another object!
print(f"result.encoding    is {result.encoding}")  # utf-8 is very common
print(f"result.status_code is {result.status_code}")  # 200 is success!


#
# in this case, we know the result is a json file, and we can obtain it that way:
json_contents = result.json()
print(json_contents)

# remember:  json_contents will be a _dictionary_


#
# let's re-remind ourselves how dictionaries work:
long1 = float (json_contents['iss_position']['longitude'])
lat1 = float (json_contents['iss_position']['latitude'])       # challenge:  could we access the other components? what _types_ are they?!!

print(long1)
print(lat1)


#
# in python, we can use the resulting dictionary... let's see its keys:
print(list(json_contents.keys()))  

# also, watch out for string vs. numeric types, e.g., for latitude and longitude.
# at heart, _all_ web data are strings... .

# these experiments will be helpful for problem 1, below :


def harversine(lat1, long1, lat2, long2):
    """
    calculate the circle distance in km between two points
    """
    from math import radians, sin, cos, sqrt, asin #this import is for the sin, cos, radians
    #convert decimal in degrees to radians
    long1, lat1, long2, lat2 = map(radians, [long1, lat1, long2, lat2])

    #harversine forumla
    dlong = long2 - long1
    dlat = lat2 - lat1
    trig = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlong/2)**2
    #radius of the earth. 3956 for miles. 6371 for km
    radius = 3956 #miles
    return radius * 2 * asin(sqrt(trig))

long2 = 34.0967
lat2 = -117.7198

harversine(lat1, long1, lat2, long2)


# json is a javascript dictionary format -- almost the same as a python dictionary:
data = { 'key':'value',  'fave':42,  'list':[5,6,7,{'mascot':'aliiien'}] }
print(data)

# we can write in json format to a local file, named small42.json:
import json 

with open("small.json", "w") as f:
    json.dump( data, f )


# we can also read from a json file
# the resulting data will be a _dictionary_:

with open("small.json", "r") as f:
    dictionary = json.load( f )

print(f"the {dictionary = }")


# let's access this dictionary -- first, the keys:
list(dictionary.keys())   # how do we get 'aliiien' from newdata?


# task: use the dictionary to obtain (a) 'value' , (b) 42 , (c) 'aliiien'  [tricky!]

# remember that there are two ways to get the value from a key:
# way 1:  dictionary['key']            # errors if 'key' isn't present
# way 2:  dictionary.get('key')        # returns none if 'key' isn't present

dictionary['key']


import requests 

# here, we will obtain plain-text results from a request
url = "https://www.cs.hmc.edu/~dodds/demo.html"  # try it + source
# url = "https://www.scrippscollege.edu/"          # another possible site...
# url = "https://www.pitzer.edu/"                  # another possible site...
# url = "https://www.cmc.edu/"                     # and another!
# url = "https://www.cgu.edu/"
result = requests.get(url)        
print(f"result is {result}")        # hopefully it's 200


# if the request was successful, the response will be [200]. 
# then, we can grab the text - or json - from the site:

text = result.text                  # provides the html page as a large string...
print(f"len(text) is {len(text)}")  # let's see how large the html page is... 

print("\nthe first 242 characters are\n")
print(text[:242])                  # we'll print the first few characters...  

# change this to text[:] to see the whole document...
# notice that we can run many different analyses without having to re-call/re-scrape the page (this is good!)


#
# we assign the url and use requests.get to obtain the result into result_astro
#
#    remember, result_astro will be an object that contains many fields (not a simple string)
# 

import requests

url = "http://api.open-notify.org/astros.json"   # this is sometimes called an "endpoint" ...
result_astro = requests.get(url)
result_astro

# if it succeeded, you should see <response [200]>


# if the request succeeded, we know the result is a json file, and we can obtain it that way.
# let's call our dictionary something more specific:

astronauts = result_astro.json()
print(astronauts)
d = astronauts     # d is shorter to type

# remember:  d and astronauts will be a _dictionary_

note = """ here's yesterday's result - it _should_ be the same today!

{"people": [{"craft": "iss", "name": "oleg kononenko"}, {"craft": "iss", "name": "nikolai chub"},
{"craft": "iss", "name": "tracy caldwell dyson"}, {"craft": "iss", "name": "matthew dominick"},
{"craft": "iss", "name": "michael barratt"}, {"craft": "iss", "name": "jeanette epps"},
{"craft": "iss", "name": "alexander grebenkin"}, {"craft": "iss", "name": "butch wilmore"},
{"craft": "iss", "name": "sunita williams"}, {"craft": "tiangong", "name": "li guangsu"},
{"craft": "tiangong", "name": "li cong"}, {"craft": "tiangong", "name": "ye guangfu"}], "number": 12, "message": "success"}
"""
""


#
# cell to try out parsing d  (astronauts)
#
print(d['people'][4]['name'])
d['people'][4]['name'][3:0:-2]


#
# let's try the  count  endpoint, with geojson format (json with geographical data)
#

url = "https://earthquake.usgs.gov/fdsnws/event/1/count?format=geojson&minmagnitude=5.0&starttime=2024-01-01&endtime=2024-02-01"

result = requests.get(url)                       # a named input, params, taking the value param_d, above
print(f"result is {result}")                     # hopefully, this is 200
print(f"the full url used was\n {result.url}")   # it's nice to be able to see this


# if it worked, we should be able to obtain the json. remember, it's a dictionary. let's use d:

d = result.json()

print(f"{d =}")


#
# here is the endpoint
#
url = "https://earthquake.usgs.gov/fdsnws/event/1/count"

# let's use variables for three of the parameters:
min_mag = 5.0               # the minimum magnitude considered a quake (min_mag)
start_time = "2025-01-01"   # this is the year-month-day format of the start
finish_time = "2025-02-01"  # similar for the end

# we assemble a dictionary of our parameters, let's name it para_dict
# there are many more parameters available. the problems below ask you to explore them...
para_dict = { "format":"geojson",         # this is simply hard-coded to obtain json
                     "starttime":start_time,
                     "endtime":finish_time,
                     "minmagnitude":min_mag,
                     }

# here, we use requests to make the request. the parameters will be added by this api call:
result = requests.get(url, params=para_dict)
print(f"result is {result}")                     # hopefully, this is 200
print(f"the full url used was\n {result.url}")   # this will include the parameters!


# if it worked, we should be able to see the json results:

d = result.json()
print(f"json returned was {d = }")


#
# how many quakes of magnitude >= 4.2 have been within 300km of claremont 
#     + in jan 2025
#     + in dec 2025
#
url = "https://earthquake.usgs.gov/fdsnws/event/1/count"

# let's use variables for three of the parameters:
min_mag = 4.2               # the minimum magnitude considered a quake (min_mag)
start_time = "2025-01-01"   # this is the year-month-day format of the start
finish_time = "2025-02-01"  # similar for the end
# start_time = "2024-01-01"   # similar, but for a year-cs35_participant_2 span...
# finish_time = "2025-01-01"  # similar for the end
radius_in_km = 300

# we assemble a dictionary of our parameters, let's name it para_dict
# there are many more parameters available. the problems below ask you to explore them...
para_dict = { "format":"geojson",         # this is simply hard-coded to obtain json
                     "starttime":start_time,
                     "endtime":finish_time,
                     "minmagnitude":min_mag,
                     "latitude":34.0967,
                     "longitude":-117.7198,
                     "maxradiuskm":radius_in_km,
                     }

# here, we use requests to make the request. the parameters will be added by this api call:
result = requests.get(url, params=para_dict)
print(f"result is {result}")                     # hopefully, this is 200
print(f"the full url used was\n {result.url}")   # this will include the parameters!

# we'll extract the final result in another cell:


# let's finish up here:
quake_count = result.json()
print(f"{quake_count = }")


#
# here is the endpoint
#
url = "https://earthquake.usgs.gov/fdsnws/event/1/query"

# let's use variables for three of the parameters:
min_mag = 7.5               # the minimum magnitude considered a quake (min_mag)
start_time = "2024-01-01"   # this is the year-month-day format of the start
finish_time = "2024-12-31"  # similar for the end

# we assemble a dictionary of our parameters, let's name it para_dict
# there are many more parameters available. the problems below ask you to explore them...
para_dict = { "format":"geojson",         # this is simply hard-coded to obtain json
                     "starttime":start_time,
                     "endtime":finish_time,
                     "minmagnitude":min_mag,
                     }

# here, we use requests to make the request. the parameters will be added by this api call:
result = requests.get(url, params=para_dict)
print(f"result is {result}")                     # hopefully, this is 200
print(f"the full url used was\n {result.url}")   # this will include the parameters!


# if it worked, we should be able to see the json results:

d = result.json()
print(f"json returned was {d = }")


#
# that's hard to read!
# let's pretty-print it with the json library
#       also, this version can be pasted into online formatters, e.g., https://jsonformatter.org/

import json 
nice_string = json.dumps(d)   # this outputs a "nicely formatted string" using double quotes
print(nice_string)




import json 
nicer_string = json.dumps(d, indent=4)   # we can specify the indentation. 
print(nicer_string)                      # it's another tree structure... !


#
# hw2: iss tasks 1 and 2 ...
# 
# two functions:  iss_now(), iss_distance()

#
# use the iss examples above to write a function, named 
#     
#      iss_now()
#
# that uses requests to return the current latitude and longitude -- as floating-point values -- right now.
# be sure to test it! 

import requests

def iss_now():
    url = "http://api.open-notify.org/iss-now.json"   # this is sometimes called an "endpoint" ...
    result = requests.get(url)
    result    
    json_contents = result.json()
    long1 = float(json_contents['iss_position']['longitude'])
    lat1 = float(json_contents['iss_position']['latitude'])
    return long1, lat1

iss_now()


# 
# once your iss_now() function is working, write a new function
#
#       iss_distance()
#
# which uses iss_now to obtain the lat/cs35_participant_2 of the iss and then
# uses the haversine distance (look up a python implementation or use one of ours... :)
# to compute the iss's distance from a city of your choice.
#
# the haversine distance computes the "great circle" distance from two points on the globe
#     using latitude and longitude  
#
def iss_distance(long2, lat2):
    from math import radians, sin, cos, sqrt, asin  # this import is for the sin, cos, radians
    
    long1, lat1 = iss_now()
    #decimal degrees to radians
    long1, lat1, long2, lat2 = map(radians, [long1, lat1, long2, lat2])


    # haversine formula
    dlong = long2 - long1
    dlat = lat2 - lat1
    trig = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlong/2)**2
    #radius of earth. 3956 for miles. 6371 for km.
    radius = 3956  # miles
    return radius * 2 * asin(sqrt(trig))

iss_distance(34.0967, -117.7198)



#
# open-ended possibility:  
#    (a) create a new function iss_distance(place) that takes in a place name
#    (b) find a service by which you can look up the lat + cs35_participant_2 using the place name
#         (b*)  i'm not sure how to do this - it's exploratory! 
#    (c) then, continue with the previous computation to find the iss distance! :) 
#

# the final problem of this hw2 is to take on _one_ open-ended possibility. 
#     (this iss-themed one is only the first possibility.)
#     others, below, involve earthquakes, or your own choice of api exploration...


#
# hw2: usgs tasks 3 and 4 ...
# 
# two functions:  quake_loop(), quake_compare(place1, place2)

#
# use the usgs (earthquake) examples above to write a function, named 
#     
#      quake_loop()
#
# that uses requests within a loop of your own design in order to
#   + obtain at least 10 distinct, comparable data elements (counts are encouraged; other items ok)
#   + see the assignment page for an example where the looping iterates over the _month_
#
#   + choose your favorite parameter(s) to vary, e.g., magnitude, time, radius, location, etc.
#   + it should collect all of those data elements into a list
#   + and render the list in a neatly formatted chart (f-strings welcome; not required)
#
#   + in addition, include a overall reflection on the results, as well as a comment on additional effort
#     that could expand your results (you need not run it), and any concerns or caveats about the data...
#   + feel free to copy-paste-edit the markdown "reflection-template," above  

import requests
import time


#
# here is an example of using a for-loop with the usgs api
#
import requests
import time


def get_num_quakes(latitude, longitude, month, magnitude, radius):
   """ returns number of earthquakes/month throughout 2024
   """


   url = "https://earthquake.usgs.gov/fdsnws/event/1/count"


   # parameters
   min_mag = magnitude #min magnitude
    #y/m/d
   start_time = f"2024-{month:02d}-01"
   finish_time = f"2024-{month+1:02d}-01"


   # we assemble a dictionary of our parameters, let's name it para_dict
   # there are many more parameters available. the problems below ask you to explore them...
   para_dict = { "format": "geojson",
                        "starttime": start_time,
                        "endtime": finish_time,
                        "minmagnitude": magnitude,
                        "latitude": latitude,
                        "longitude": longitude,
                        "maxradiuskm": radius,
                       }


   # here, we use requests to make the request. the parameters will be added by this api call:
   time.sleep(2)
   result = requests.get(url, params=para_dict)
   # print(f"result is {result}")
   # print(f"the full url used: {result.url}")
   d = result.json()
   number_of_quakes = d['count']
   return number_of_quakes




def quake_loop():
    print(f"{'month':<10} {'mag':<10} {'radius(km)':<12} {'quakes':<10}")
    print("=" * 42)
    loq = []
    latitude = 34.0967
    longitude = -117.7198
    for month in range(1,11):
        magnitude = 1.0 + (month * 0.1)  # margin for error
        radius = 100 + (month * 10)  # increase radius over months
        quake_count = get_num_quakes(latitude, longitude, month, magnitude, radius)

        loq.append((month, round(magnitude, 1), radius, quake_count))
        print(f"{month:<10} {round(magnitude,1):<10} {radius:<12} {quake_count:<10}")
        loq += [result]
    return loq

print(quake_loop())

'''
i choose to use radius and magnitude, slightly increasing both. something interesting included is changing radius rather than the magnitude while counting.
showing this information from the output table on a graph and observing the patterns it follows might provide insight on earthquake data. 
initially the values level out, then dip, and then spike. this tells us that the frequency/magnitude of earthquakes increases with increasing radius. 
we can determine its radius from the data, but it is still to be determined how much more magnitude would be required to match it. 
'''

#found issue in re-running code after looking at it again. won't run an output


# 
# once your quake_loop() function is working, write a new function
#
#       quake_compare(place1, place2)
#
# where place1 should be a 2-element tuple:  (latitude1, longitude1)
# and  place2 should be a 2-element tuple:  (latitude2, longitude2)
#
# and then your function should compare which of the two places is "quakier" (not a real word)
# for a given time span (you choose), and a given strength-of-quakes (you choose), and
# for a specific radius around each of the two places (you choose)
#
# as is clear, there is lots of freedom to design a "comparison of quakiness" -- wonderful!
# feel free to start somewhere, and tune the results.
#
# your function should print the results it finds (in this case, it's not important to return
# and specific value -- though you're encouraged (not required) to create a helper function and 
# then call it twice for the two locations! (that helper function would need a return value!)
#
#

place1 = (34.12, 117.74) #webbs location
place2 = (0.0, 0.0)

def quake_compare(place1, place2):
    start_time = "2024-01-01"
    end_time = "2024-12-31"
    magnitude = 1  
    radius = 300

    lat1, long1 = place1
    lat2, long2 = place2

    quakesuno = get_num_quakes(lat1, long1, 1, magnitude, radius)
    quakesdos = get_num_quakes(lat2, long2, 1, magnitude, radius)

    if quakesuno > quakesdos:
        print(f"place 1 ({lat1}, {long1}) is quakier")
    elif quakesdos > quakesuno:
        print(f"place 2 ({lat2}, {long2}) is quakier")
    elif quakesuno == quakesdos:
        print("both places are equally quaky")
    else:
        print("error")

quake_compare(place1, place2)

#ran into same issue as the previous, unable to run code


#
# cells for your own api experimentations + results!
#

import requests

# get weather data
def get_weather(city):
    api_key = "your_openweather_api_key"
    url = f"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}"
    response = requests.get(url)
    data = response.json()
    if response.status_code == 200:
        weather = data["weather"][0]["main"].lower()
        return weather
    else:
        return none

# get pokémon based on weather
def get_pokemon(weather):
    weather_to_type = {
        "clear": "fire",
        "clouds": "normal",
        "rain": "water",
        "snow": "ice",
        "thunderstorm": "electric",
        "mist": "ghost",
    }
    pokemon_type = weather_to_type.get(weather, "normal")
    
    url = f"https://pokeapi.co/api/v2/type/{pokemon_type}"
    response = requests.get(url)
    data = response.json()
    if response.status_code == 200:
        pokemon_list = [p["pokemon"]["name"] for p in data["pokemon"]]
        return pokemon_list[:5]  # return top 5 pokémon
    else:
        return none

# run the two-hop api calls
city = "los angeles"
weather = get_weather(city)
if weather:
    pokemon = get_pokemon(weather)
    print(f"current weather in {city}: {weather.capitalize()}")
    print(f"recommended pokémon: {', '.join(pokemon) if pokemon else 'no pokémon found'}")
else:
    print("failed to fetch weather data.")


"""
performs a two-hop api task by:
1. getting the current weather for a given city using the openweather api.
2. mapping the weather condition to a corresponding pokémon type.
3. getting a list of pokémon of that type from the pokéapi and displaying recommendations.


- replace 'your_openweather_api_key' with a valid openweather api key.
- set the 'city' variable to the desired location.
- run the program to get weather-based pokémon recommendations.
"""



#re-ran vscode, still having issues in reopening an output cell.


