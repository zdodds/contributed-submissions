{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### cs35 Week5: Reading and response \n",
    "\n",
    "_More data!_   &nbsp;&nbsp; (hw5pr0.ipynb)\n",
    "\n",
    "In fact, can we _generate_ our own?!\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Reading for hw5...     (hw5pr0.ipynb)\n",
    "\n",
    "This week's reading is an [Economist article](https://www.economist.com/technology-quarterly/2020/06/11/for-ai-data-are-harder-to-come-by-than-you-think) (here is a [pdf version](https://drive.google.com/file/d/1tJC3jLjk_ZNzA1UTxREJGqzZg5pg2N24/view)) on the pitfalls and promise of the data-driven era we now inhabit.  \n",
    "\n",
    "The article takes a \"data-based\" view on the developments and concerns in AI. It's from about 5 years ago, and you'll notice that this is a _long_ time ago, AI-wise!\n",
    "\n",
    "One of the more durable ideas in this article is the possibility -- and possible importance -- of ***generating*** data to improve model-training, when available data is inequitable, inflexible, or insufficient in another way. (Amazon Go, on the other hand? [Gone.](https://foodinstitute.com/focus/rise-and-stall-of-amazon-go-illustrates-limits-of-ai/))   \n",
    "\n",
    "Using the article and your own experience, what are <font color=\"Coral\"><b>your thoughts on artificially generating data to assist AI/ML training</b></font>?  Possible jumping-off points include \n",
    "+ (1) echo-chamber effects: &nbsp; Can generated data yield more fairness -- or only reinforce existing biases?, or \n",
    "+ (2) implementation concerns: &nbsp; What process would artificially generate the data?, or \n",
    "+ (3) a specific example you've encountered, &nbsp; where a computational system generated data, but \"got things obviously wrong\" (you may have experiences several of these examples!) \n",
    "\n",
    "In the last case, the automatically-generated data may have made the world's data-landscape worse, not better.  \n",
    "\n",
    "Alternative and additional perspectives about artificially-generated data are more than welcome... &nbsp; .\n",
    "\n",
    "As with each week's reading, responses should be thoughtful, but need not be CS35_Participant_2: a 4-5 sentence paragraph is wonderful.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading response\n",
    "\n",
    "I am concerned with the echo chamber effect when it comes to artificially generating data to assist AI/ML training. In our data driven world today, we tend to hear \"the data tells us [...],\" which is great- insights are now more than ever driven by measurable outcomes. If artificially generated data is modeled only after existing data, there is a danger to reinforcing existing biases. Now we'd say \"the data tell us [...] but the data was only trained on xyz.\" AI/ML training would lack the human sophistication to implement a change into such issues that involve biases. As mentioned in the article, racial discrimination in hiring is the first that comes to mind as I learnt in my Experimental Economics class. \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ccb4bb6bd67730c9185e6c24c983362cd7b4575b595bfae100d8d91e48f4f1e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
