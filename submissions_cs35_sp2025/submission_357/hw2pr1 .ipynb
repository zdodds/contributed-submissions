{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### week2 ~ APIs !\n",
    "\n",
    "<b>that is, _the-web-as-your-filesystem_ ...</b>  &nbsp;&nbsp; (hw2pr1.ipynb)\n",
    "\n",
    "[the google doc with hw2's details](https://docs.google.com/document/d/1z4HwpUL1-ImGX3j-6bddyZAfdv2SkRQHRNhF5Cu3Fkk/edit?tab=t.0)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# computing-styling trick of the day     (or, of the minute...)\n",
    "#\n",
    "# The setting for word-wrapping on the output is\n",
    "#     \"notebook.output.wordWrap\": true,   (in your settings.json file or from Code ... Settings ...) \n",
    "\n",
    "print( list(range(100)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see if you already have the requests library..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import requests\n",
    "# see if we have the requests library...\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# If you _don't_ have the requests library, let's install it!\n",
    "#\n",
    "%pip install requests\n",
    "\n",
    "# for me, it worked to uncomment and run this command, here in this cell:\n",
    "# !pip3 install requests  OR   !pip install requests\n",
    "\n",
    "# an alternative is to run, in a terminal, the command would be \n",
    "#  pip3 install requests  OR    pip install requests      (the ! is needed only if inside Python)\n",
    "\n",
    "# It's very system-dependent how much you have to \"restart\" in order to use\n",
    "# the new library (the notebook, VSCode, the Jupyter extension, etc.)\n",
    "\n",
    "# Troubles?  Let us know!  We'll work on it with you..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# hopefully, this now works! (if so, running will succeed silently)\n",
    "#\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# let's try it on a simple webpage\n",
    "#\n",
    "\n",
    "#\n",
    "# we assign the url and obtain the api-call result into result\n",
    "#    Note that result will be an object that contains many fields (not a simple string)\n",
    "# \n",
    "\n",
    "url = \"https://www.cs.hmc.edu/~dodds/demo.html\"\n",
    "result = requests.get(url)\n",
    "result    \n",
    "\n",
    "# if it succeeded, you should see <Response [200]>\n",
    "# See the list of HTTP reponse codes for the full set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Here is Wikipedia's list of all HTTP response codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "+ 100's: information\n",
    "+ 200's: success           \n",
    "+ 300's: redirects\n",
    "+ 400's + 500's: errors\n",
    "\n",
    "Perhaps familiar:  404 <br>\n",
    "Especially fun:  418\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# when exploring, you'll often obtain an unfamiliar object. \n",
    "# Here, we'll ask what type it is \n",
    "type(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to access the data inside this object, ``result`` ?\n",
    "\n",
    "One way: [Head over to the online documentation](https://requests.readthedocs.io/en/latest/api/#requests.Response)\n",
    "\n",
    "In addition, you can \"look around\" in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.cs.hmc.edu/~dodds/demo.html'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is one of the data members within the result\n",
    "# it \"remembers\" (keeps track of) the url requested:\n",
    "result.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close\n",
      "connection\n",
      "content\n",
      "cookies\n",
      "elapsed\n",
      "encoding\n",
      "headers\n",
      "history\n",
      "json\n",
      "links\n",
      "next\n",
      "ok\n",
      "raw\n",
      "reason\n",
      "request\n",
      "text\n",
      "url\n"
     ]
    }
   ],
   "source": [
    "# We can print all of the data members in an object with dir\n",
    "# Since dir returns a list, we will grab that list and loop over it:\n",
    "all_fields = dir(result)\n",
    "\n",
    "for field in all_fields:\n",
    "    if \"_\" not in field: \n",
    "        print(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result.url         is https://www.cs.hmc.edu/~dodds/demo.html\n",
      "result.raw         is <urllib3.response.HTTPResponse object at 0x1088f60b0>\n",
      "result.encoding    is ISO-8859-1\n",
      "result.status_code is 200\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Let's try printing a few of those fields (data members): \n",
    "print(f\"result.url         is {result.url}\")  # the original url\n",
    "print(f\"result.raw         is {result.raw}\")  # another object!\n",
    "print(f\"result.encoding    is {result.encoding}\")  # utf-8 is very common\n",
    "print(f\"result.status_code is {result.status_code}\")  # 200 is success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "  <head>\n",
      "    <title>My streamlined website</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1> Welcome! </h1>\n",
      "    <h2> The best numbers </h2>\n",
      "\n",
      "    <div id=\"numberlist\">\n",
      "      <ol>\n",
      "\t<li class=\"number\"> 42 </li>\n",
      "\t<li class=\"number\"> 176 </li>\n",
      "\t<li class=\"number\"> <a href=\"https://en.wikipedia.org/wiki/Rayo%27s_number\">Rayo's number</a> </li>\n",
      "      </ol>\n",
      "    </div>\n",
      "\n",
      "    <img src=\"./spam.jpg\" height=\"84px\">\n",
      "    <br><br>\n",
      "\n",
      "    <h2> The <s>best</s> only snacks </h2>\n",
      "\n",
      "    <div id=\"snacklist\">\n",
      "      <ul>\n",
      "\t<li class=\"snack\"> Poptarts </li>\n",
      "\t<li class=\"snack\"> Chocolate Chip Mini Muffins </li>\n",
      "\t<li class=\"snack\"> Coffee </li>\n",
      "      </ul>\n",
      "    </div>\n",
      "\n",
      "<!--    <a href=\"./demo_cat.html\">Aliens <3 cats!</a>  -->\n",
      "\n",
      "    <img src=\"./alien.png\" height=\"101px\">\n",
      "\n",
      "  </body>\n",
      "</html>\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In this case, the result is a text file (HTML) Let's see it!\n",
    "contents = result.text\n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yay!  \n",
    "# This shows that you are able to \"scrape\" an arbitrary HTML page... \n",
    "\n",
    "# Now, we're off to more _structured_ data-gathering..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traversing the world - and web - <i>without a browser</i>.   \n",
    "\n",
    "<b>Using the ISS APIs</b> \n",
    "\n",
    "+ Here, you'll make some calls using `requests` to, first, the International Space Station API \n",
    "+ and, then, the US Geological Survey's earthquake API\n",
    "+ \"API\" is short for \"Application Programming Interface\" \n",
    "  + Admittedly, this is not a very informative name:\n",
    "  + The API is the set of services, which are functions and/or urls, provided by some software or site"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it with the International Space Station api at [http://api.open-notify.org/iss-now.json](http://api.open-notify.org/iss-now.json)\n",
    "+ [This page has documentation on the ISS API](http://open-notify.org/Open-Notify-API/ISS-Location-Now/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# we assign the url and obtain the api-call result into result\n",
    "#    Note that result will be an object that contains many fields (not a simple string)\n",
    "# \n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://api.open-notify.org/iss-now.json\"   # this is sometimes called an \"endpoint\" ...\n",
    "result = requests.get(url)\n",
    "result    \n",
    "\n",
    "# if it succeeds, you should see <Response [200]>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result.url         is http://api.open-notify.org/iss-now.json\n",
      "result.raw         is <urllib3.response.HTTPResponse object at 0x1088f7700>\n",
      "result.encoding    is utf-8\n",
      "result.status_code is 200\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Let's try printing those shorter fields from before:\n",
    "print(f\"result.url         is {result.url}\")  # the original url\n",
    "print(f\"result.raw         is {result.raw}\")  # another object!\n",
    "print(f\"result.encoding    is {result.encoding}\")  # utf-8 is very common\n",
    "print(f\"result.status_code is {result.status_code}\")  # 200 is success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'success', 'iss_position': {'longitude': '150.2934', 'latitude': '27.2946'}, 'timestamp': 1739048913}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# In this case, we know the result is a JSON file, and we can obtain it that way:\n",
    "json_contents = result.json()\n",
    "print(json_contents)\n",
    "\n",
    "# Remember:  json_contents will be a _dictionary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Let's re-remind ourselves how dictionaries work:\n",
    "CS35_Participant_2 = float(json_contents['iss_position']['longitude'])\n",
    "json_contents['message']       # Challenge:  could we access the other components? What _types_ are they?!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['message', 'iss_position', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# In Python, we can use the resulting dictionary... let's see its keys:\n",
    "print(list(json_contents.keys()))  \n",
    "\n",
    "# Also, watch out for string vs. numeric types, e.g., for latitude and longitude.\n",
    "# At heart, _all_ web data are strings... .\n",
    "\n",
    "# These experiments will be helpful for problem 1, below :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"Coral\"><b>Task 0a</b></font>  &nbsp;&nbsp; From here, \n",
    "+ extract the lat and CS35_Participant_2 of the ISS from ``json_contents``  (dictinoary practice!)\n",
    "+ copy the ``haversine`` function from the assignment\n",
    "+ find the lat/CS35_Participant_2 of Claremont (or grab it from the hw page! ðŸ˜Š )\n",
    "+ combine these to find out how far, in miles, the ISS is from Claremont  \n",
    "+ <font size=\"-2\">you could _imagine_ writing a function to do all this (no need to - we'll do it with earthquakes!)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON\n",
    "\n",
    "####  Let's make a brief JSON visit in Python\n",
    "\n",
    "The library ``json`` allows us to create and read arbitrary JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'value', 'fave': 42, 'list': [5, 6, 7, {'mascot': 'Aliiien'}]}\n"
     ]
    }
   ],
   "source": [
    "# JSON is a javascript dictionary format -- almost the same as a Python dictionary:\n",
    "data = { 'key':'value',  'fave':42,  'list':[5,6,7,{'mascot':'Aliiien'}] }\n",
    "print(data)\n",
    "\n",
    "# we can write in JSON format to a local file, named small42.json:\n",
    "import json \n",
    "\n",
    "with open(\"small.json\", \"w\") as f:\n",
    "    json.dump( data, f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dictionary = {'key': 'value', 'fave': 42, 'list': [5, 6, 7, {'mascot': 'Aliiien'}]}\n"
     ]
    }
   ],
   "source": [
    "# We can also read from a json file\n",
    "# The resulting data will be a _dictionary_:\n",
    "\n",
    "with open(\"small.json\", \"r\") as f:\n",
    "    dictionary = json.load( f )\n",
    "\n",
    "print(f\"the {dictionary = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['key', 'fave', 'list']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's access this dictionary -- first, the keys:\n",
    "list(dictionary.keys())   # How do we get 'Aliiien' from newdata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'value'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task: use the dictionary to obtain (a) 'value' , (b) 42 , (c) 'Aliiien'  [tricky!]\n",
    "\n",
    "# remember that there are two ways to get the value from a key:\n",
    "# way 1:  dictionary['key']            # errors if 'key' isn't present\n",
    "# way 2:  dictionary.get('key')        # returns None if 'key' isn't present\n",
    "\n",
    "dictionary['key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time this will be done for us by the ``requests`` library. So, we will simply receive the dictionary of data sent.\n",
    "\n",
    "Then, the trick is to \"extract\" the data fragments we want. (Sometimes it feels like forensics - or archaeology!) Try excavating items one **layer** at a time..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remember: &nbsp; <i>not</i> every url returns json data...\n",
    "+ The url [https://www.cs.hmc.edu/~dodds/demo.html](https://www.cs.hmc.edu/~dodds/demo.html) returns a plain-text file with _markup_ text\n",
    "+ that is to say, with HTML tags, such as `<title>Title</title>` to designate the components of its content\n",
    "+ HTML stands for _hypertext markup language_   \n",
    "+ Often anything with tags similar to `<b>be bold!</b>` is called \"markup.\" \n",
    "\n",
    "Let's try our 5C homepages: they're HTML, not JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "\n",
    "# here, we will obtain plain-text results from a request\n",
    "url = \"https://www.cs.hmc.edu/~dodds/demo.html\"  # try it + source\n",
    "# url = \"https://www.scrippscollege.edu/\"          # another possible site...\n",
    "# url = \"https://www.pitzer.edu/\"                  # another possible site...\n",
    "# url = \"https://www.cmc.edu/\"                     # and another!\n",
    "# url = \"https://www.cgu.edu/\"\n",
    "result = requests.get(url)        \n",
    "print(f\"result is {result}\")        # hopefully it's 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(text) is 763\n",
      "\n",
      "The first 242 characters are\n",
      "\n",
      "<html>\n",
      "  <head>\n",
      "    <title>My streamlined website</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1> Welcome! </h1>\n",
      "    <h2> The best numbers </h2>\n",
      "\n",
      "    <div id=\"numberlist\">\n",
      "      <ol>\n",
      "\t<li class=\"number\"> 42 </li>\n",
      "\t<li class=\"number\"> 176 </li>\n",
      "\t<li class\n"
     ]
    }
   ],
   "source": [
    "# if the request was successful, the Response will be [200]. \n",
    "# Then, we can grab the text - or json - from the site:\n",
    "\n",
    "text = result.text                  # provides the HTML page as a large string...\n",
    "print(f\"len(text) is {len(text)}\")  # let's see how large the HTML page is... \n",
    "\n",
    "print(\"\\nThe first 242 characters are\\n\")\n",
    "print(text[:242])                  # we'll print the first few characters...  \n",
    "\n",
    "# change this to text[:] to see the whole document...\n",
    "# Notice that we can run many different analyses without having to re-call/re-scrape the page (this is good!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declined requests!\n",
    "\n",
    "Caution: <i>See this week's reading!</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For now let's focus on API calls providing JSON \n",
    "+ We're reading-aligned, as we should be!\n",
    "+ The open-ended problem (the finale in this notebook) offers the _option_ of scraping raw html -- up to you...\n",
    "\n",
    "<br>\n",
    "\n",
    "<b>Let's try another ISS \"endpoint\" ~ one with all of the <i>people</i> in space.</b>\n",
    "\n",
    "It's at this url:  [http://api.open-notify.org/astros.json](http://api.open-notify.org/astros.json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# we assign the url and use requests.get to obtain the result into result_astro\n",
    "#\n",
    "#    Remember, result_astro will be an object that contains many fields (not a simple string)\n",
    "# \n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://api.open-notify.org/astros.json\"   # this is sometimes called an \"endpoint\" ...\n",
    "result_astro = requests.get(url)\n",
    "result_astro\n",
    "\n",
    "# if it succeeded, you should see <Response [200]>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': [{'craft': 'ISS', 'name': 'Oleg Kononenko'}, {'craft': 'ISS', 'name': 'Nikolai Chub'}, {'craft': 'ISS', 'name': 'Tracy Caldwell Dyson'}, {'craft': 'ISS', 'name': 'Matthew Dominick'}, {'craft': 'ISS', 'name': 'Michael Barratt'}, {'craft': 'ISS', 'name': 'Jeanette Epps'}, {'craft': 'ISS', 'name': 'Alexander Grebenkin'}, {'craft': 'ISS', 'name': 'Butch Wilmore'}, {'craft': 'ISS', 'name': 'Sunita Williams'}, {'craft': 'Tiangong', 'name': 'Li Guangsu'}, {'craft': 'Tiangong', 'name': 'Li Cong'}, {'craft': 'Tiangong', 'name': 'Ye Guangfu'}], 'number': 12, 'message': 'success'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the request succeeded, we know the result is a JSON file, and we can obtain it that way.\n",
    "# Let's call our dictionary something more specific:\n",
    "\n",
    "astronauts = result_astro.json()\n",
    "print(astronauts)\n",
    "d = astronauts     # d is shorter to type\n",
    "\n",
    "# Remember:  d and astronauts will be a _dictionary_\n",
    "\n",
    "note = \"\"\" here's yesterday's result - it _should_ be the same today!\n",
    "\n",
    "{\"people\": [{\"craft\": \"ISS\", \"name\": \"Oleg Kononenko\"}, {\"craft\": \"ISS\", \"name\": \"Nikolai Chub\"},\n",
    "{\"craft\": \"ISS\", \"name\": \"Tracy Caldwell Dyson\"}, {\"craft\": \"ISS\", \"name\": \"Matthew Dominick\"},\n",
    "{\"craft\": \"ISS\", \"name\": \"Michael Barratt\"}, {\"craft\": \"ISS\", \"name\": \"Jeanette Epps\"},\n",
    "{\"craft\": \"ISS\", \"name\": \"Alexander Grebenkin\"}, {\"craft\": \"ISS\", \"name\": \"Butch Wilmore\"},\n",
    "{\"craft\": \"ISS\", \"name\": \"Sunita Williams\"}, {\"craft\": \"Tiangong\", \"name\": \"Li Guangsu\"},\n",
    "{\"craft\": \"Tiangong\", \"name\": \"Li Cong\"}, {\"craft\": \"Tiangong\", \"name\": \"Ye Guangfu\"}], \"number\": 12, \"message\": \"success\"}\n",
    "\"\"\"\n",
    "\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty intricate. Let's try unpacking this - _parsing it_ - with an in-class break-out challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Cell to try out parsing d  (astronauts)\n",
    "#\n",
    "\n",
    "d['people'][0]['name'][7:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare with a whole other webservice: **earthquakes** \n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "#### Earthquake data\n",
    "\n",
    "[Here is the USGS Earthquate data API documentation](https://earthquake.usgs.gov/fdsnws/event/1/)\n",
    "\n",
    "Notice that the \"headline\" is the URL: &nbsp; This is the <i>domain</i> from which we'll access data.\n",
    "+ Underneath, there are several different <i>endpoints</i> \n",
    "+ We are going to focus on the <tt>count</tt> endpoint and the <tt>query</tt> endpoint\n",
    "+ along with their parameters\n",
    "  + the whole list of parameters is linked and available by scrolling down\n",
    "  + that said, it's easy to miss (well, at least I did! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's establish that, for these endpoints, we can make requests - by hand - in our browser!\n",
    "\n",
    "Try this link: <br><br>  [https://earthquake.usgs.gov/fdsnws/event/1/count?format=geojson&minmagnitude=5.0&starttime=2024-01-01&endtime=2024-02-01](https://earthquake.usgs.gov/fdsnws/event/1/count?format=geojson&minmagnitude=5.0&starttime=2024-01-01&endtime=2024-02-01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! Let's parse this url. Requests in which there are parameters <i><b>in the url</b></i> are called GET requests:\n",
    "+ the <b>endpoint</b> is the first part: ``https://earthquake.usgs.gov/fdsnws/event/1/count``\n",
    "   + Notice that the forward-slashes are very much like our file-system trees from last week!\n",
    "   + In fact, they usually <i>are</i> file-system trees. They're just on the <i>server</i> side, instead of our \"client\" side...\n",
    "+ the <b>parameters</b> follow the question mark: ``format=geojson&minmagnitude=5.0&starttime=2024-01-01&endtime=2024-02-01``\n",
    "   + There are four parameters here. Parameters are separated by the ampersand <tt>&amp;</tt> character.\n",
    "   + Each one is in the format <tt>name=value</tt>  Here are the four:\n",
    "   + ``format=geojson`` specifies the desired format of the returned data. ``geojson`` is JSON with geographic data.\n",
    "   + ``minmagnitude=5.0`` specifies the minimum magnitude of earthquakes to consider. 5.0 is strong, if not always catastrophic.\n",
    "   + ``starttime=2024-01-01`` specifies the earlier time-endpoint to consider. (Jan 1, 2024)\n",
    "   + ``endtime=2024-02-01`` specifies the later time-endpoint to consider. (Feb 1, 2024)\n",
    "\n",
    "My result was this:  ``{\"count\":134,\"maxAllowed\":20000}``\n",
    "+ Earthquakes are always happening -- and they do get reclassified. So, the numbers can change - even in the past.\n",
    "\n",
    "Try it, in your browser.\n",
    "\n",
    "Also, try increasing the ``minmagnitude`` -- you'll see a progression of fewer and fewer quakes. (Fortunately!) \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, try it using a short Python script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is <Response [200]>\n",
      "the full url used was\n",
      " https://earthquake.usgs.gov/fdsnws/event/1/count?format=geojson&minmagnitude=5.0&starttime=2024-01-01&endtime=2024-02-01\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Let's try the  count  endpoint, with geojson format (json with geographical data)\n",
    "#\n",
    "\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/count?format=geojson&minmagnitude=5.0&starttime=2024-01-01&endtime=2024-02-01\"\n",
    "\n",
    "result = requests.get(url)                       # a named input, params, taking the value param_d, above\n",
    "print(f\"result is {result}\")                     # hopefully, this is 200\n",
    "print(f\"the full url used was\\n {result.url}\")   # it's nice to be able to see this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d ={'count': 133, 'maxAllowed': 20000}\n"
     ]
    }
   ],
   "source": [
    "# If it worked, we should be able to obtain the JSON. Remember, it's a dictionary. Let's use d:\n",
    "\n",
    "d = result.json()\n",
    "\n",
    "print(f\"{d =}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling parameters separately...\n",
    "\n",
    "It's awkward to include all the parameters as part of the url.\n",
    "\n",
    "It's much more common to create a <i>dictionary</i> of the parameters, and then pass that to ``requests.get``\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is <Response [200]>\n",
      "the full url used was\n",
      " https://earthquake.usgs.gov/fdsnws/event/1/count?format=geojson&starttime=2025-01-01&endtime=2025-02-01&minmagnitude=5.0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Here is the endpoint\n",
    "#\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/count\"\n",
    "\n",
    "# Let's use variables for three of the parameters:\n",
    "min_mag = 5.0               # the minimum magnitude considered a quake (min_mag)\n",
    "start_time = \"2025-01-01\"   # this is the year-month-day format of the start\n",
    "finish_time = \"2025-02-01\"  # similar for the end\n",
    "\n",
    "# we assemble a dictionary of our parameters, let's name it param_dictionary\n",
    "# there are many more parameters available. The problems below ask you to explore them...\n",
    "param_dictionary = { \"format\":\"geojson\",         # this is simply hard-coded to obtain json\n",
    "                     \"starttime\":start_time,\n",
    "                     \"endtime\":finish_time,\n",
    "                     \"minmagnitude\":min_mag,\n",
    "                     }\n",
    "\n",
    "# Here, we use requests to make the request. The parameters will be added by this API call:\n",
    "result = requests.get(url, params=param_dictionary)\n",
    "print(f\"result is {result}\")                     # hopefully, this is 200\n",
    "print(f\"the full url used was\\n {result.url}\")   # this will include the parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON returned was d = {'count': 133, 'maxAllowed': 20000}\n"
     ]
    }
   ],
   "source": [
    "# If it worked, we should be able to see the json results:\n",
    "\n",
    "d = result.json()\n",
    "print(f\"JSON returned was {d = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, it would be possible to write one or more loops and build an earthquake dataset. For example,\n",
    "+ it would be possible to loop over the ``minmagnitude`` to get a distribution of different sized quakes (or a histogram)\n",
    "+ it would be possible to loop over one of the <i>time-endpoints</i>\n",
    "+ it would be possible to loop over one of the _other parameters_ e.g.,\n",
    "  + you can specify a circle around a specific ``latitude`` and ``longitude`` with a ``maxradiuskm`` (the radius)\n",
    "  + Claremont is at ``latitude=34.0967`` and ``longitude=-117.7198`` \n",
    "\n",
    "The next two cells have an example of a Claremont-centric quake-count question and answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is <Response [200]>\n",
      "the full url used was\n",
      " https://earthquake.usgs.gov/fdsnws/event/1/count?format=geojson&starttime=2025-01-01&endtime=2025-02-01&minmagnitude=4.2&latitude=34.0967&longitude=-117.7198&maxradiuskm=300\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# How many quakes of magnitude >= 4.2 have been within 300km of Claremont \n",
    "#     + in Jan 2025\n",
    "#     + in Dec 2025\n",
    "#\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/count\"\n",
    "\n",
    "# Let's use variables for three of the parameters:\n",
    "min_mag = 4.2               # the minimum magnitude considered a quake (min_mag)\n",
    "start_time = \"2025-01-01\"   # this is the year-month-day format of the start\n",
    "finish_time = \"2025-02-01\"  # similar for the end\n",
    "# start_time = \"2024-01-01\"   # similar, but for a year-CS35_Participant_2 span...\n",
    "# finish_time = \"2025-01-01\"  # similar for the end\n",
    "radius_in_km = 300\n",
    "\n",
    "# we assemble a dictionary of our parameters, let's name it param_dictionary\n",
    "# there are many more parameters available. The problems below ask you to explore them...\n",
    "param_dictionary = { \"format\":\"geojson\",         # this is simply hard-coded to obtain json\n",
    "                     \"starttime\":start_time,\n",
    "                     \"endtime\":finish_time,\n",
    "                     \"minmagnitude\":min_mag,\n",
    "                     \"latitude\":34.0967,\n",
    "                     \"longitude\":-117.7198,\n",
    "                     \"maxradiuskm\":radius_in_km,\n",
    "                     }\n",
    "\n",
    "# Here, we use requests to make the request. The parameters will be added by this API call:\n",
    "result = requests.get(url, params=param_dictionary)\n",
    "print(f\"result is {result}\")                     # hopefully, this is 200\n",
    "print(f\"the full url used was\\n {result.url}\")   # this will include the parameters!\n",
    "\n",
    "# We'll extract the final result in another cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quake_count = {'count': 133, 'maxAllowed': 20000}\n"
     ]
    }
   ],
   "source": [
    "# Let's finish up here:\n",
    "quake_count = result.json()\n",
    "print(f\"{quake_count = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"Coral\"><b>Try this, task \"0b\"</b></font>  &nbsp;&nbsp; \n",
    "+ Would you expect more or fewer quakes if a minimum magnitude of 2.2 were used?\n",
    "+ Try the above cells again for a minimum magnitude of 2.2 -- if that the difference you'd expect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"DodgerBlue\"><b>Quake-counting Results:</b></font> \n",
    "\n",
    "#### Number of Claremont-centric quakes\n",
    "  + <u>Overall</u> The API calls to the USGS showed that, within 300km of Claremont, there were\n",
    "    + 1 quake of magnitude 4.2 or larger within 300km of Claremont in Jan '25\n",
    "    + more quakes  of magitude 2.2 or larger within 300km of Claremont in Jan '25 <br><br>\n",
    "  + <u>Reflection</u>: _This is not enough data to establish a trend. (I hope!)_ That said, for the hw, you should include a **loop** over at least 10 values, as well as a text-formatted set of values. (It's ok for the output values to be in the computational cell(s), not the markdown cell. The markdown is really for reflection on results than reporting of results.) <br><br>\n",
    "  + <u>Opportunities</u>: In fact, there are lots of values over which the USGS API allows to vary. For example,  minmagnitude (or maxmagnitude), radius, location (lat/CS35_Participant_2), months (or other time-measurements) - and others. In addition, there is the chance to look at the details of each quake using the ``query`` endpoint. <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping over API calls to gather data will be one of the hw problems.\n",
    "\n",
    "<hr>\n",
    "\n",
    "#### The ``query`` endpoint\n",
    "\n",
    "Let's see, too, that it's possible to obtain, not only a <i>count</i>, but also a <b>\"full report\"</b> of all of the earthquakes.\n",
    "\n",
    "To do so, the only change needed is from the endpoint ``count`` to the endpoint ``query``\n",
    "\n",
    "First, try it \"by hand\" -- by opening this url in your browser:\n",
    "\n",
    "[https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&minmagnitude=6.8&starttime=2024-01-01&endtime=2024-02-01](https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&minmagnitude=6.8&starttime=2024-01-01&endtime=2024-02-01)\n",
    "\n",
    "Take a look -- there is a lot more data!  \n",
    "\n",
    "Next, let's try it programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is <Response [200]>\n",
      "the full url used was\n",
      " https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime=2025-01-01&endtime=2025-02-01&minmagnitude=6.5\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Here is the endpoint\n",
    "#\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "\n",
    "# Let's use variables for three of the parameters:\n",
    "min_mag = 6.5               # the minimum magnitude considered a quake (min_mag)\n",
    "start_time = \"2025-01-01\"   # this is the year-month-day format of the start\n",
    "finish_time = \"2025-02-01\"  # similar for the end\n",
    "\n",
    "# we assemble a dictionary of our parameters, let's name it param_dictionary\n",
    "# there are many more parameters available. The problems below ask you to explore them...\n",
    "param_dictionary = { \"format\":\"geojson\",         # this is simply hard-coded to obtain json\n",
    "                     \"starttime\":start_time,\n",
    "                     \"endtime\":finish_time,\n",
    "                     \"minmagnitude\":min_mag,\n",
    "                     }\n",
    "\n",
    "# Here, we use requests to make the request. The parameters will be added by this API call:\n",
    "result = requests.get(url, params=param_dictionary)\n",
    "print(f\"result is {result}\")                     # hopefully, this is 200\n",
    "print(f\"the full url used was\\n {result.url}\")   # this will include the parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON returned was d = {'type': 'FeatureCollection', 'metadata': {'generated': 1738817075000, 'url': 'https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime=2025-01-01&endtime=2025-02-01&minmagnitude=6.5', 'title': 'USGS Earthquakes', 'status': 200, 'api': '1.14.1', 'count': 2}, 'features': [{'type': 'Feature', 'properties': {'mag': 6.8, 'place': '12 km ESE of Miyazaki, Japan', 'time': 1736770772300, 'updated': 1738679872023, 'tz': None, 'url': 'https://earthquake.usgs.gov/earthquakes/eventpage/us6000pjny', 'detail': 'https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=us6000pjny&format=geojson', 'felt': 35, 'cdi': 8.5, 'mmi': 6.206, 'alert': 'green', 'status': 'reviewed', 'tsunami': 1, 'sig': 741, 'net': 'us', 'code': '6000pjny', 'ids': ',at00sq10wm,pt25013000,us6000pjny,usauto6000pjny,', 'sources': ',at,pt,us,usauto,', 'types': ',dyfi,ground-failure,impact-link,impact-text,internal-moment-tensor,internal-origin,losspager,moment-tensor,origin,phase-data,shakemap,', 'nst': 151, 'dmin': 0.98, 'rms': 0.99, 'gap': 18, 'magType': 'mww', 'type': 'earthquake', 'title': 'M 6.8 - 12 km ESE of Miyazaki, Japan'}, 'geometry': {'type': 'Point', 'coordinates': [131.53, 31.8525, 39]}, 'id': 'us6000pjny'}, {'type': 'Feature', 'properties': {'mag': 7.1, 'place': '2025 Southern Tibetan Plateau Earthquake', 'time': 1736211916716, 'updated': 1738121358298, 'tz': None, 'url': 'https://earthquake.usgs.gov/earthquakes/eventpage/us6000pi9w', 'detail': 'https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=us6000pi9w&format=geojson', 'felt': 864, 'cdi': 9.1, 'mmi': 9.212, 'alert': 'red', 'status': 'reviewed', 'tsunami': 0, 'sig': 2786, 'net': 'us', 'code': '6000pi9w', 'ids': ',us6000pi9w,usauto6000pi9w,pt25007000,', 'sources': ',us,usauto,pt,', 'types': ',dyfi,earthquake-name,finite-fault,general-text,ground-failure,impact-text,internal-moment-tensor,internal-origin,losspager,moment-tensor,origin,phase-data,shakemap,', 'nst': 315, 'dmin': 3.47, 'rms': 0.57, 'gap': 17, 'magType': 'mww', 'type': 'earthquake', 'title': 'M 7.1 - 2025 Southern Tibetan Plateau Earthquake'}, 'geometry': {'type': 'Point', 'coordinates': [87.375, 28.5733, 10]}, 'id': 'us6000pi9w'}], 'bbox': [87.375, 28.5733, 10, 131.53, 31.8525, 39]}\n"
     ]
    }
   ],
   "source": [
    "# If it worked, we should be able to see the json results:\n",
    "\n",
    "d = result.json()\n",
    "print(f\"JSON returned was {d = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"type\": \"FeatureCollection\", \"metadata\": {\"generated\": 1738817075000, \"url\": \"https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime=2025-01-01&endtime=2025-02-01&minmagnitude=6.5\", \"title\": \"USGS Earthquakes\", \"status\": 200, \"api\": \"1.14.1\", \"count\": 2}, \"features\": [{\"type\": \"Feature\", \"properties\": {\"mag\": 6.8, \"place\": \"12 km ESE of Miyazaki, Japan\", \"time\": 1736770772300, \"updated\": 1738679872023, \"tz\": null, \"url\": \"https://earthquake.usgs.gov/earthquakes/eventpage/us6000pjny\", \"detail\": \"https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=us6000pjny&format=geojson\", \"felt\": 35, \"cdi\": 8.5, \"mmi\": 6.206, \"alert\": \"green\", \"status\": \"reviewed\", \"tsunami\": 1, \"sig\": 741, \"net\": \"us\", \"code\": \"6000pjny\", \"ids\": \",at00sq10wm,pt25013000,us6000pjny,usauto6000pjny,\", \"sources\": \",at,pt,us,usauto,\", \"types\": \",dyfi,ground-failure,impact-link,impact-text,internal-moment-tensor,internal-origin,losspager,moment-tensor,origin,phase-data,shakemap,\", \"nst\": 151, \"dmin\": 0.98, \"rms\": 0.99, \"gap\": 18, \"magType\": \"mww\", \"type\": \"earthquake\", \"title\": \"M 6.8 - 12 km ESE of Miyazaki, Japan\"}, \"geometry\": {\"type\": \"Point\", \"coordinates\": [131.53, 31.8525, 39]}, \"id\": \"us6000pjny\"}, {\"type\": \"Feature\", \"properties\": {\"mag\": 7.1, \"place\": \"2025 Southern Tibetan Plateau Earthquake\", \"time\": 1736211916716, \"updated\": 1738121358298, \"tz\": null, \"url\": \"https://earthquake.usgs.gov/earthquakes/eventpage/us6000pi9w\", \"detail\": \"https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=us6000pi9w&format=geojson\", \"felt\": 864, \"cdi\": 9.1, \"mmi\": 9.212, \"alert\": \"red\", \"status\": \"reviewed\", \"tsunami\": 0, \"sig\": 2786, \"net\": \"us\", \"code\": \"6000pi9w\", \"ids\": \",us6000pi9w,usauto6000pi9w,pt25007000,\", \"sources\": \",us,usauto,pt,\", \"types\": \",dyfi,earthquake-name,finite-fault,general-text,ground-failure,impact-text,internal-moment-tensor,internal-origin,losspager,moment-tensor,origin,phase-data,shakemap,\", \"nst\": 315, \"dmin\": 3.47, \"rms\": 0.57, \"gap\": 17, \"magType\": \"mww\", \"type\": \"earthquake\", \"title\": \"M 7.1 - 2025 Southern Tibetan Plateau Earthquake\"}, \"geometry\": {\"type\": \"Point\", \"coordinates\": [87.375, 28.5733, 10]}, \"id\": \"us6000pi9w\"}], \"bbox\": [87.375, 28.5733, 10, 131.53, 31.8525, 39]}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# That's hard to read!\n",
    "# Let's pretty-print it with the json library\n",
    "#       Also, this version can be pasted into online formatters, e.g., https://jsonformatter.org/\n",
    "\n",
    "import json \n",
    "nice_string = json.dumps(d)   # this outputs a \"nicely formatted string\" using double quotes\n",
    "print(nice_string)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but, we can do better! \n",
    "\n",
    "the \"dump string\" function, json.dumps, can output the formatted version, too...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"type\": \"FeatureCollection\",\n",
      "    \"metadata\": {\n",
      "        \"generated\": 1738817075000,\n",
      "        \"url\": \"https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime=2025-01-01&endtime=2025-02-01&minmagnitude=6.5\",\n",
      "        \"title\": \"USGS Earthquakes\",\n",
      "        \"status\": 200,\n",
      "        \"api\": \"1.14.1\",\n",
      "        \"count\": 2\n",
      "    },\n",
      "    \"features\": [\n",
      "        {\n",
      "            \"type\": \"Feature\",\n",
      "            \"properties\": {\n",
      "                \"mag\": 6.8,\n",
      "                \"place\": \"12 km ESE of Miyazaki, Japan\",\n",
      "                \"time\": 1736770772300,\n",
      "                \"updated\": 1738679872023,\n",
      "                \"tz\": null,\n",
      "                \"url\": \"https://earthquake.usgs.gov/earthquakes/eventpage/us6000pjny\",\n",
      "                \"detail\": \"https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=us6000pjny&format=geojson\",\n",
      "                \"felt\": 35,\n",
      "                \"cdi\": 8.5,\n",
      "                \"mmi\": 6.206,\n",
      "                \"alert\": \"green\",\n",
      "                \"status\": \"reviewed\",\n",
      "                \"tsunami\": 1,\n",
      "                \"sig\": 741,\n",
      "                \"net\": \"us\",\n",
      "                \"code\": \"6000pjny\",\n",
      "                \"ids\": \",at00sq10wm,pt25013000,us6000pjny,usauto6000pjny,\",\n",
      "                \"sources\": \",at,pt,us,usauto,\",\n",
      "                \"types\": \",dyfi,ground-failure,impact-link,impact-text,internal-moment-tensor,internal-origin,losspager,moment-tensor,origin,phase-data,shakemap,\",\n",
      "                \"nst\": 151,\n",
      "                \"dmin\": 0.98,\n",
      "                \"rms\": 0.99,\n",
      "                \"gap\": 18,\n",
      "                \"magType\": \"mww\",\n",
      "                \"type\": \"earthquake\",\n",
      "                \"title\": \"M 6.8 - 12 km ESE of Miyazaki, Japan\"\n",
      "            },\n",
      "            \"geometry\": {\n",
      "                \"type\": \"Point\",\n",
      "                \"coordinates\": [\n",
      "                    131.53,\n",
      "                    31.8525,\n",
      "                    39\n",
      "                ]\n",
      "            },\n",
      "            \"id\": \"us6000pjny\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"Feature\",\n",
      "            \"properties\": {\n",
      "                \"mag\": 7.1,\n",
      "                \"place\": \"2025 Southern Tibetan Plateau Earthquake\",\n",
      "                \"time\": 1736211916716,\n",
      "                \"updated\": 1738121358298,\n",
      "                \"tz\": null,\n",
      "                \"url\": \"https://earthquake.usgs.gov/earthquakes/eventpage/us6000pi9w\",\n",
      "                \"detail\": \"https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=us6000pi9w&format=geojson\",\n",
      "                \"felt\": 864,\n",
      "                \"cdi\": 9.1,\n",
      "                \"mmi\": 9.212,\n",
      "                \"alert\": \"red\",\n",
      "                \"status\": \"reviewed\",\n",
      "                \"tsunami\": 0,\n",
      "                \"sig\": 2786,\n",
      "                \"net\": \"us\",\n",
      "                \"code\": \"6000pi9w\",\n",
      "                \"ids\": \",us6000pi9w,usauto6000pi9w,pt25007000,\",\n",
      "                \"sources\": \",us,usauto,pt,\",\n",
      "                \"types\": \",dyfi,earthquake-name,finite-fault,general-text,ground-failure,impact-text,internal-moment-tensor,internal-origin,losspager,moment-tensor,origin,phase-data,shakemap,\",\n",
      "                \"nst\": 315,\n",
      "                \"dmin\": 3.47,\n",
      "                \"rms\": 0.57,\n",
      "                \"gap\": 17,\n",
      "                \"magType\": \"mww\",\n",
      "                \"type\": \"earthquake\",\n",
      "                \"title\": \"M 7.1 - 2025 Southern Tibetan Plateau Earthquake\"\n",
      "            },\n",
      "            \"geometry\": {\n",
      "                \"type\": \"Point\",\n",
      "                \"coordinates\": [\n",
      "                    87.375,\n",
      "                    28.5733,\n",
      "                    10\n",
      "                ]\n",
      "            },\n",
      "            \"id\": \"us6000pi9w\"\n",
      "        }\n",
      "    ],\n",
      "    \"bbox\": [\n",
      "        87.375,\n",
      "        28.5733,\n",
      "        10,\n",
      "        131.53,\n",
      "        31.8525,\n",
      "        39\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "nicer_string = json.dumps(d, indent=4)   # We can specify the indentation. \n",
    "print(nicer_string)                      # It's another tree structure... !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"Coral\"><b>Try this, also for Task 0b</b></font>  &nbsp;&nbsp; \n",
    "+ Look through the response to find where and when the largest eathquake was, in the previous year\n",
    "+ What was its magnitude?\n",
    "+ (optional) Do you see a way that - just by making small changes and re-running - you could find the second-biggest quake of '24?  Perhaps try it...  ðŸ¦”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest Earthquake in 2024:\n",
      "  - Magnitude: 7.5\n",
      "  - Location: 2024 Noto Peninsula, Japan Earthquake\n",
      "  - Time (Timestamp): 1704093009476\n"
     ]
    }
   ],
   "source": [
    "# API endpoint\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "\n",
    "# Query parameters for the entire year of 2024\n",
    "params = {\n",
    "    \"format\": \"geojson\",  # Get data in JSON format\n",
    "    \"starttime\": \"2024-01-01\",\n",
    "    \"endtime\": \"2024-12-31\",\n",
    "    \"minmagnitude\": 5.0,  # Get only significant earthquakes\n",
    "    \"limit\": 1000,  # Get a large dataset\n",
    "    \"orderby\": \"magnitude\"  # Order results by magnitude (largest first)\n",
    "}\n",
    "\n",
    "# Make API request\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()  # Convert response to JSON format\n",
    "    earthquakes = data.get(\"features\", [])\n",
    "\n",
    "    if earthquakes:\n",
    "        # Find the largest earthquake\n",
    "        largest_quake = max(earthquakes, key=lambda eq: eq[\"properties\"][\"mag\"])\n",
    "        largest_info = {\n",
    "            \"Magnitude\": largest_quake[\"properties\"][\"mag\"],\n",
    "            \"Location\": largest_quake[\"properties\"][\"place\"],\n",
    "            \"Time (UTC)\": largest_quake[\"properties\"][\"time\"]\n",
    "        }\n",
    "        \n",
    "        print(\"Largest Earthquake in 2024:\")\n",
    "        print(f\"  - Magnitude: {largest_info['Magnitude']}\")\n",
    "        print(f\"  - Location: {largest_info['Location']}\")\n",
    "        print(f\"  - Time (Timestamp): {largest_info['Time (UTC)']}\")\n",
    "\n",
    "    else:\n",
    "        print(\"No significant earthquakes found in 2024.\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "#### Launching into hw2's challenges:\n",
    "+ <font color=\"Coral\"><b>Tasks1-2</b></font> &nbsp;&nbsp; ISS challenges:\n",
    "  + ``ISS_now()`` which will find and return the ISS's lat/CS35_Participant_2 (as floats)\n",
    "    + use the earlier examples as a starting point...\n",
    "  + ``ISS_distance()`` which will return the distance of the ISS from a city of your choice (a constant city, not a variable). It can be Claremont, but doesn't have to be. This will require using the <i>haversine</i> distance for global lat/CS35_Participant_2 coordinates...\n",
    "+ <font color=\"Coral\"><b>Tasks3-4</b></font> &nbsp;&nbsp; Earthquake challenges:\n",
    "  + ``Quake_loop()`` which will loop over a parameter of your choice, print a formatted list of quake-count data, and return that list\n",
    "  + ``Quake_compare(place1, place2)`` which will ask - and answer - a comparative question about \"quakiness\" for two different places, using the quake data... \n",
    "    + Here, the goal is to define which of the two places is \"quakiest.\"\n",
    "    + Notice that the definition of \"quakiest\" is up to you...\n",
    "    + The inputs, place1 and place2, can be lat/CS35_Participant_2 pairs - or strings, which then get looked up...\n",
    "\n",
    "<br>\n",
    "\n",
    "#### <font color=\"Coral\"><b>Task5</b></font> &nbsp;&nbsp; Open-ended, two-hop challenge\n",
    "\n",
    "Then, you'll choose or create an open-ended API task -- or create a variant of your own design from at least two APIs - or \"scrapes\" - of your choice.\n",
    "+ The key constraint is to be sure you meaningfully use the  <font color=\"DodgerBlue\">result</font>  from the first API call in order to customize the request of the second API call.\n",
    "+ Then, with the result of that second API call, interpret the data obtained to make a final \"statement\" -- which can be anywhere amid serious, silly, surreal -- that combines the two API insights.\n",
    "+ See below for a far-fetched superbowl-themed idea...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat = '-30.3520' and CS35_Participant_2 = '-13.8789'\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# hw2: ISS tasks 1 and 2 ...\n",
    "# \n",
    "# Two functions:  ISS_now(), ISS_distance()\n",
    "\n",
    "#\n",
    "# Use the ISS examples above to write a function, named \n",
    "#     \n",
    "#      ISS_now()\n",
    "#\n",
    "# that uses requests to return the current latitude and longitude -- as floating-point values -- right now.\n",
    "# Be sure to test it! \n",
    "\n",
    "from math import radians, sin, cos, sqrt, asin\n",
    "import requests\n",
    "\n",
    "def ISS_now():\n",
    "    \"\"\" get the ISS current location and return lat CS35_Participant_2! \"\"\"\n",
    "    url = \"http://api.open-notify.org/iss-now.json\" \n",
    "    result = requests.get(url)  \n",
    "    json_contents = result.json()\n",
    "    CS35_Participant_2 = json_contents['iss_position']['longitude']\n",
    "    lat = json_contents['iss_position']['latitude']\n",
    "    return lat,CS35_Participant_2\n",
    "\n",
    "lat, CS35_Participant_2 = ISS_now()\n",
    "print(f\"{lat = } and {CS35_Participant_2 = }\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to create some new cells around this area to write and test ``ISS_now()`` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between Claremont and ISS: 8117.348056935208\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Once your ISS_now() function is working, write a new function\n",
    "#\n",
    "#       ISS_distance()\n",
    "#\n",
    "# which uses ISS_now to obtain the lat/CS35_Participant_2 of the ISS and then\n",
    "# uses the haversine distance (look up a Python implementation or use one of ours... :)\n",
    "# to compute the ISS's distance from a city of your choice.\n",
    "#\n",
    "# The haversine distance computes the \"great circle\" distance from two points on the globe\n",
    "#     using latitude and longitude  \n",
    "# lat and CS35_Participant_2 of Claremont and ISS\n",
    "def haversine(lat1, long1, lat2, long2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance in kilometers between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians\n",
    "    lat1, long1, lat2, long2 = map(float, [lat1, long1, lat2, long2])\n",
    "    long1, lat1, long2, lat2 = map(radians, [long1, lat1, long2, lat2])\n",
    "\n",
    "    # haversine formula\n",
    "    dlong = long2 - long1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlong/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    # Radius of earth. Use 3956 for miles. 6371 for km.\n",
    "    r = 3956\n",
    "    return c * r\n",
    "\n",
    "def ISS_distance():\n",
    "    lat_C = 34.097\n",
    "    long_C = -117.719\n",
    "    lat_ISS , long_ISS = ISS_now()\n",
    "    result = haversine(lat_C, long_C, lat_ISS, long_ISS)\n",
    "    return result \n",
    "\n",
    "print(f\"Distance between Claremont and ISS: {ISS_distance()}\")\n",
    "\n",
    "#print(ISS_distance())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to create some new cells around this area to write and test ``ISS_distance()`` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Open-ended possibility:  \n",
    "#    (a) create a new function ISS_distance(place) that takes in a place name\n",
    "#    (b) find a service by which you can look up the lat + CS35_Participant_2 using the place name\n",
    "#         (b*)  I'm not sure how to do this - it's exploratory! \n",
    "#    (c) then, continue with the previous computation to find the ISS distance! :) \n",
    "#\n",
    "\n",
    "# The final problem of this hw2 is to take on _ONE_ open-ended possibility. \n",
    "#     (This ISS-themed one is only the first possibility.)\n",
    "#     Others, below, involve earthquakes, or your own choice of API exploration..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USGS Challenges\n",
    "\n",
    "Tasks 3 and 4 use the earthquake API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month        Quakes      \n",
      "------------------------------\n",
      "Jan          12          \n",
      "Feb          4           \n",
      "March        8           \n",
      "April        12          \n",
      "May          8           \n",
      "June         7           \n",
      "July         9           \n",
      "Aug          10          \n",
      "Sep          8           \n",
      "Oct          7           \n",
      "[12, 4, 8, 12, 8, 7, 9, 10, 8, 7]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# hw2: USGS Tasks 3 and 4 ...\n",
    "# \n",
    "# Two functions:  Quake_loop(), Quake_compare(place1, place2)\n",
    "\n",
    "#\n",
    "# Use the USGS (earthquake) examples above to write a function, named \n",
    "#     \n",
    "#      Quake_loop()\n",
    "#\n",
    "# that uses requests within a loop of your own design in order to\n",
    "#   + obtain at least 10 distinct, comparable data elements (counts are encouraged; other items ok)\n",
    "#   + see the assignment page for an example where the looping iterates over the _month_\n",
    "#\n",
    "#   + choose your favorite parameter(s) to vary, e.g., magnitude, time, radius, location, etc.\n",
    "#   + it should collect all of those data elements into a list\n",
    "#   + and render the list in a neatly formatted chart (f-strings welcome; not required)\n",
    "#\n",
    "#   + in addition, include a overall reflection on the results, as well as a comment on additional effort\n",
    "#     that could expand your results (you need not run it), and any concerns or caveats about the data...\n",
    "#   + feel free to copy-paste-edit the markdown \"reflection-template,\" above  \n",
    "\n",
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "def get_num_quakes(month, magnitude):\n",
    "   \"\"\" returns the number of quakes in month (of '24)\n",
    "           of at least magnitude ...\n",
    "   \"\"\"\n",
    "\n",
    "\n",
    "   url = \"https://earthquake.usgs.gov/fdsnws/event/1/count\"\n",
    "\n",
    "\n",
    "   # Let's use variables for three of the parameters:\n",
    "   min_mag = magnitude         # the minimum magnitude considered a quake (min_mag)\n",
    "   start_time = f\"2024-{month:02d}-01\"   # this is the year-month-day format of the start\n",
    "   finish_time = f\"2024-{month+1:02d}-01\"  # similar for the end (f-strings! :)\n",
    "\n",
    "\n",
    "   # we assemble a dictionary of our parameters, let's name it param_dictionary\n",
    "   # there are many more parameters available. The problems below ask you to explore them...\n",
    "   param_dictionary = { \"format\":\"geojson\",         # this is simply hard-coded to obtain json\n",
    "                        \"starttime\":start_time,\n",
    "                        \"endtime\":finish_time,\n",
    "                        \"minmagnitude\":min_mag,\n",
    "                       }\n",
    "\n",
    "\n",
    "   # Here, we use requests to make the request. The parameters will be added by this API call:\n",
    "   time.sleep(2)\n",
    "   result = requests.get(url, params=param_dictionary)\n",
    "   # print(f\"result is {result}\")                     # hopefully, this is 200\n",
    "   # print(f\"the full url used: {result.url}\")   # this will include the parameters!\n",
    "   d = result.json()\n",
    "   number_of_quakes = d['count']\n",
    "   month_names = {1: 'Jan', 2: 'Feb', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'Aug', 9:'Sep', 10: 'Oct'}\n",
    "   print(f\"{month_names[month]:<12} {number_of_quakes:<12}\")\n",
    "   return number_of_quakes\n",
    "\n",
    "def Quake_loop():\n",
    "   print(f\"{'Month':<12} {'Quakes':<12}\")\n",
    "   print(\"-\"*30)\n",
    "   LoQ = []\n",
    "   for month in range(1,11):\n",
    "      magnitude = 6\n",
    "      result = get_num_quakes(month,magnitude)\n",
    "      LoQ += [result]\n",
    "   return LoQ\n",
    "\n",
    "print(Quake_loop())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to create some new cells around this area to write and test ``Quake_loop()`` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthquake count near location 1 (Lat: 34.0522, Lon: -118.2437): 1\n",
      "Earthquake count near location 2 (Lat: 35.6895, Lon: 139.6917): 39\n",
      "Location 2 is quakier!\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Once your Quake_loop() function is working, write a new function\n",
    "#\n",
    "#       Quake_compare(place1, place2)\n",
    "#\n",
    "# where place1 should be a 2-element tuple:  (latitude1, longitude1)\n",
    "# and  place2 should be a 2-element tuple:  (latitude2, longitude2)\n",
    "#\n",
    "# and then your function should compare which of the two places is \"quakier\" (not a real word)\n",
    "# for a given time span (you choose), and a given strength-of-quakes (you choose), and\n",
    "# for a specific radius around each of the two places (you choose)\n",
    "#\n",
    "# As is clear, there is lots of freedom to design a \"comparison of quakiness\" -- wonderful!\n",
    "# Feel free to start somewhere, and tune the results.\n",
    "#\n",
    "# Your function should print the results it finds (in this case, it's not important to return\n",
    "# and specific value -- though you're encouraged (not required) to create a helper function and\n",
    "# then call it twice for the two locations! (That helper function would need a return value!)\n",
    "#\n",
    "#\n",
    "import requests\n",
    "import time\n",
    "place1 = (34.0522, -118.2437)  # Los Angeles, CA\n",
    "place2 = (35.6895, 139.6917)   # Tokyo, Japan\n",
    "\n",
    "def get_quake_count(latitude, longitude, radius, min_magnitude, start_time, end_time):\n",
    "    \"\"\" Returns the number of earthquakes near a given location within a given radius, time frame, and magnitude. \"\"\"\n",
    "    url = \"https://earthquake.usgs.gov/fdsnws/event/1/count\"\n",
    "\n",
    "    params = {\n",
    "        \"format\": \"geojson\",\n",
    "        \"starttime\": start_time,\n",
    "        \"endtime\": end_time,\n",
    "        \"minmagnitude\": min_magnitude,\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"maxradiuskm\": radius,\n",
    "    }\n",
    "\n",
    "    time.sleep(2)  # To avoid hitting API limits\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data.get(\"count\", 0)\n",
    "    else:\n",
    "        print(f\"Error fetching data: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def Quake_compare(place1, place2):\n",
    "    \"\"\" Compares earthquake activity between two locations. \"\"\"\n",
    "\n",
    "    # Parameters\n",
    "    min_magnitude = 5.0  # Consider quakes with magnitude >= 5.0\n",
    "    radius = 500  # Search within 500 km of each location\n",
    "    start_time = \"2024-01-01\"  # Start of 2024\n",
    "    end_time = \"2024-12-31\"  # End of 2024\n",
    "\n",
    "    # Get earthquake counts\n",
    "    count1 = get_quake_count(place1[0], place1[1], radius, min_magnitude, start_time, end_time)\n",
    "    count2 = get_quake_count(place2[0], place2[1], radius, min_magnitude, start_time, end_time)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Earthquake count near location 1 (Lat: {place1[0]}, Lon: {place1[1]}): {count1}\")\n",
    "    print(f\"Earthquake count near location 2 (Lat: {place2[0]}, Lon: {place2[1]}): {count2}\")\n",
    "\n",
    "    if count1 > count2:\n",
    "        print(\"Location 1 is quakier!\")\n",
    "    elif count2 > count1:\n",
    "        print(\"Location 2 is quakier!\")\n",
    "    else:\n",
    "        print(\"Both locations have the same earthquake activity.\")\n",
    "\n",
    "Quake_compare(place1, place2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to create some new cells around this area to write and test ``Quake_compare(place1, place2)`` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final API challenge:  an open-ended, two-hop API task...\n",
    "\n",
    "<font color=\"Coral\">Key constraint: _Use two hops!_</font>  &nbsp;&nbsp; Be sure to dome something that uses two separate API calls, in which the results of the first affect the second - culminating in an aggregate, overall result.\n",
    "\n",
    "Possibilities: \n",
    "  + You should use at least one other API. (See the hw2 page for links to many.)\n",
    "      + The [Poke API](https://pokeapi.co/)  or [one of these](https://medium.com/codex/15-fun-and-interesting-apis-to-use-for-your-next-coding-project-in-2022-86a4ff3a2742) or [one of the many, many more!](https://github.com/public-apis/public-apis)\n",
    "  + That said, <u><b>one</b></u> of the two can be ISS or USGS, as you used above.\n",
    "\n",
    "\n",
    "\n",
    "<font size=\"-2\">PS. My example of this is in ``superbowl_prediction.ipynb`` with the starter files. It used to be here, but it was too clutter-y... .</font>\n",
    "\n",
    "<br><hr><br>\n",
    "\n",
    "Big-picture, an important part of using API calls is gathering a _specific piece_ of data from an otherwise too-large ocean of raw material. That element then allows you to express a natural _next_ specific question, obtain its relevant data, and continue to build from there, with each round-trip branching into additional (possible) questions... .\n",
    "\n",
    "<br>\n",
    "\n",
    "Good luck API'ing!!\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\":\"online\"}\n"
     ]
    }
   ],
   "source": [
    "import http.client\n",
    "\n",
    "conn = http.client.HTTPSConnection(\"exercisedb.p.rapidapi.com\")\n",
    "\n",
    "headers = {\n",
    "    'x-rapidapi-key': \"ea05327a5dmsha02021e1aacef7ap1919c5jsne180af786525\",\n",
    "    'x-rapidapi-host': \"exercisedb.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "conn.request(\"GET\", \"/status\", headers=headers)\n",
    "\n",
    "res = conn.getresponse()\n",
    "data = res.read()\n",
    "\n",
    "print(data.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¨ Checking color mood...\n",
      "âœ… Detected Color: Pompadour\n",
      " Matched Mood Color: Red\n",
      "Suggested Workout Type: Cardio\n",
      "\n",
      "â³ Fetching personalized exercises...\n",
      "\n",
      " Recommended Exercises\n",
      "1. jack burpee\n",
      "   ðŸ‹ï¸â€â™‚ï¸ Exercise GIF: https://v2.exercisedb.io/image/8QwJqMhqDEI5Cy\n",
      "\n",
      "2. mountain climber\n",
      "   ðŸ‹ï¸â€â™‚ï¸ Exercise GIF: https://v2.exercisedb.io/image/OVnUJYOSaFV101\n",
      "\n",
      "3. run (equipment)\n",
      "   ðŸ‹ï¸â€â™‚ï¸ Exercise GIF: https://v2.exercisedb.io/image/rYnsTPTLkUyqua\n",
      "\n",
      "4. run\n",
      "   ðŸ‹ï¸â€â™‚ï¸ Exercise GIF: https://v2.exercisedb.io/image/cZzmunR0baA-w9\n",
      "\n",
      "5. stationary bike walk\n",
      "   ðŸ‹ï¸â€â™‚ï¸ Exercise GIF: https://v2.exercisedb.io/image/j9bo8Af3Wg5VBc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Cells for your own API experimentations + results!\n",
    "# using color API and excercise DB to personalize workout recommendation based on the user input color.  \n",
    "\n",
    "import requests\n",
    "import http.client\n",
    "import json\n",
    "\n",
    "# Mood-Color to Workout Mapping (Grouped by Similar Colors)\n",
    "MOOD_WORKOUT_MAP = {\n",
    "    \"Red\": [\"cardio\", \"HIIT\", \"boxing\"],        # High intensity, aggressive\n",
    "    \"Blue\": [\"stretching\", \"yoga\", \"pilates\"],  # Calm, relaxed\n",
    "    \"Yellow\": [\"plyometrics\", \"dance\"],        # Energetic, fun\n",
    "    \"Green\": [\"running\", \"hiking\"],            # Nature, endurance\n",
    "    \"Purple\": [\"strength\", \"powerlifting\"],    # Focus, strength training\n",
    "    \"Orange\": [\"HIIT\", \"cardio\"],              # Explosive energy\n",
    "    \"Pink\": [\"pilates\", \"yoga\"],               # Balanced, mindful\n",
    "    \"Black\": [\"boxing\", \"combat\"],             # Power, combat sports\n",
    "    \"White\": [\"meditation\", \"stretching\"],     # Low intensity, mindfulness\n",
    "}\n",
    "def get_color_details(hex_code):\n",
    "    url = f\"https://www.thecolorapi.com/id?hex={hex_code.strip('#')}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return {\n",
    "            \"name\": data['name']['value'],  \n",
    "            \"rgb\": data['rgb']  # Gets RGB values\n",
    "        }\n",
    "    \n",
    "    return {\"name\": \"Unknown\", \"rgb\": {\"r\": 255, \"g\": 0, \"b\": 0}}  # Default to red\n",
    "\n",
    "# Function to get color name from The Color API\n",
    "def get_color_name(hex_code):\n",
    "    url = f\"https://www.thecolorapi.com/id?hex={hex_code.strip('#')}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()['name']['value']\n",
    "    \n",
    "    return \"Unknown\"\n",
    "\n",
    "# maps RGB color to closest base color. Since color api has specific color names, \n",
    "#we use the hex color to classify the colors\n",
    "\n",
    "def get_closest_mood_color(rgb):\n",
    "    r, g, b = rgb[\"r\"], rgb[\"g\"], rgb[\"b\"]\n",
    "\n",
    "    if r > 200 and g < 100 and b < 100:\n",
    "        return \"Red\"\n",
    "    elif b > 200 and r < 100 and g < 150:\n",
    "        return \"Blue\"\n",
    "    elif r > 200 and g > 200 and b < 100:\n",
    "        return \"Yellow\"\n",
    "    elif g > 150 and r < 150 and b < 100:\n",
    "        return \"Green\"\n",
    "    elif r > 150 and b > 150 and g < 100:\n",
    "        return \"Purple\"\n",
    "    elif r > 200 and g > 120 and b < 50:\n",
    "        return \"Orange\"\n",
    "    elif r > 200 and g < 150 and b > 150:\n",
    "        return \"Pink\"\n",
    "    elif r < 50 and g < 50 and b < 50:\n",
    "        return \"Black\"\n",
    "    elif r > 200 and g > 200 and b > 200:\n",
    "        return \"White\"\n",
    "    \n",
    "    return \"Red\"  # Default fallback\n",
    "\n",
    "# Function to get workouts from ExerciseDB API\n",
    "def get_workouts(workout_type):\n",
    "    url = f\"https://exercisedb.p.rapidapi.com/exercises/bodyPart/{workout_type}\"\n",
    "    headers = {\n",
    "        'x-rapidapi-key': \"ea05327a5dmsha02021e1aacef7ap1919c5jsne180af786525\",\n",
    "        'x-rapidapi-host': \"exercisedb.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        exercises = response.json()\n",
    "        if isinstance(exercises, list) and len(exercises) > 0:\n",
    "            return [{\"name\": ex[\"name\"], \"gif\": ex[\"gifUrl\"]} for ex in exercises[:5]]\n",
    "    \n",
    "    return [{\"name\": \"Jumping Jacks\", \"gif\": \"https://example.com/jumping-jacks.gif\"}]  # Default fallback\n",
    "\n",
    "# Function to generate workout based on color mood\n",
    "def mood_based_workout(hex_code):\n",
    "    print(\"\\nðŸŽ¨ Checking color mood...\")\n",
    "    color_details = get_color_details(hex_code)\n",
    "    detected_color_name = color_details[\"name\"]\n",
    "    detected_rgb = color_details[\"rgb\"]\n",
    "\n",
    "    print(f\"âœ… Detected Color: {detected_color_name}\")\n",
    "\n",
    "    # Find the closest mood color based on RGB\n",
    "    mood_color = get_closest_mood_color(detected_rgb)\n",
    "    print(f\" Matched Mood Color: {mood_color}\")\n",
    "\n",
    "    # Pick a workout type from the available ones for that mood\n",
    "    workout_types = MOOD_WORKOUT_MAP[mood_color]\n",
    "    selected_workout = workout_types[0]  # Always pick the first workout type\n",
    "    \n",
    "    print(f\"Suggested Workout Type: {selected_workout.capitalize()}\")\n",
    "\n",
    "    # Fetch exercises from API\n",
    "    print(\"\\nâ³ Fetching personalized exercises...\\n\")\n",
    "    exercises = get_workouts(selected_workout)\n",
    "\n",
    "    # Display results\n",
    "    print(\" Recommended Exercises\")\n",
    "    for i, ex in enumerate(exercises, 1):\n",
    "        print(f\"{i}. {ex['name']}\")\n",
    "        print(f\"   ðŸ‹ï¸â€â™‚ï¸ Exercise GIF: {ex['gif']}\\n\")\n",
    "\n",
    "#  User Input for Hex Code\n",
    "hex_code = input(\"ðŸŽ¨ Enter a color hex code (e.g., #FF5733): \")\n",
    "mood_based_workout(hex_code)\n",
    "\n",
    "\n",
    "#Output format was with the help of ChatGPT\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
