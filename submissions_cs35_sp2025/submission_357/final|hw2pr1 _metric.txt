#
# computing-styling trick of the day     (or, of the minute...)
#
# the setting for word-wrapping on the output is
#     "notebook.output.wordwrap": true,   (in your settings.json file or from code ... settings ...) 

print( list(range(100)) )



#
import requests
# see if we have the requests library...
#



#
# if you _don't_ have the requests library, let's install it!
#

# for me, it worked to uncomment and run this command, here in this cell:
# #3 install requests  or   # install requests

# an alternative is to run, in a terminal, the command would be 
#  #3 install requests  or    # install requests      (the ! is needed only if inside python)

# it's very system-dependent how much you have to "restart" in order to use
# the new library (the notebook, vscode, the jupyter extension, etc.)

# troubles?  let us know!  we'll work on it with you...


#
# hopefully, this now works! (if so, running will succeed silently)
#

import requests


#
# let's try it on a simple webpage
#

#
# we assign the url and obtain the api-call result into result
#    note that result will be an object that contains many fields (not a simple string)
# 

url = "https://www.cs.hmc.edu/~dodds/demo.html"
result = requests.get(url)
result    

# if it succeeded, you should see <response [200]>
# see the list of http reponse codes for the full set!


#
# when exploring, you'll often obtain an unfamiliar object. 
# here, we'll ask what type it is 
type(result)


# here is one of the data members within the result
# it "remembers" (keeps track of) the url requested:
result.url


# we can print all of the data members in an object with dir
# since dir returns a list, we will grab that list and loop over it:
all_fields = dir(result)

for field in all_fields:
    if "_" not in field: 
        print(field)


#
# let's try printing a few of those fields (data members): 
print(f"result.url         is {result.url}")  # the original url
print(f"result.raw         is {result.raw}")  # another object!
print(f"result.encoding    is {result.encoding}")  # utf-8 is very common
print(f"result.status_code is {result.status_code}")  # 200 is success!


# in this case, the result is a text file (html) let's see it!
contents = result.text
print(contents)


# yay!  
# this shows that you are able to "scrape" an arbitrary html page... 

# now, we're off to more _structured_ data-gathering...


#
# we assign the url and obtain the api-call result into result
#    note that result will be an object that contains many fields (not a simple string)
# 

import requests

url = "http://api.open-notify.org/iss-now.json"   # this is sometimes called an "endpoint" ...
result = requests.get(url)
result    

# if it succeeds, you should see <response [200]>


#
# let's try printing those shorter fields from before:
print(f"result.url         is {result.url}")  # the original url
print(f"result.raw         is {result.raw}")  # another object!
print(f"result.encoding    is {result.encoding}")  # utf-8 is very common
print(f"result.status_code is {result.status_code}")  # 200 is success!


#
# in this case, we know the result is a json file, and we can obtain it that way:
json_contents = result.json()
print(json_contents)

# remember:  json_contents will be a _dictionary_


#
# let's re-remind ourselves how dictionaries work:
cs35_participant_2 = float(json_contents['iss_position']['longitude'])
json_contents['message']       # challenge:  could we access the other components? what _types_ are they?!!


#
# in python, we can use the resulting dictionary... let's see its keys:
print(list(json_contents.keys()))  

# also, watch out for string vs. numeric types, e.g., for latitude and longitude.
# at heart, _all_ web data are strings... .

# these experiments will be helpful for problem 1, below :)


# json is a javascript dictionary format -- almost the same as a python dictionary:
data = { 'key':'value',  'fave':42,  'list':[5,6,7,{'mascot':'aliiien'}] }
print(data)

# we can write in json format to a local file, named small42.json:
import json 

with open("small.json", "w") as f:
    json.dump( data, f )


# we can also read from a json file
# the resulting data will be a _dictionary_:

with open("small.json", "r") as f:
    dictionary = json.load( f )

print(f"the {dictionary = }")


# let's access this dictionary -- first, the keys:
list(dictionary.keys())   # how do we get 'aliiien' from newdata?


# task: use the dictionary to obtain (a) 'value' , (b) 42 , (c) 'aliiien'  [tricky!]

# remember that there are two ways to get the value from a key:
# way 1:  dictionary['key']            # errors if 'key' isn't present
# way 2:  dictionary.get('key')        # returns none if 'key' isn't present

dictionary['key']


import requests 

# here, we will obtain plain-text results from a request
url = "https://www.cs.hmc.edu/~dodds/demo.html"  # try it + source
# url = "https://www.scrippscollege.edu/"          # another possible site...
# url = "https://www.pitzer.edu/"                  # another possible site...
# url = "https://www.cmc.edu/"                     # and another!
# url = "https://www.cgu.edu/"
result = requests.get(url)        
print(f"result is {result}")        # hopefully it's 200


# if the request was successful, the response will be [200]. 
# then, we can grab the text - or json - from the site:

text = result.text                  # provides the html page as a large string...
print(f"len(text) is {len(text)}")  # let's see how large the html page is... 

print("\nthe first 242 characters are\n")
print(text[:242])                  # we'll print the first few characters...  

# change this to text[:] to see the whole document...
# notice that we can run many different analyses without having to re-call/re-scrape the page (this is good!)


#
# we assign the url and use requests.get to obtain the result into result_astro
#
#    remember, result_astro will be an object that contains many fields (not a simple string)
# 

import requests

url = "http://api.open-notify.org/astros.json"   # this is sometimes called an "endpoint" ...
result_astro = requests.get(url)
result_astro

# if it succeeded, you should see <response [200]>


# if the request succeeded, we know the result is a json file, and we can obtain it that way.
# let's call our dictionary something more specific:

astronauts = result_astro.json()
print(astronauts)
d = astronauts     # d is shorter to type

# remember:  d and astronauts will be a _dictionary_

note = """ here's yesterday's result - it _should_ be the same today!

{"people": [{"craft": "iss", "name": "oleg kononenko"}, {"craft": "iss", "name": "nikolai chub"},
{"craft": "iss", "name": "tracy caldwell dyson"}, {"craft": "iss", "name": "matthew dominick"},
{"craft": "iss", "name": "michael barratt"}, {"craft": "iss", "name": "jeanette epps"},
{"craft": "iss", "name": "alexander grebenkin"}, {"craft": "iss", "name": "butch wilmore"},
{"craft": "iss", "name": "sunita williams"}, {"craft": "tiangong", "name": "li guangsu"},
{"craft": "tiangong", "name": "li cong"}, {"craft": "tiangong", "name": "ye guangfu"}], "number": 12, "message": "success"}
"""
""


#
# cell to try out parsing d  (astronauts)
#

d['people'][0]['name'][7:9]


#
# let's try the  count  endpoint, with geojson format (json with geographical data)
#

url = "https://earthquake.usgs.gov/fdsnws/event/1/count?format=geojson&minmagnitude=5.0&starttime=2024-01-01&endtime=2024-02-01"

result = requests.get(url)                       # a named input, params, taking the value param_d, above
print(f"result is {result}")                     # hopefully, this is 200
print(f"the full url used was\n {result.url}")   # it's nice to be able to see this


# if it worked, we should be able to obtain the json. remember, it's a dictionary. let's use d:

d = result.json()

print(f"{d =}")


#
# here is the endpoint
#
url = "https://earthquake.usgs.gov/fdsnws/event/1/count"

# let's use variables for three of the parameters:
min_mag = 5.0               # the minimum magnitude considered a quake (min_mag)
start_time = "2025-01-01"   # this is the year-month-day format of the start
finish_time = "2025-02-01"  # similar for the end

# we assemble a dictionary of our parameters, let's name it param_dictionary
# there are many more parameters available. the problems below ask you to explore them...
param_dictionary = { "format":"geojson",         # this is simply hard-coded to obtain json
                     "starttime":start_time,
                     "endtime":finish_time,
                     "minmagnitude":min_mag,
                     }

# here, we use requests to make the request. the parameters will be added by this api call:
result = requests.get(url, params=param_dictionary)
print(f"result is {result}")                     # hopefully, this is 200
print(f"the full url used was\n {result.url}")   # this will include the parameters!


# if it worked, we should be able to see the json results:

d = result.json()
print(f"json returned was {d = }")


#
# how many quakes of magnitude >= 4.2 have been within 300km of claremont 
#     + in jan 2025
#     + in dec 2025
#
url = "https://earthquake.usgs.gov/fdsnws/event/1/count"

# let's use variables for three of the parameters:
min_mag = 4.2               # the minimum magnitude considered a quake (min_mag)
start_time = "2025-01-01"   # this is the year-month-day format of the start
finish_time = "2025-02-01"  # similar for the end
# start_time = "2024-01-01"   # similar, but for a year-cs35_participant_2 span...
# finish_time = "2025-01-01"  # similar for the end
radius_in_km = 300

# we assemble a dictionary of our parameters, let's name it param_dictionary
# there are many more parameters available. the problems below ask you to explore them...
param_dictionary = { "format":"geojson",         # this is simply hard-coded to obtain json
                     "starttime":start_time,
                     "endtime":finish_time,
                     "minmagnitude":min_mag,
                     "latitude":34.0967,
                     "longitude":-117.7198,
                     "maxradiuskm":radius_in_km,
                     }

# here, we use requests to make the request. the parameters will be added by this api call:
result = requests.get(url, params=param_dictionary)
print(f"result is {result}")                     # hopefully, this is 200
print(f"the full url used was\n {result.url}")   # this will include the parameters!

# we'll extract the final result in another cell:


# let's finish up here:
quake_count = result.json()
print(f"{quake_count = }")


#
# here is the endpoint
#
url = "https://earthquake.usgs.gov/fdsnws/event/1/query"

# let's use variables for three of the parameters:
min_mag = 6.5               # the minimum magnitude considered a quake (min_mag)
start_time = "2025-01-01"   # this is the year-month-day format of the start
finish_time = "2025-02-01"  # similar for the end

# we assemble a dictionary of our parameters, let's name it param_dictionary
# there are many more parameters available. the problems below ask you to explore them...
param_dictionary = { "format":"geojson",         # this is simply hard-coded to obtain json
                     "starttime":start_time,
                     "endtime":finish_time,
                     "minmagnitude":min_mag,
                     }

# here, we use requests to make the request. the parameters will be added by this api call:
result = requests.get(url, params=param_dictionary)
print(f"result is {result}")                     # hopefully, this is 200
print(f"the full url used was\n {result.url}")   # this will include the parameters!


# if it worked, we should be able to see the json results:

d = result.json()
print(f"json returned was {d = }")


#
# that's hard to read!
# let's pretty-print it with the json library
#       also, this version can be pasted into online formatters, e.g., https://jsonformatter.org/

import json 
nice_string = json.dumps(d)   # this outputs a "nicely formatted string" using double quotes
print(nice_string)

 



import json 
nicer_string = json.dumps(d, indent=4)   # we can specify the indentation. 
print(nicer_string)                      # it's another tree structure... !


# api endpoint
url = "https://earthquake.usgs.gov/fdsnws/event/1/query"

# query parameters for the entire year of 2024
params = {
    "format": "geojson",  # get data in json format
    "starttime": "2024-01-01",
    "endtime": "2024-12-31",
    "minmagnitude": 5.0,  # get only significant earthquakes
    "limit": 1000,  # get a large dataset
    "orderby": "magnitude"  # order results by magnitude (largest first)
}

# make api request
response = requests.get(url, params=params)

# check if the request was successful
if response.status_code == 200:
    data = response.json()  # convert response to json format
    earthquakes = data.get("features", [])

    if earthquakes:
        # find the largest earthquake
        largest_quake = max(earthquakes, key=lambda eq: eq["properties"]["mag"])
        largest_info = {
            "magnitude": largest_quake["properties"]["mag"],
            "location": largest_quake["properties"]["place"],
            "time (utc)": largest_quake["properties"]["time"]
        }
        
        print("largest earthquake in 2024:")
        print(f"  - magnitude: {largest_info['magnitude']}")
        print(f"  - location: {largest_info['location']}")
        print(f"  - time (timestamp): {largest_info['time (utc)']}")

    else:
        print("no significant earthquakes found in 2024.")

else:
    print(f"error: {response.status_code}")



#
# hw2: iss tasks 1 and 2 ...
# 
# two functions:  iss_now(), iss_distance()

#
# use the iss examples above to write a function, named 
#     
#      iss_now()
#
# that uses requests to return the current latitude and longitude -- as floating-point values -- right now.
# be sure to test it! 

from math import radians, sin, cos, sqrt, asin
import requests

def iss_now():
    """ get the iss current location and return lat cs35_participant_2! """
    url = "http://api.open-notify.org/iss-now.json" 
    result = requests.get(url)  
    json_contents = result.json()
    cs35_participant_2 = json_contents['iss_position']['longitude']
    lat = json_contents['iss_position']['latitude']
    return lat,cs35_participant_2

lat, cs35_participant_2 = iss_now()
print(f"{lat = } and {cs35_participant_2 = }")




# 
# once your iss_now() function is working, write a new function
#
#       iss_distance()
#
# which uses iss_now to obtain the lat/cs35_participant_2 of the iss and then
# uses the haversine distance (look up a python implementation or use one of ours... :)
# to compute the iss's distance from a city of your choice.
#
# the haversine distance computes the "great circle" distance from two points on the globe
#     using latitude and longitude  
# lat and cs35_participant_2 of claremont and iss
def haversine(lat1, long1, lat2, long2):
    """
    calculate the great circle distance in kilometers between two points
    on the earth (specified in decimal degrees)
    """
    # convert decimal degrees to radians
    lat1, long1, lat2, long2 = map(float, [lat1, long1, lat2, long2])
    long1, lat1, long2, lat2 = map(radians, [long1, lat1, long2, lat2])

    # haversine formula
    dlong = long2 - long1
    dlat = lat2 - lat1
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlong/2)**2
    c = 2 * asin(sqrt(a))
    # radius of earth. use 3956 for miles. 6371 for km.
    r = 3956
    return c * r

def iss_distance():
    lat_c = 34.097
    long_c = -117.719
    lat_iss , long_iss = iss_now()
    result = haversine(lat_c, long_c, lat_iss, long_iss)
    return result 

print(f"distance between claremont and iss: {iss_distance()}")

#print(iss_distance())



#
# open-ended possibility:  
#    (a) create a new function iss_distance(place) that takes in a place name
#    (b) find a service by which you can look up the lat + cs35_participant_2 using the place name
#         (b*)  i'm not sure how to do this - it's exploratory! 
#    (c) then, continue with the previous computation to find the iss distance! :) 
#

# the final problem of this hw2 is to take on _one_ open-ended possibility. 
#     (this iss-themed one is only the first possibility.)
#     others, below, involve earthquakes, or your own choice of api exploration...


#
# hw2: usgs tasks 3 and 4 ...
# 
# two functions:  quake_loop(), quake_compare(place1, place2)

#
# use the usgs (earthquake) examples above to write a function, named 
#     
#      quake_loop()
#
# that uses requests within a loop of your own design in order to
#   + obtain at least 10 distinct, comparable data elements (counts are encouraged; other items ok)
#   + see the assignment page for an example where the looping iterates over the _month_
#
#   + choose your favorite parameter(s) to vary, e.g., magnitude, time, radius, location, etc.
#   + it should collect all of those data elements into a list
#   + and render the list in a neatly formatted chart (f-strings welcome; not required)
#
#   + in addition, include a overall reflection on the results, as well as a comment on additional effort
#     that could expand your results (you need not run it), and any concerns or caveats about the data...
#   + feel free to copy-paste-edit the markdown "reflection-template," above  

import requests
import time


def get_num_quakes(month, magnitude):
   """ returns the number of quakes in month (of '24)
           of at least magnitude ...
   """


   url = "https://earthquake.usgs.gov/fdsnws/event/1/count"


   # let's use variables for three of the parameters:
   min_mag = magnitude         # the minimum magnitude considered a quake (min_mag)
   start_time = f"2024-{month:02d}-01"   # this is the year-month-day format of the start
   finish_time = f"2024-{month+1:02d}-01"  # similar for the end (f-strings! :)


   # we assemble a dictionary of our parameters, let's name it param_dictionary
   # there are many more parameters available. the problems below ask you to explore them...
   param_dictionary = { "format":"geojson",         # this is simply hard-coded to obtain json
                        "starttime":start_time,
                        "endtime":finish_time,
                        "minmagnitude":min_mag,
                       }


   # here, we use requests to make the request. the parameters will be added by this api call:
   time.sleep(2)
   result = requests.get(url, params=param_dictionary)
   # print(f"result is {result}")                     # hopefully, this is 200
   # print(f"the full url used: {result.url}")   # this will include the parameters!
   d = result.json()
   number_of_quakes = d['count']
   month_names = {1: 'jan', 2: 'feb', 3: 'march', 4: 'april', 5: 'may', 6: 'june', 7: 'july', 8: 'aug', 9:'sep', 10: 'oct'}
   print(f"{month_names[month]:<12} {number_of_quakes:<12}")
   return number_of_quakes

def quake_loop():
   print(f"{'month':<12} {'quakes':<12}")
   print("-"*30)
   loq = []
   for month in range(1,11):
      magnitude = 6
      result = get_num_quakes(month,magnitude)
      loq += [result]
   return loq

print(quake_loop())
    


#
# once your quake_loop() function is working, write a new function
#
#       quake_compare(place1, place2)
#
# where place1 should be a 2-element tuple:  (latitude1, longitude1)
# and  place2 should be a 2-element tuple:  (latitude2, longitude2)
#
# and then your function should compare which of the two places is "quakier" (not a real word)
# for a given time span (you choose), and a given strength-of-quakes (you choose), and
# for a specific radius around each of the two places (you choose)
#
# as is clear, there is lots of freedom to design a "comparison of quakiness" -- wonderful!
# feel free to start somewhere, and tune the results.
#
# your function should print the results it finds (in this case, it's not important to return
# and specific value -- though you're encouraged (not required) to create a helper function and
# then call it twice for the two locations! (that helper function would need a return value!)
#
#
import requests
import time
place1 = (34.0522, -118.2437)  # los angeles, ca
place2 = (35.6895, 139.6917)   # tokyo, japan

def get_quake_count(latitude, longitude, radius, min_magnitude, start_time, end_time):
    """ returns the number of earthquakes near a given location within a given radius, time frame, and magnitude. """
    url = "https://earthquake.usgs.gov/fdsnws/event/1/count"

    params = {
        "format": "geojson",
        "starttime": start_time,
        "endtime": end_time,
        "minmagnitude": min_magnitude,
        "latitude": latitude,
        "longitude": longitude,
        "maxradiuskm": radius,
    }

    time.sleep(2)  # to avoid hitting api limits
    response = requests.get(url, params=params)
    
    if response.status_code == 200:
        data = response.json()
        return data.get("count", 0)
    else:
        print(f"error fetching data: {response.status_code}")
        return none

def quake_compare(place1, place2):
    """ compares earthquake activity between two locations. """

    # parameters
    min_magnitude = 5.0  # consider quakes with magnitude >= 5.0
    radius = 500  # search within 500 km of each location
    start_time = "2024-01-01"  # start of 2024
    end_time = "2024-12-31"  # end of 2024

    # get earthquake counts
    count1 = get_quake_count(place1[0], place1[1], radius, min_magnitude, start_time, end_time)
    count2 = get_quake_count(place2[0], place2[1], radius, min_magnitude, start_time, end_time)

    # print results
    print(f"earthquake count near location 1 (lat: {place1[0]}, lon: {place1[1]}): {count1}")
    print(f"earthquake count near location 2 (lat: {place2[0]}, lon: {place2[1]}): {count2}")

    if count1 > count2:
        print("location 1 is quakier!")
    elif count2 > count1:
        print("location 2 is quakier!")
    else:
        print("both locations have the same earthquake activity.")

quake_compare(place1, place2)





import http.client

conn = http.client.httpsconnection("exercisedb.p.rapidapi.com")

headers = {
    'x-rapidapi-key': "ea05327a5dmsha02021e1aacef7ap1919c5jsne180af786525",
    'x-rapidapi-host': "exercisedb.p.rapidapi.com"
}

conn.request("get", "/status", headers=headers)

res = conn.getresponse()
data = res.read()

print(data.decode("utf-8"))


#
# cells for your own api experimentations + results!
# using color api and excercise db to personalize workout recommendation based on the user input color.  

import requests
import http.client
import json

# mood-color to workout mapping (grouped by similar colors)
mood_workout_map = {
    "red": ["cardio", "hiit", "boxing"],        # high intensity, aggressive
    "blue": ["stretching", "yoga", "pilates"],  # calm, relaxed
    "yellow": ["plyometrics", "dance"],        # energetic, fun
    "green": ["running", "hiking"],            # nature, endurance
    "purple": ["strength", "powerlifting"],    # focus, strength training
    "orange": ["hiit", "cardio"],              # explosive energy
    "pink": ["pilates", "yoga"],               # balanced, mindful
    "black": ["boxing", "combat"],             # power, combat sports
    "white": ["meditation", "stretching"],     # low intensity, mindfulness
}
def get_color_details(hex_code):
    url = f"https://www.thecolorapi.com/id?hex={hex_code.strip('#')}"
    response = requests.get(url)
    
    if response.status_code == 200:
        data = response.json()
        return {
            "name": data['name']['value'],  
            "rgb": data['rgb']  # gets rgb values
        }
    
    return {"name": "unknown", "rgb": {"r": 255, "g": 0, "b": 0}}  # default to red

# function to get color name from the color api
def get_color_name(hex_code):
    url = f"https://www.thecolorapi.com/id?hex={hex_code.strip('#')}"
    response = requests.get(url)
    
    if response.status_code == 200:
        return response.json()['name']['value']
    
    return "unknown"

# maps rgb color to closest base color. since color api has specific color names, 
#we use the hex color to classify the colors

def get_closest_mood_color(rgb):
    r, g, b = rgb["r"], rgb["g"], rgb["b"]

    if r > 200 and g < 100 and b < 100:
        return "red"
    elif b > 200 and r < 100 and g < 150:
        return "blue"
    elif r > 200 and g > 200 and b < 100:
        return "yellow"
    elif g > 150 and r < 150 and b < 100:
        return "green"
    elif r > 150 and b > 150 and g < 100:
        return "purple"
    elif r > 200 and g > 120 and b < 50:
        return "orange"
    elif r > 200 and g < 150 and b > 150:
        return "pink"
    elif r < 50 and g < 50 and b < 50:
        return "black"
    elif r > 200 and g > 200 and b > 200:
        return "white"
    
    return "red"  # default fallback

# function to get workouts from exercisedb api
def get_workouts(workout_type):
    url = f"https://exercisedb.p.rapidapi.com/exercises/bodypart/{workout_type}"
    headers = {
        'x-rapidapi-key': "ea05327a5dmsha02021e1aacef7ap1919c5jsne180af786525",
        'x-rapidapi-host': "exercisedb.p.rapidapi.com"
    }

    response = requests.get(url, headers=headers)
    
    if response.status_code == 200:
        exercises = response.json()
        if isinstance(exercises, list) and len(exercises) > 0:
            return [{"name": ex["name"], "gif": ex["gifurl"]} for ex in exercises[:5]]
    
    return [{"name": "jumping jacks", "gif": "https://example.com/jumping-jacks.gif"}]  # default fallback

# function to generate workout based on color mood
def mood_based_workout(hex_code):
    print("\n🎨 checking color mood...")
    color_details = get_color_details(hex_code)
    detected_color_name = color_details["name"]
    detected_rgb = color_details["rgb"]

    print(f"✅ detected color: {detected_color_name}")

    # find the closest mood color based on rgb
    mood_color = get_closest_mood_color(detected_rgb)
    print(f" matched mood color: {mood_color}")

    # pick a workout type from the available ones for that mood
    workout_types = mood_workout_map[mood_color]
    selected_workout = workout_types[0]  # always pick the first workout type
    
    print(f"suggested workout type: {selected_workout.capitalize()}")

    # fetch exercises from api
    print("\n⏳ fetching personalized exercises...\n")
    exercises = get_workouts(selected_workout)

    # display results
    print(" recommended exercises")
    for i, ex in enumerate(exercises, 1):
        print(f"{i}. {ex['name']}")
        print(f"   🏋️‍♂️ exercise gif: {ex['gif']}\n")

#  user input for hex code
hex_code = input("🎨 enter a color hex code (e.g., #ff5733): ")
mood_based_workout(hex_code)


#output format was with the help of chatgpt




