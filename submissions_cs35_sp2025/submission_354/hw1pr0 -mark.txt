# Welcome to cs35, hw1pr0 ! #### Homework 1, problem 0 is a "reading-and-response problem"
+ There is usually one of these each week
+ It often reflects on the programming portion of that week...
+ **Response**    We ask you to compose a response to each article. It can be short (4-5 sentences is great), and the goal is to engage with the article, as well as to incorporate your own thoughts and experiences into your response. 
  + Include your response in the cell at the bottom of this notebook
  + Then, submit this notebook `hw1pr0.ipynb` to the submission site

<br>

+ To get familiar with Gradescope, feel free to submit this notebook, for the moment, _without_ the reading-response 
  + It's always possible to re-submit a file to Gradescope.
  + Gradescope keeps all submitted versions; the graders see the last version submitted

<br>

<hr>### The reading

Similar in spirit to cs5's reading/response assignments, each week there will be a short article overlapping that week's topics (sometimes broadly, other times narrowly). 

This week has "1+" readings. 

<br>

The "1" of "1+" comes from a short Nature article that describes a "credit-blame asymmetry" caused by AI, i.e., LLMs.  That is, LLMs make it more difficult to feel that creditable work is being accomplished -- but they do not change the standards for blame.  This is timely, seeing as this class -- and so much else -- is about using and exploring AI.  First, the article:

+ The article:     [Generative AI entails a creditâ€“blame asymmetry](https://www.nature.com/articles/s42256-023-00653-1)  &nbsp;&nbsp;   [pdf](https://drive.google.com/file/d/1rgIBOjld0N6QZpkI6G4Vm4YZAFVyYQe_/view?usp=drive_link)  &nbsp;&nbsp;     <font size="-2">(Oxford's  <a href="https://www.ox.ac.uk/news/2023-05-05-tackling-ethical-dilemma-responsibility-large-language-models">overview</a>  of the article)</font>

<br>

The prompt below will ask if you sense the "asymmetry" the article claims. But, first, the "+" of "1+":

The "+" of "1+" is the first two sections, 1.1 and 1.2, of the [ACM's Code of Ethics and Professional Conduct](https://ethics.acm.org/). The ACM is the Association for Computing Machinery and  is the world's largest professional-computing group. In 2018, the ACM released "the Code," its broad ethical guide for all computing work:  

+ Read sections 1.1 and 1.2  of "[the Code](https://ethics.acm.org/)."  More, of course, if you'd like...

<br><hr><br>
#### The prompt

As each week, this "problem 0" asks you to compose a one-paragraph reflection (~5 sentences, give or take), with the goal of bridging your personal experiences with the ideas in the articles. 

This week's prompts:

<br>

(a) The Nature article - and its overview - suggests that society is "justified in holding persons accountable for deliberate or careless errors in generated text if they put such text to use in ways that negatively impact others"  [<font color="DodgerBlue">the "blame" side</font>] and also that society "might not think people deserve credit for text generated without much skill and effort, such as ChatGPT-generated exam papers" [<font color="DodgerBlue">the "credit" side</font>].  <font color="Coral">Do you agree with neither, either, or both of these two "sides" of the article's "credit-blame asymmetry"? In a sentence or two, elaborate how/why</font>

(b) The ACM Code of Ethics, especially sections 1.1 (<i>Contribute...</i>) and 1.2 (<i>Avoid harm</i>), mirror this credit-blame dichotomy.  With these principles in mind, <font color="Coral">do you feel that, in particular, AI systems are ethics-promoting? detracting? neutral? amplifying what's already there?</font>  What changes to norms or expectations would you like to see around AI systems, credit for creative work, and blame for misuse? 

<br>

Here, and in general, your response should incorporate ideas from the article(s), connecting them with your own thoughts, takes, and experiences. 

And - you can always add detours, if you'd like ...

<br><hr><br>#### The Response

(Feel free to use this cell for your response.)


<br>I agree with both of the two sides of the article's "credit-blame asymmetry" as it all depends on the situation. For the blame side, although an individual's intent is not to cause harm, they still have to bear the consequences of their carelessness. An example would be if I forgot that I left a nail on the ground and someone steps on it. Even though my intent was not to hurt someone, I am still responsible for whoever got hurt. As for the credit side, the article says that individuals should not get credit for Ai content that lacks human effort or thinking. I agree with this as the work would not be a reflection of the student's own understand and skills. It would also be unfair for thoses that actually put in the work.  <br>


<font color="gray">Feel free to edit this cell itself.</font><br><br>
<hr>
<br>

Additional thoughts on LLMs: not necessary for cs35.

In fact, we will explore more about the technical workings of LLMs around weeks 8-9.

+ [LLMs don't have a coherent model of the world](https://www.lesswrong.com/posts/wkws2WgraeN8AYJjv/llms-don-t-have-a-coherent-model-of-the-world-what-it-means) &nbsp; Interesting...
+ [Human Immortality using LLMs](https://danielmiessler.com/p/human-immortality-using-llms) &nbsp; Is that word warranted? ...
+ [LLM Programs](https://mpost.io/llm-programs-the-new-path-to-fine-tuning-neural-models-in-complex-situations/) &nbsp; An overview article
+ [Large language model programs](https://arxiv.org/abs/2305.05364) &nbsp; An Arxiv article
