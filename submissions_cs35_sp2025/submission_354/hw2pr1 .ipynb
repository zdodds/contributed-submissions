{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### week2 ~ APIs !\n",
    "\n",
    "<b>that is, _the-web-as-your-filesystem_ ...</b>  &nbsp;&nbsp; (hw2pr1.ipynb)\n",
    "\n",
    "[the google doc with hw2's details](https://docs.google.com/document/d/1z4HwpUL1-ImGX3j-6bddyZAfdv2SkRQHRNhF5Cu3Fkk/edit?tab=t.0)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# computing-styling trick of the day     (or, of the minute...)\n",
    "#\n",
    "# The setting for word-wrapping on the output is\n",
    "#     \"notebook.output.wordWrap\": true,   (in your settings.json file or from Code ... Settings ...) \n",
    "\n",
    "print( list(range(100)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see if you already have the requests library..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# see if we have the requests library...\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'requests'"
     ]
    }
   ],
   "source": [
    "#\n",
    "# see if we have the requests library...\n",
    "#\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl (196 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 idna-3.10 requests-2.32.3 urllib3-2.3.0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# If you _don't_ have the requests library, let's install it!\n",
    "#\n",
    "\n",
    "# for me, it worked to uncomment and run this command, here in this cell:\n",
    "!pip3 install requests\n",
    "\n",
    "# an alternative is to run, in a terminal, the command would be \n",
    "#  pip3 install requests  OR    pip install requests      (the ! is needed only if inside Python)\n",
    "\n",
    "# It's very system-dependent how much you have to \"restart\" in order to use\n",
    "# the new library (the notebook, VSCode, the Jupyter extension, etc.)\n",
    "\n",
    "# Troubles?  Let us know!  We'll work on it with you..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# hopefully, this now works! (if so, running will succeed silently)\n",
    "#\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# let's try it on a simple webpage\n",
    "#\n",
    "\n",
    "#\n",
    "# we assign the url and obtain the api-call result into result\n",
    "#    Note that result will be an object that contains many fields (not a simple string)\n",
    "# \n",
    "\n",
    "url = \"https://www.cs.hmc.edu/~dodds/demo.html\"\n",
    "result = requests.get(url)\n",
    "result    \n",
    "\n",
    "# if it succeeded, you should see <Response [200]>\n",
    "# See the list of HTTP reponse codes for the full set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Here is Wikipedia's list of all HTTP response codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "+ 100's: information\n",
    "+ 200's: success           \n",
    "+ 300's: redirects\n",
    "+ 400's + 500's: errors\n",
    "\n",
    "Perhaps familiar:  404 <br>\n",
    "Especially fun:  418\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# when exploring, you'll often obtain an unfamiliar object. \n",
    "# Here, we'll ask what type it is \n",
    "type(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to access the data inside this object, ``result`` ?\n",
    "\n",
    "One way: [Head over to the online documentation](https://requests.readthedocs.io/en/latest/api/#requests.Response)\n",
    "\n",
    "In addition, you can \"look around\" in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.cs.hmc.edu/~dodds/demo.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is one of the data members within the result\n",
    "# it \"remembers\" (keeps track of) the url requested:\n",
    "result.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close\n",
      "connection\n",
      "content\n",
      "cookies\n",
      "elapsed\n",
      "encoding\n",
      "headers\n",
      "history\n",
      "json\n",
      "links\n",
      "next\n",
      "ok\n",
      "raw\n",
      "reason\n",
      "request\n",
      "text\n",
      "url\n"
     ]
    }
   ],
   "source": [
    "# We can print all of the data members in an object with dir\n",
    "# Since dir returns a list, we will grab that list and loop over it:\n",
    "all_fields = dir(result)\n",
    "\n",
    "for field in all_fields:\n",
    "    if \"_\" not in field: \n",
    "        print(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result.url         is https://www.cs.hmc.edu/~dodds/demo.html\n",
      "result.raw         is <urllib3.response.HTTPResponse object at 0x10a6ace80>\n",
      "result.encoding    is ISO-8859-1\n",
      "result.status_code is 200\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Let's try printing a few of those fields (data members): \n",
    "print(f\"result.url         is {result.url}\")  # the original url\n",
    "print(f\"result.raw         is {result.raw}\")  # another object!\n",
    "print(f\"result.encoding    is {result.encoding}\")  # utf-8 is very common\n",
    "print(f\"result.status_code is {result.status_code}\")  # 200 is success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "  <head>\n",
      "    <title>My streamlined website</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1> Welcome! </h1>\n",
      "    <h2> The best numbers </h2>\n",
      "\n",
      "    <div id=\"numberlist\">\n",
      "      <ol>\n",
      "\t<li class=\"number\"> 35 </li>\n",
      "\t<li class=\"number\"> 42 </li>\n",
      "\t<li class=\"number\"> <a href=\"https://en.wikipedia.org/wiki/Rayo%27s_number\">Rayo's number</a> </li>\n",
      "      </ol>\n",
      "    </div>\n",
      "\n",
      "    <img src=\"./spam.jpg\" height=\"84px\">\n",
      "    <br><br>\n",
      "\n",
      "    <h2> The <s>only</s> best snacks </h2>\n",
      "\n",
      "    <div id=\"snacklist\">\n",
      "      <ul>\n",
      "\t<li class=\"snack\"> Poptarts </li>\n",
      "\t<li class=\"snack\"> Chocolate </li>\n",
      "\t<li class=\"snack\"> Coffee </li>\n",
      "      </ul>\n",
      "    </div>\n",
      "\n",
      "<!--    <a href=\"./demo_cat.html\">Aliens <3 cats!</a>  -->\n",
      "\n",
      "    <img src=\"./alien.png\" height=\"101px\">\n",
      "\n",
      "  </body>\n",
      "</html>\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In this case, the result is a text file (HTML) Let's see it!\n",
    "contents = result.text\n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yay!  \n",
    "# This shows that you are able to \"scrape\" an arbitrary HTML page... \n",
    "\n",
    "# Now, we're off to more _structured_ data-gathering..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traversing the world - and web - <i>without a browser</i>.   \n",
    "\n",
    "<b>Using the ISS APIs</b> \n",
    "\n",
    "+ Here, you'll make some calls using `requests` to, first, the International Space Station API \n",
    "+ and, then, the US Geological Survey's earthquake API\n",
    "+ \"API\" is short for \"Application Programming Interface\" \n",
    "  + Admittedly, this is not a very informative name:\n",
    "  + The API is the set of services, which are functions and/or urls, provided by some software or site"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it with the International Space Station api at [http://api.open-notify.org/iss-now.json](http://api.open-notify.org/iss-now.json)\n",
    "+ [This page has documentation on the ISS API](http://open-notify.org/Open-Notify-API/ISS-Location-Now/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# we assign the url and obtain the api-call result into result\n",
    "#    Note that result will be an object that contains many fields (not a simple string)\n",
    "# \n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://api.open-notify.org/iss-now.json\"   # this is sometimes called an \"endpoint\" ...\n",
    "result = requests.get(url)\n",
    "result    \n",
    "\n",
    "# if it succeeds, you should see <Response [200]>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result.url         is http://api.open-notify.org/iss-now.json\n",
      "result.raw         is <urllib3.response.HTTPResponse object at 0x1108bf070>\n",
      "result.encoding    is utf-8\n",
      "result.status_code is 200\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Let's try printing those shorter fields from before:\n",
    "print(f\"result.url         is {result.url}\")  # the original url\n",
    "print(f\"result.raw         is {result.raw}\")  # another object!\n",
    "print(f\"result.encoding    is {result.encoding}\")  # utf-8 is very common\n",
    "print(f\"result.status_code is {result.status_code}\")  # 200 is success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'success', 'timestamp': 1739439871, 'iss_position': {'longitude': '19.3594', 'latitude': '50.0339'}}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# In this case, we know the result is a JSON file, and we can obtain it that way:\n",
    "json_contents = result.json()\n",
    "print(json_contents)\n",
    "\n",
    "# Remember:  json_contents will be a _dictionary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Let's re-remind ourselves how dictionaries work:\n",
    "\n",
    "json_contents['message']       # Challenge:  could we access the other components? What _types_ are they?!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['message', 'timestamp', 'iss_position']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# In Python, we can use the resulting dictionary... let's see its keys:\n",
    "print(list(json_contents.keys()))  \n",
    "\n",
    "# Also, watch out for string vs. numeric types, e.g., for latitude and longitude.\n",
    "# At heart, _all_ web data are strings... .\n",
    "\n",
    "# These experiments will be helpful for problem 1, below :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"Coral\"><b>Task 0a</b></font>  &nbsp;&nbsp; From here, \n",
    "+ extract the lat and CS35_Participant_2 of the ISS from ``json_contents``  (dictinoary practice!)\n",
    "+ copy the ``haversine`` function from the assignment\n",
    "+ find the lat/CS35_Participant_2 of Claremont (or grab it from the hw page! 😊 )\n",
    "+ combine these to find out how far, in miles, the ISS is from Claremont  \n",
    "+ <font size=\"-2\">you could _imagine_ writing a function to do all this (no need to - we'll do it with earthquakes!)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON\n",
    "\n",
    "####  Let's make a brief JSON visit in Python\n",
    "\n",
    "The library ``json`` allows us to create and read arbitrary JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'value', 'fave': 42, 'list': [5, 6, 7, {'mascot': 'Aliiien'}]}\n"
     ]
    }
   ],
   "source": [
    "# JSON is a javascript dictionary format -- almost the same as a Python dictionary:\n",
    "data = { 'key':'value',  'fave':42,  'list':[5,6,7,{'mascot':'Aliiien'}] }\n",
    "print(data)\n",
    "\n",
    "# we can write in JSON format to a local file, named small42.json:\n",
    "import json \n",
    "\n",
    "with open(\"small.json\", \"w\") as f:\n",
    "    json.dump( data, f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dictionary = {'key': 'value', 'fave': 42, 'list': [5, 6, 7, {'mascot': 'Aliiien'}]}\n"
     ]
    }
   ],
   "source": [
    "# We can also read from a json file\n",
    "# The resulting data will be a _dictionary_:\n",
    "\n",
    "with open(\"small.json\", \"r\") as f:\n",
    "    dictionary = json.load( f )\n",
    "\n",
    "print(f\"the {dictionary = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['key', 'fave', 'list']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's access this dictionary -- first, the keys:\n",
    "list(dictionary.keys())   # How do we get 'Aliiien' from newdata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aliiien'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task: use the dictionary to obtain (a) 'value' , (b) 42 , (c) 'Aliiien'  [tricky!]\n",
    "\n",
    "# remember that there are two ways to get the value from a key:\n",
    "# way 1:  dictionary['key']            # errors if 'key' isn't present\n",
    "# way 2:  dictionary.get('key')        # returns None if 'key' isn't present\n",
    "\n",
    "#a\n",
    "dictionary['key']\n",
    "\n",
    "#b\n",
    "dictionary['fave']\n",
    "\n",
    "#c\n",
    "dictionary[\"list\"][-1][\"mascot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time this will be done for us by the ``requests`` library. So, we will simply receive the dictionary of data sent.\n",
    "\n",
    "Then, the trick is to \"extract\" the data fragments we want. (Sometimes it feels like forensics - or archaeology!) Try excavating items one **layer** at a time..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remember: &nbsp; <i>not</i> every url returns json data...\n",
    "+ The url [https://www.cs.hmc.edu/~dodds/demo.html](https://www.cs.hmc.edu/~dodds/demo.html) returns a plain-text file with _markup_ text\n",
    "+ that is to say, with HTML tags, such as `<title>Title</title>` to designate the components of its content\n",
    "+ HTML stands for _hypertext markup language_   \n",
    "+ Often anything with tags similar to `<b>be bold!</b>` is called \"markup.\" \n",
    "\n",
    "Let's try our 5C homepages: they're HTML, not JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "\n",
    "# here, we will obtain plain-text results from a request\n",
    "url = \"https://www.cs.hmc.edu/~dodds/demo.html\"  # try it + source\n",
    "# url = \"https://www.scrippscollege.edu/\"          # another possible site...\n",
    "# url = \"https://www.pitzer.edu/\"                  # another possible site...\n",
    "# url = \"https://www.cmc.edu/\"                     # and another!\n",
    "# url = \"https://www.cgu.edu/\"\n",
    "result = requests.get(url)        \n",
    "print(f\"result is {result}\")        # hopefully it's 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(text) is 744\n",
      "\n",
      "The first 242 characters are\n",
      "\n",
      "<html>\n",
      "  <head>\n",
      "    <title>My streamlined website</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1> Welcome! </h1>\n",
      "    <h2> The best numbers </h2>\n",
      "\n",
      "    <div id=\"numberlist\">\n",
      "      <ol>\n",
      "\t<li class=\"number\"> 35 </li>\n",
      "\t<li class=\"number\"> 42 </li>\n",
      "\t<li class=\n"
     ]
    }
   ],
   "source": [
    "# if the request was successful, the Response will be [200]. \n",
    "# Then, we can grab the text - or json - from the site:\n",
    "\n",
    "text = result.text                  # provides the HTML page as a large string...\n",
    "print(f\"len(text) is {len(text)}\")  # let's see how large the HTML page is... \n",
    "\n",
    "print(\"\\nThe first 242 characters are\\n\")\n",
    "print(text[:242])                  # we'll print the first few characters...  \n",
    "\n",
    "# change this to text[:] to see the whole document...\n",
    "# Notice that we can run many different analyses without having to re-call/re-scrape the page (this is good!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declined requests!\n",
    "\n",
    "Caution: <i>See this week's reading!</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For now let's focus on API calls providing JSON \n",
    "+ We're reading-aligned, as we should be!\n",
    "+ The open-ended problem (the finale in this notebook) offers the _option_ of scraping raw html -- up to you...\n",
    "\n",
    "<br>\n",
    "\n",
    "<b>Let's try another ISS \"endpoint\" ~ one with all of the <i>people</i> in space.</b>\n",
    "\n",
    "It's at this url:  [http://api.open-notify.org/astros.json](http://api.open-notify.org/astros.json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# we assign the url and use requests.get to obtain the result into result_astro\n",
    "#\n",
    "#    Remember, result_astro will be an object that contains many fields (not a simple string)\n",
    "# \n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://api.open-notify.org/astros.json\"   # this is sometimes called an \"endpoint\" ...\n",
    "result_astro = requests.get(url)\n",
    "result_astro\n",
    "\n",
    "# if it succeeded, you should see <Response [200]>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': [{'craft': 'ISS', 'name': 'Oleg Kononenko'}, {'craft': 'ISS', 'name': 'Nikolai Chub'}, {'craft': 'ISS', 'name': 'Tracy Caldwell Dyson'}, {'craft': 'ISS', 'name': 'Matthew Dominick'}, {'craft': 'ISS', 'name': 'Michael Barratt'}, {'craft': 'ISS', 'name': 'Jeanette Epps'}, {'craft': 'ISS', 'name': 'Alexander Grebenkin'}, {'craft': 'ISS', 'name': 'Butch Wilmore'}, {'craft': 'ISS', 'name': 'Sunita Williams'}, {'craft': 'Tiangong', 'name': 'Li Guangsu'}, {'craft': 'Tiangong', 'name': 'Li Cong'}, {'craft': 'Tiangong', 'name': 'Ye Guangfu'}], 'number': 12, 'message': 'success'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the request succeeded, we know the result is a JSON file, and we can obtain it that way.\n",
    "# Let's call our dictionary something more specific:\n",
    "\n",
    "astronauts = result_astro.json()\n",
    "print(astronauts)\n",
    "d = astronauts     # d is shorter to type\n",
    "\n",
    "# Remember:  d and astronauts will be a _dictionary_\n",
    "\n",
    "note = \"\"\" here's yesterday's result - it _should_ be the same today!\n",
    "\n",
    "{\"people\": [{\"craft\": \"ISS\", \"name\": \"Oleg Kononenko\"}, {\"craft\": \"ISS\", \"name\": \"Nikolai Chub\"},\n",
    "{\"craft\": \"ISS\", \"name\": \"Tracy Caldwell Dyson\"}, {\"craft\": \"ISS\", \"name\": \"Matthew Dominick\"},\n",
    "{\"craft\": \"ISS\", \"name\": \"Michael Barratt\"}, {\"craft\": \"ISS\", \"name\": \"Jeanette Epps\"},\n",
    "{\"craft\": \"ISS\", \"name\": \"Alexander Grebenkin\"}, {\"craft\": \"ISS\", \"name\": \"Butch Wilmore\"},\n",
    "{\"craft\": \"ISS\", \"name\": \"Sunita Williams\"}, {\"craft\": \"Tiangong\", \"name\": \"Li Guangsu\"},\n",
    "{\"craft\": \"Tiangong\", \"name\": \"Li Cong\"}, {\"craft\": \"Tiangong\", \"name\": \"Ye Guangfu\"}], \"number\": 12, \"message\": \"success\"}\n",
    "\"\"\"\n",
    "\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty intricate. Let's try unpacking this - _parsing it_ - with an in-class break-out challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': [{'craft': 'ISS', 'name': 'Oleg Kononenko'},\n",
       "  {'craft': 'ISS', 'name': 'Nikolai Chub'},\n",
       "  {'craft': 'ISS', 'name': 'Tracy Caldwell Dyson'},\n",
       "  {'craft': 'ISS', 'name': 'Matthew Dominick'},\n",
       "  {'craft': 'ISS', 'name': 'Michael Barratt'},\n",
       "  {'craft': 'ISS', 'name': 'Jeanette Epps'},\n",
       "  {'craft': 'ISS', 'name': 'Alexander Grebenkin'},\n",
       "  {'craft': 'ISS', 'name': 'Butch Wilmore'},\n",
       "  {'craft': 'ISS', 'name': 'Sunita Williams'},\n",
       "  {'craft': 'Tiangong', 'name': 'Li Guangsu'},\n",
       "  {'craft': 'Tiangong', 'name': 'Li Cong'},\n",
       "  {'craft': 'Tiangong', 'name': 'Ye Guangfu'}],\n",
       " 'number': 12,\n",
       " 'message': 'success'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Cell to try out parsing d  (astronauts)\n",
    "#\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare with a whole other webservice: **earthquakes** \n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "#### Earthquake data\n",
    "\n",
    "[Here is the USGS Earthquate data API documentation](https://earthquake.usgs.gov/fdsnws/event/1/)\n",
    "\n",
    "Notice that the \"headline\" is the URL: &nbsp; This is the <i>domain</i> from which we'll access data.\n",
    "+ Underneath, there are several different <i>endpoints</i> \n",
    "+ We are going to focus on the <tt>count</tt> endpoint and the <tt>query</tt> endpoint\n",
    "+ along with their parameters\n",
    "  + the whole list of parameters is linked and available by scrolling down\n",
    "  + that said, it's easy to miss (well, at least I did! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's establish that, for these endpoints, we can make requests - by hand - in our browser!\n",
    "\n",
    "Try this link: <br><br>  [https://earthquake.usgs.gov/fdsnws/event/1/count?format=geojson&minmagnitude=5.0&starttime=2024-01-01&endtime=2024-02-01](https://earthquake.usgs.gov/fdsnws/event/1/count?format=geojson&minmagnitude=5.0&starttime=2024-01-01&endtime=2024-02-01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! Let's parse this url. Requests in which there are parameters <i><b>in the url</b></i> are called GET requests:\n",
    "+ the <b>endpoint</b> is the first part: ``https://earthquake.usgs.gov/fdsnws/event/1/count``\n",
    "   + Notice that the forward-slashes are very much like our file-system trees from last week!\n",
    "   + In fact, they usually <i>are</i> file-system trees. They're just on the <i>server</i> side, instead of our \"client\" side...\n",
    "+ the <b>parameters</b> follow the question mark: ``format=geojson&minmagnitude=5.0&starttime=2024-01-01&endtime=2024-02-01``\n",
    "   + There are four parameters here. Parameters are separated by the ampersand <tt>&amp;</tt> character.\n",
    "   + Each one is in the format <tt>name=value</tt>  Here are the four:\n",
    "   + ``format=geojson`` specifies the desired format of the returned data. ``geojson`` is JSON with geographic data.\n",
    "   + ``minmagnitude=5.0`` specifies the minimum magnitude of earthquakes to consider. 5.0 is strong, if not always catastrophic.\n",
    "   + ``starttime=2024-01-01`` specifies the earlier time-endpoint to consider. (Jan 1, 2024)\n",
    "   + ``endtime=2024-02-01`` specifies the later time-endpoint to consider. (Feb 1, 2024)\n",
    "\n",
    "My result was this:  ``{\"count\":134,\"maxAllowed\":20000}``\n",
    "+ Earthquakes are always happening -- and they do get reclassified. So, the numbers can change - even in the past.\n",
    "\n",
    "Try it, in your browser.\n",
    "\n",
    "Also, try increasing the ``minmagnitude`` -- you'll see a progression of fewer and fewer quakes. (Fortunately!) \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, try it using a short Python script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is <Response [200]>\n",
      "the full url used was\n",
      " https://earthquake.usgs.gov/fdsnws/event/1/count?format=geojson&minmagnitude=5.0&starttime=2024-01-01&endtime=2024-02-01\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Let's try the  count  endpoint, with geojson format (json with geographical data)\n",
    "#\n",
    "\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/count?format=geojson&minmagnitude=5.0&starttime=2024-01-01&endtime=2024-02-01\"\n",
    "\n",
    "result = requests.get(url)                       # a named input, params, taking the value param_d, above\n",
    "print(f\"result is {result}\")                     # hopefully, this is 200\n",
    "print(f\"the full url used was\\n {result.url}\")   # it's nice to be able to see this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it worked, we should be able to obtain the JSON. Remember, it's a dictionary. Let's use d:\n",
    "\n",
    "d = result.json()\n",
    "\n",
    "print(f\"{d =}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling parameters separately...\n",
    "\n",
    "It's awkward to include all the parameters as part of the url.\n",
    "\n",
    "It's much more common to create a <i>dictionary</i> of the parameters, and then pass that to ``requests.get``\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is <Response [200]>\n",
      "the full url used was\n",
      " https://earthquake.usgs.gov/fdsnws/event/1/count?format=geojson&starttime=2025-01-01&endtime=2025-02-01&minmagnitude=5.0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Here is the endpoint\n",
    "#\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/count\"\n",
    "\n",
    "# Let's use variables for three of the parameters:\n",
    "min_mag = 5.0               # the minimum magnitude considered a quake (min_mag)\n",
    "start_time = \"2025-01-01\"   # this is the year-month-day format of the start\n",
    "finish_time = \"2025-02-01\"  # similar for the end\n",
    "\n",
    "# we assemble a dictionary of our parameters, let's name it param_dictionary\n",
    "# there are many more parameters available. The problems below ask you to explore them...\n",
    "param_dictionary = { \"format\":\"geojson\",         # this is simply hard-coded to obtain json\n",
    "                     \"starttime\":start_time,\n",
    "                     \"endtime\":finish_time,\n",
    "                     \"minmagnitude\":min_mag,\n",
    "                     }\n",
    "\n",
    "# Here, we use requests to make the request. The parameters will be added by this API call:\n",
    "result = requests.get(url, params=param_dictionary)\n",
    "print(f\"result is {result}\")                     # hopefully, this is 200\n",
    "print(f\"the full url used was\\n {result.url}\")   # this will include the parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON returned was d = {'count': 150, 'maxAllowed': 20000}\n"
     ]
    }
   ],
   "source": [
    "# If it worked, we should be able to see the json results:\n",
    "\n",
    "d = result.json()\n",
    "print(f\"JSON returned was {d = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, it would be possible to write one or more loops and build an earthquake dataset. For example,\n",
    "+ it would be possible to loop over the ``minmagnitude`` to get a distribution of different sized quakes (or a histogram)\n",
    "+ it would be possible to loop over one of the <i>time-endpoints</i>\n",
    "+ it would be possible to loop over one of the _other parameters_ e.g.,\n",
    "  + you can specify a circle around a specific ``latitude`` and ``longitude`` with a ``maxradiuskm`` (the radius)\n",
    "  + Claremont is at ``latitude=34.0967`` and ``longitude=-117.7198`` \n",
    "\n",
    "The next two cells have an example of a Claremont-centric quake-count question and answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is <Response [200]>\n",
      "the full url used was\n",
      " https://earthquake.usgs.gov/fdsnws/event/1/count?format=geojson&starttime=2025-01-01&endtime=2025-02-01&minmagnitude=2.2&latitude=34.0967&longitude=-117.7198&maxradiuskm=300\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# How many quakes of magnitude >= 4.2 have been within 300km of Claremont \n",
    "#     + in Jan 2025\n",
    "#     + in Dec 2025\n",
    "#\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/count\"\n",
    "\n",
    "# Let's use variables for three of the parameters:\n",
    "min_mag = 2.2               # the minimum magnitude considered a quake (min_mag)\n",
    "start_time = \"2025-01-01\"   # this is the year-month-day format of the start\n",
    "finish_time = \"2025-02-01\"  # similar for the end\n",
    "# start_time = \"2024-01-01\"   # similar, but for a year-CS35_Participant_2 span...\n",
    "# finish_time = \"2025-01-01\"  # similar for the end\n",
    "radius_in_km = 300\n",
    "\n",
    "# we assemble a dictionary of our parameters, let's name it param_dictionary\n",
    "# there are many more parameters available. The problems below ask you to explore them...\n",
    "param_dictionary = { \"format\":\"geojson\",         # this is simply hard-coded to obtain json\n",
    "                     \"starttime\":start_time,\n",
    "                     \"endtime\":finish_time,\n",
    "                     \"minmagnitude\":min_mag,\n",
    "                     \"latitude\":34.0967,\n",
    "                     \"longitude\":-117.7198,\n",
    "                     \"maxradiuskm\":radius_in_km,\n",
    "                     }\n",
    "\n",
    "# Here, we use requests to make the request. The parameters will be added by this API call:\n",
    "result = requests.get(url, params=param_dictionary)\n",
    "print(f\"result is {result}\")                     # hopefully, this is 200\n",
    "print(f\"the full url used was\\n {result.url}\")   # this will include the parameters!\n",
    "\n",
    "# We'll extract the final result in another cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quake_count = {'count': 70, 'maxAllowed': 20000}\n"
     ]
    }
   ],
   "source": [
    "# Let's finish up here:\n",
    "quake_count = result.json()\n",
    "print(f\"{quake_count = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"Coral\"><b>Try this, task \"0b\"</b></font>  &nbsp;&nbsp; \n",
    "+ Would you expect more or fewer quakes if a minimum magnitude of 2.2 were used?\n",
    "    \n",
    "    One would expect more quakes as lowering the minimum magnitudes means more smaller earthquakes (more frequent than stronger ones).\n",
    "+ Try the above cells again for a minimum magnitude of 2.2 -- if that the difference you'd expect?\n",
    "    \n",
    "    Higher count of quakes. Expected result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"DodgerBlue\"><b>Quake-counting Results:</b></font> \n",
    "\n",
    "\n",
    "\n",
    "#### Number of Claremont-centric quakes\n",
    "  + <u>Overall</u> The API calls to the USGS showed that, within 300km of Claremont, there were\n",
    "    + 1 quake of magnitude 4.2 or larger within 300km of Claremont in Jan '25\n",
    "    + more quakes  of magitude 2.2 or larger within 300km of Claremont in Jan '25 <br><br>\n",
    "  + <u>Reflection</u>: _This is not enough data to establish a trend. (I hope!)_ That said, for the hw, you should include a **loop** over at least 10 values, as well as a text-formatted set of values. (It's ok for the output values to be in the computational cell(s), not the markdown cell. The markdown is really for reflection on results than reporting of results.) <br><br>\n",
    "  + <u>Opportunities</u>: In fact, there are lots of values over which the USGS API allows to vary. For example,  minmagnitude (or maxmagnitude), radius, location (lat/CS35_Participant_2), months (or other time-measurements) - and others. In addition, there is the chance to look at the details of each quake using the ``query`` endpoint. <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping over API calls to gather data will be one of the hw problems.\n",
    "\n",
    "<hr>\n",
    "\n",
    "#### The ``query`` endpoint\n",
    "\n",
    "Let's see, too, that it's possible to obtain, not only a <i>count</i>, but also a <b>\"full report\"</b> of all of the earthquakes.\n",
    "\n",
    "To do so, the only change needed is from the endpoint ``count`` to the endpoint ``query``\n",
    "\n",
    "First, try it \"by hand\" -- by opening this url in your browser:\n",
    "\n",
    "[https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&minmagnitude=6.8&starttime=2024-01-01&endtime=2024-02-01](https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&minmagnitude=6.8&starttime=2024-01-01&endtime=2024-02-01)\n",
    "\n",
    "Take a look -- there is a lot more data!  \n",
    "\n",
    "Next, let's try it programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is <Response [200]>\n",
      "the full url used was\n",
      " https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime=2025-01-01&endtime=2025-02-01&minmagnitude=7.4\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Here is the endpoint\n",
    "#\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "\n",
    "# Let's use variables for three of the parameters:\n",
    "min_mag = 7.4               # the minimum magnitude considered a quake (min_mag)\n",
    "start_time = \"2025-01-01\"   # this is the year-month-day format of the start\n",
    "finish_time = \"2025-02-01\"  # similar for the end\n",
    "\n",
    "# we assemble a dictionary of our parameters, let's name it param_dictionary\n",
    "# there are many more parameters available. The problems below ask you to explore them...\n",
    "param_dictionary = { \"format\":\"geojson\",         # this is simply hard-coded to obtain json\n",
    "                     \"starttime\":start_time,\n",
    "                     \"endtime\":finish_time,\n",
    "                     \"minmagnitude\":min_mag,\n",
    "                     }\n",
    "\n",
    "# Here, we use requests to make the request. The parameters will be added by this API call:\n",
    "result = requests.get(url, params=param_dictionary)\n",
    "print(f\"result is {result}\")                     # hopefully, this is 200\n",
    "print(f\"the full url used was\\n {result.url}\")   # this will include the parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON returned was d = {'type': 'FeatureCollection', 'metadata': {'generated': 1739440797000, 'url': 'https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime=2025-01-01&endtime=2025-02-01&minmagnitude=7.4', 'title': 'USGS Earthquakes', 'status': 200, 'api': '1.14.1', 'count': 0}, 'features': []}\n"
     ]
    }
   ],
   "source": [
    "# If it worked, we should be able to see the json results:\n",
    "\n",
    "d = result.json()\n",
    "print(f\"JSON returned was {d = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"type\": \"FeatureCollection\", \"metadata\": {\"generated\": 1739440712000, \"url\": \"https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime=2025-01-01&endtime=2025-02-01&minmagnitude=6.9\", \"title\": \"USGS Earthquakes\", \"status\": 200, \"api\": \"1.14.1\", \"count\": 1}, \"features\": [{\"type\": \"Feature\", \"properties\": {\"mag\": 7.1, \"place\": \"2025 Southern Tibetan Plateau Earthquake\", \"time\": 1736211916716, \"updated\": 1738121358298, \"tz\": null, \"url\": \"https://earthquake.usgs.gov/earthquakes/eventpage/us6000pi9w\", \"detail\": \"https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=us6000pi9w&format=geojson\", \"felt\": 864, \"cdi\": 9.1, \"mmi\": 9.212, \"alert\": \"red\", \"status\": \"reviewed\", \"tsunami\": 0, \"sig\": 2786, \"net\": \"us\", \"code\": \"6000pi9w\", \"ids\": \",us6000pi9w,usauto6000pi9w,pt25007000,\", \"sources\": \",us,usauto,pt,\", \"types\": \",dyfi,earthquake-name,finite-fault,general-text,ground-failure,impact-text,internal-moment-tensor,internal-origin,losspager,moment-tensor,origin,phase-data,shakemap,\", \"nst\": 315, \"dmin\": 3.47, \"rms\": 0.57, \"gap\": 17, \"magType\": \"mww\", \"type\": \"earthquake\", \"title\": \"M 7.1 - 2025 Southern Tibetan Plateau Earthquake\"}, \"geometry\": {\"type\": \"Point\", \"coordinates\": [87.375, 28.5733, 10]}, \"id\": \"us6000pi9w\"}]}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# That's hard to read!\n",
    "# Let's pretty-print it with the json library\n",
    "#       Also, this version can be pasted into online formatters, e.g., https://jsonformatter.org/\n",
    "\n",
    "import json \n",
    "nice_string = json.dumps(d)   # this outputs a \"nicely formatted string\" using double quotes\n",
    "print(nice_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but, we can do better! \n",
    "\n",
    "the \"dump string\" function, json.dumps, can output the formatted version, too...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"type\": \"FeatureCollection\",\n",
      "    \"metadata\": {\n",
      "        \"generated\": 1739440712000,\n",
      "        \"url\": \"https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime=2025-01-01&endtime=2025-02-01&minmagnitude=6.9\",\n",
      "        \"title\": \"USGS Earthquakes\",\n",
      "        \"status\": 200,\n",
      "        \"api\": \"1.14.1\",\n",
      "        \"count\": 1\n",
      "    },\n",
      "    \"features\": [\n",
      "        {\n",
      "            \"type\": \"Feature\",\n",
      "            \"properties\": {\n",
      "                \"mag\": 7.1,\n",
      "                \"place\": \"2025 Southern Tibetan Plateau Earthquake\",\n",
      "                \"time\": 1736211916716,\n",
      "                \"updated\": 1738121358298,\n",
      "                \"tz\": null,\n",
      "                \"url\": \"https://earthquake.usgs.gov/earthquakes/eventpage/us6000pi9w\",\n",
      "                \"detail\": \"https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=us6000pi9w&format=geojson\",\n",
      "                \"felt\": 864,\n",
      "                \"cdi\": 9.1,\n",
      "                \"mmi\": 9.212,\n",
      "                \"alert\": \"red\",\n",
      "                \"status\": \"reviewed\",\n",
      "                \"tsunami\": 0,\n",
      "                \"sig\": 2786,\n",
      "                \"net\": \"us\",\n",
      "                \"code\": \"6000pi9w\",\n",
      "                \"ids\": \",us6000pi9w,usauto6000pi9w,pt25007000,\",\n",
      "                \"sources\": \",us,usauto,pt,\",\n",
      "                \"types\": \",dyfi,earthquake-name,finite-fault,general-text,ground-failure,impact-text,internal-moment-tensor,internal-origin,losspager,moment-tensor,origin,phase-data,shakemap,\",\n",
      "                \"nst\": 315,\n",
      "                \"dmin\": 3.47,\n",
      "                \"rms\": 0.57,\n",
      "                \"gap\": 17,\n",
      "                \"magType\": \"mww\",\n",
      "                \"type\": \"earthquake\",\n",
      "                \"title\": \"M 7.1 - 2025 Southern Tibetan Plateau Earthquake\"\n",
      "            },\n",
      "            \"geometry\": {\n",
      "                \"type\": \"Point\",\n",
      "                \"coordinates\": [\n",
      "                    87.375,\n",
      "                    28.5733,\n",
      "                    10\n",
      "                ]\n",
      "            },\n",
      "            \"id\": \"us6000pi9w\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "nicer_string = json.dumps(d, indent=4)   # We can specify the indentation. \n",
    "print(nicer_string)                      # It's another tree structure... !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"Coral\"><b>Try this, also for Task 0b</b></font>  &nbsp;&nbsp; \n",
    "+ Look through the response to find where and when the largest eathquake was, in the previous year\n",
    "\n",
    "    Noto Peninsula, Japan on January 2024.\n",
    "+ What was its magnitude?\n",
    "\n",
    "    7.5\n",
    "+ (optional) Do you see a way that - just by making small changes and re-running - you could find the second-biggest quake of '24?  Perhaps try it...  🦔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "#### Launching into hw2's challenges:\n",
    "+ <font color=\"Coral\"><b>Tasks1-2</b></font> &nbsp;&nbsp; ISS challenges:\n",
    "  + ``ISS_now()`` which will find and return the ISS's lat/CS35_Participant_2 (as floats)\n",
    "    + use the earlier examples as a starting point...\n",
    "  + ``ISS_distance()`` which will return the distance of the ISS from a city of your choice (a constant city, not a variable). It can be Claremont, but doesn't have to be. This will require using the <i>haversine</i> distance for global lat/CS35_Participant_2 coordinates...\n",
    "+ <font color=\"Coral\"><b>Tasks3-4</b></font> &nbsp;&nbsp; Earthquake challenges:\n",
    "  + ``Quake_loop()`` which will loop over a parameter of your choice, print a formatted list of quake-count data, and return that list\n",
    "  + ``Quake_compare(place1, place2)`` which will ask - and answer - a comparative question about \"quakiness\" for two different places, using the quake data... \n",
    "    + Here, the goal is to define which of the two places is \"quakiest.\"\n",
    "    + Notice that the definition of \"quakiest\" is up to you...\n",
    "    + The inputs, place1 and place2, can be lat/CS35_Participant_2 pairs - or strings, which then get looked up...\n",
    "\n",
    "<br>\n",
    "\n",
    "#### <font color=\"Coral\"><b>Task5</b></font> &nbsp;&nbsp; Open-ended, two-hop challenge\n",
    "\n",
    "Then, you'll choose or create an open-ended API task -- or create a variant of your own design from at least two APIs - or \"scrapes\" - of your choice.\n",
    "+ The key constraint is to be sure you meaningfully use the  <font color=\"DodgerBlue\">result</font>  from the first API call in order to customize the request of the second API call.\n",
    "+ Then, with the result of that second API call, interpret the data obtained to make a final \"statement\" -- which can be anywhere amid serious, silly, surreal -- that combines the two API insights.\n",
    "+ See below for a far-fetched superbowl-themed idea...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result = {'message': 'success', 'timestamp': 1739441165, 'iss_position': {'longitude': '88.4164', 'latitude': '-4.5425'}}\n",
      "ISS Current Location: Latitude -4.5425, Longitude 88.4164\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# hw2: ISS tasks 1 and 2 ...\n",
    "# \n",
    "# Two functions:  ISS_now(), ISS_distance()\n",
    "\n",
    "#\n",
    "# Use the ISS examples above to write a function, named \n",
    "#     \n",
    "#      ISS_now()\n",
    "#\n",
    "# that uses requests to return the current latitude and longitude -- as floating-point values -- right now.\n",
    "# Be sure to test it! \n",
    "\n",
    "\n",
    "url = \"http://api.open-notify.org/iss-now.json\"\n",
    "\n",
    "result = requests.get(url)\n",
    "\n",
    "iss_data = result.json()\n",
    "print(f\"Result = {iss_data}\")\n",
    "\n",
    "\n",
    "latitude = iss_data['iss_position']['latitude']\n",
    "longitude = iss_data['iss_position']['longitude']\n",
    "print(f\"ISS Current Location: Latitude {latitude}, Longitude {longitude}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to create some new cells around this area to write and test ``ISS_now()`` ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to create some new cells around this area to write and test ``ISS_distance()`` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Open-ended possibility:  \n",
    "#    (a) create a new function ISS_distance(place) that takes in a place name\n",
    "#    (b) find a service by which you can look up the lat + CS35_Participant_2 using the place name\n",
    "#         (b*)  I'm not sure how to do this - it's exploratory! \n",
    "#    (c) then, continue with the previous computation to find the ISS distance! :) \n",
    "#\n",
    "\n",
    "# The final problem of this hw2 is to take on _ONE_ open-ended possibility. \n",
    "#     (This ISS-themed one is only the first possibility.)\n",
    "#     Others, below, involve earthquakes, or your own choice of API exploration..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USGS Challenges\n",
    "\n",
    "Tasks 3 and 4 use the earthquake API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthquakes from 2024-01-01 - 2024-02-01: 4\n",
      "Earthquakes from 2024-02-01 - 2024-03-01: 5\n",
      "Earthquakes from 2024-03-01 - 2024-04-01: 0\n",
      "Earthquakes from 2024-04-01 - 2024-05-01: 1\n",
      "Earthquakes from 2024-05-01 - 2024-06-01: 9\n",
      "Earthquakes from 2024-06-01 - 2024-07-01: 3\n",
      "Earthquakes from 2024-07-01 - 2024-08-01: 1\n",
      "Earthquakes from 2024-08-01 - 2024-09-01: 6\n",
      "Earthquakes from 2024-09-01 - 2024-10-01: 1\n",
      "Earthquakes from 2024-10-01 - 2024-11-01: 3\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# hw2: USGS Tasks 3 and 4 ...\n",
    "# \n",
    "# Two functions:  Quake_loop(), Quake_compare(place1, place2)\n",
    "\n",
    "#\n",
    "# Use the USGS (earthquake) examples above to write a function, named \n",
    "#     \n",
    "#      Quake_loop()\n",
    "#\n",
    "# that uses requests within a loop of your own design in order to\n",
    "#   + obtain at least 10 distinct, comparable data elements (counts are encouraged; other items ok)\n",
    "#   + see the assignment page for an example where the looping iterates over the _month_\n",
    "#\n",
    "#   + choose your favorite parameter(s) to vary, e.g., magnitude, time, radius, location, etc.\n",
    "#   + it should collect all of those data elements into a list\n",
    "#   + and render the list in a neatly formatted chart (f-strings welcome; not required)\n",
    "#\n",
    "#   + in addition, include a overall reflection on the results, as well as a comment on additional effort\n",
    "#     that could expand your results (you need not run it), and any concerns or caveats about the data...\n",
    "#   + feel free to copy-paste-edit the markdown \"reflection-template,\" above  \n",
    "\n",
    "\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/count\"\n",
    "\n",
    "\n",
    "min_mag = 4.0 \n",
    "latitude = 34.0967\n",
    "longitude = -117\n",
    "radius_km = 350\n",
    "\n",
    "\n",
    "for month in range(1, 11):\n",
    "    start_time = f\"2024-{month:02d}-01\"\n",
    "    end_time = f\"2024-{month+1:02d}-01\" if month < 12 else \"2025-01-01\"\n",
    "\n",
    "\n",
    "    param_dictionary = {\n",
    "        \"format\": \"geojson\",\n",
    "        \"starttime\": start_time,\n",
    "        \"endtime\": end_time,\n",
    "        \"minmagnitude\": min_mag,\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"maxradiuskm\": radius_km,\n",
    "    }\n",
    "\n",
    "\n",
    "    result = requests.get(url, params=param_dictionary)\n",
    "    data = result.json()\n",
    "\n",
    " \n",
    "    print(f\"Earthquakes from {start_time} - {end_time}: {data['count']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to create some new cells around this area to write and test ``Quake_loop()`` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthquake count for (34.0967, -117.7198): 28\n",
      "Earthquake count for (37.7749, -122.4194): 9\n",
      "(34.0967, -117.7198) is quakier than (37.7749, -122.4194).\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Once your Quake_loop() function is working, write a new function\n",
    "#\n",
    "#       Quake_compare(place1, place2)\n",
    "#\n",
    "# where place1 should be a 2-element tuple:  (latitude1, longitude1)\n",
    "# and  place2 should be a 2-element tuple:  (latitude2, longitude2)\n",
    "#\n",
    "# and then your function should compare which of the two places is \"quakier\" (not a real word)\n",
    "# for a given time span (you choose), and a given strength-of-quakes (you choose), and\n",
    "# for a specific radius around each of the two places (you choose)\n",
    "#\n",
    "# As is clear, there is lots of freedom to design a \"comparison of quakiness\" -- wonderful!\n",
    "# Feel free to start somewhere, and tune the results.\n",
    "#\n",
    "# Your function should print the results it finds (in this case, it's not important to return\n",
    "# and specific value -- though you're encouraged (not required) to create a helper function and \n",
    "# then call it twice for the two locations! (That helper function would need a return value!)\n",
    "#\n",
    "#\n",
    "\n",
    "\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/count\"\n",
    "\n",
    "\n",
    "start_time = \"2024-01-01\"\n",
    "end_time = \"2025-01-01\"\n",
    "min_mag = 4.0 \n",
    "radius_km = 300 \n",
    "\n",
    "\n",
    "place1 = (34.0967, -117.7198) \n",
    "place2 = (37.7749, -122.4194) \n",
    "\n",
    "def get_quake_count(lat, lon):\n",
    "    param_dictionary = {\n",
    "        \"format\": \"geojson\",\n",
    "        \"starttime\": start_time,\n",
    "        \"endtime\": end_time,\n",
    "        \"minmagnitude\": min_mag,\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"maxradiuskm\": radius_km\n",
    "    }\n",
    "    response = requests.get(url, params=param_dictionary)\n",
    "    return response.json()[\"count\"]\n",
    "\n",
    "count1 = get_quake_count(*place1)\n",
    "count2 = get_quake_count(*place2)\n",
    "\n",
    "\n",
    "print(f\"Earthquake count for {place1}: {count1}\")\n",
    "print(f\"Earthquake count for {place2}: {count2}\")\n",
    "\n",
    "if count1 > count2:\n",
    "    print(f\"{place1} is quakier than {place2}.\")\n",
    "else:\n",
    "    print(f\"{place2} is quakier than {place1}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to create some new cells around this area to write and test ``Quake_compare(place1, place2)`` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthquake count for (34.0967, -117.7198): 28\n",
      "Earthquake count for (37.7749, -122.4194): 24\n",
      "(34.0967, -117.7198) is quakier than (37.7749, -122.4194).\n"
     ]
    }
   ],
   "source": [
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/count\"\n",
    "\n",
    "\n",
    "start_time = \"2024-01-01\"\n",
    "end_time = \"2025-01-01\"\n",
    "min_mag = 4.0 \n",
    "radius_km = 300 \n",
    "\n",
    "\n",
    "claremont = (34.0967, -117.7198) \n",
    "arcadia = (34.1397, -118.0353) \n",
    "\n",
    "def get_quake_count(lat, lon):\n",
    "    param_dictionary = {\n",
    "        \"format\": \"geojson\",\n",
    "        \"starttime\": start_time,\n",
    "        \"endtime\": end_time,\n",
    "        \"minmagnitude\": min_mag,\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"maxradiuskm\": radius_km\n",
    "    }\n",
    "    response = requests.get(url, params=param_dictionary)\n",
    "    return response.json()[\"count\"]\n",
    "\n",
    "count1 = get_quake_count(*claremont)\n",
    "count2 = get_quake_count(*arcadia)\n",
    "\n",
    "\n",
    "print(f\"Earthquake count for {place1}: {count1}\")\n",
    "print(f\"Earthquake count for {place2}: {count2}\")\n",
    "\n",
    "if count1 > count2:\n",
    "    print(f\"{place1} is quakier than {place2}.\")\n",
    "else:\n",
    "    print(f\"{place2} is quakier than {place1}.\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final API challenge:  an open-ended, two-hop API task...\n",
    "\n",
    "<font color=\"Coral\">Key constraint: _Use two hops!_</font>  &nbsp;&nbsp; Be sure to dome something that uses two separate API calls, in which the results of the first affect the second - culminating in an aggregate, overall result.\n",
    "\n",
    "Possibilities: \n",
    "  + You should use at least one other API. (See the hw2 page for links to many.)\n",
    "      + The [Poke API](https://pokeapi.co/)  or [one of these](https://medium.com/codex/15-fun-and-interesting-apis-to-use-for-your-next-coding-project-in-2022-86a4ff3a2742) or [one of the many, many more!](https://github.com/public-apis/public-apis)\n",
    "  + That said, <u><b>one</b></u> of the two can be ISS or USGS, as you used above.\n",
    "\n",
    "\n",
    "\n",
    "<font size=\"-2\">PS. My example of this is in ``superbowl_prediction.ipynb`` with the starter files. It used to be here, but it was too clutter-y... .</font>\n",
    "\n",
    "<br><hr><br>\n",
    "\n",
    "Big-picture, an important part of using API calls is gathering a _specific piece_ of data from an otherwise too-large ocean of raw material. That element then allows you to express a natural _next_ specific question, obtain its relevant data, and continue to build from there, with each round-trip branching into additional (possible) questions... .\n",
    "\n",
    "<br>\n",
    "\n",
    "Good luck API'ing!!\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 ISS Current Location: Latitude -13.4369, Longitude -116.3955\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Cells for your own API experimentations + results!\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "iss_url = \"http://api.open-notify.org/iss-now.json\"\n",
    "iss_response = requests.get(iss_url)\n",
    "iss_data = iss_response.json()\n",
    "\n",
    "\n",
    "iss_latitude = iss_data['iss_position']['latitude']\n",
    "iss_longitude = iss_data['iss_position']['longitude']\n",
    "print(f\"🚀 ISS Current Location: Latitude {iss_latitude}, Longitude {iss_longitude}\")\n",
    "\n",
    "\n",
    "nasa_api_key = \"262wN439DCsNcRlR2yCATn88KeHeIO1LkyD45SwJ\" #https://api.nasa.gov/\n",
    "\n",
    "\n",
    "date_to_try = \"2022-11-18\"  \n",
    "\n",
    "\n",
    "nasa_url = f\"https://api.nasa.gov/planetary/earth/imagery?lon={iss_longitude}&lat={iss_latitude}&date={date_to_try}&dim=0.1&api_key={nasa_api_key}\"\n",
    "\n",
    "\n",
    "nasa_response = requests.get(nasa_url)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
