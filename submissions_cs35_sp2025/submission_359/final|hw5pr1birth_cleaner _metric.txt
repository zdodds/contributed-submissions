#
# hw5pr1births_cleaner:  birth classification by month + day    (above/below median: 190942)
#


# libraries!
import numpy as np      # numpy is python's "array" library
import pandas as pd     # pandas is python's "data" library ("dataframe" == spreadsheet)


#
# *** suggestion ***  
# 
#       +++ copy-paste-and-alter from the iris-cleaning notebook to here +++
#
# this approach has the advantage of more deeply "digesting" the iris workflow...
#      ... altering the parts that don't transfer, and taking the parts that do!
#

# eventually you'll get rid of the _births_ column, that can be here or in the modeling notebook


# read in our spreadsheet (csv)
filename = 'births.csv'
df = pd.read_csv(filename)        # encoding="utf-8" et al.
print(f"{filename} : file read into a pandas dataframe.")


#
# a dataframe is a "spreadsheet in python"   (note that extra column at the right!)
#
# let's view it:



# let's look at the dataframe's "info":
df.info()


# we can drop a series of data (a row or a column)
# the dimensions each have a numeric value, row~0, col~1, but let's use readable names we define:
row = 0        
column = 1     

# we are dropping this final column - it was just a citation...
df_clean1 = df.drop('from http://chmullig.com/2012/06/births-by-day-of-year/', 
axis=column)

# df_clean1 is a new dataframe, without the unwanted columns!


#
# let's get rid of all non-real dates -- should have 366 rows, not 372!
#

df_clean2 = df_clean1[ df_clean1['births'] > 40000 ]


#
# let's re-look at our cleaned-up dataframe's info:
#
df_clean2.info()   



#
# let's keep our column names in variables, for reference
#
columns = df_clean2.columns            # "list" of columns
print(f"columns is {columns}")  
  # it's a "pandas" list, called an index
  # use it just as a python list of strings:
print(f"columns[0] is {columns[0]}\n")

# let's create a dictionary to look up an index from its name:
col_index = {}
for i, name in enumerate(columns):
    col_index[name] = i  # using the name (as key), look up the value (i)
print(f"col_index is {col_index}")
print(f"col_index[ 'month'] is {col_index[ 'month' ]}")


# all of scikit-learn's ml routines need numbers, not strings
#   ... even for categories/classifications (like species!)
#   so, we will convert above/below median to numbers

#
# first, let's map above/below median to numeric values:

maptomedian = ['below', 'above']   # int to str
median_index = {'above':1,'below':0}  # str to int

def convert_median_index(name):
    """ return the species index (a unique integer/category) """
    return median_index[name]

# let's try it out...
for name in maptomedian:
    print(f"{name} maps to {convert_median_index(name)}")


convert_median_index('above')  # try it!


#
# we can "apply" to a whole column and create a new column
#   it may give a warning, but this is ok...
#

df_clean3 = df_clean2.copy()  # copy everything and...

# add a new column, 'irisnum'
df_clean3['mediannum'] = df_clean3['above/below median'].apply(convert_median_index)

# let's see...
df_clean3


#
# let's call it df_tidy 
#
df_tidy =  df_clean3



#
# that's it!  then, and write it out to iris_cleaned.csv

# we'll construct the new filename:
old_filename_without_extension = filename[:-4]                      # remove the ".csv"

cleaned_filename = old_filename_without_extension + "_cleaned.csv"  # name-creating
print(f"cleaned_filename is {cleaned_filename}")

# now, save the dataframe names df_tidy
df_tidy.to_csv(cleaned_filename, index_label=false)  # no "index" column...


#
# let's make sure this worked, by re-reading in the data...
#

# let's re-read that file and take a look...
df_tidy_reread = pd.read_csv(cleaned_filename)   # encoding="utf-8" et al.
print(f"{cleaned_filename} : file read into a pandas dataframe.")
df_tidy_reread


