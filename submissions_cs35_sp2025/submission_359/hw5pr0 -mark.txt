<br>

### cs35 Week5: Reading and response 

_More data!_   &nbsp;&nbsp; (hw5pr0.ipynb)

In fact, can we _generate_ our own?!

<hr><br>

#### Reading for hw5...     (hw5pr0.ipynb)

This week's reading is an [Economist article](https://www.economist.com/technology-quarterly/2020/06/11/for-ai-data-are-harder-to-come-by-than-you-think) (here is a [pdf version](https://drive.google.com/file/d/1tJC3jLjk_ZNzA1UTxREJGqzZg5pg2N24/view)) on the pitfalls and promise of the data-driven era we now inhabit.  

The article takes a "data-based" view on the developments and concerns in AI. It's from about 5 years ago, and you'll notice that this is a _long_ time ago, AI-wise!

One of the more durable ideas in this article is the possibility -- and possible importance -- of ***generating*** data to improve model-training, when available data is inequitable, inflexible, or insufficient in another way. (Amazon Go, on the other hand? [Gone.](https://foodinstitute.com/focus/rise-and-stall-of-amazon-go-illustrates-limits-of-ai/))   

Using the article and your own experience, what are <font color="Coral"><b>your thoughts on artificially generating data to assist AI/ML training</b></font>?  Possible jumping-off points include 
+ (1) echo-chamber effects: &nbsp; Can generated data yield more fairness -- or only reinforce existing biases?, or 
+ (2) implementation concerns: &nbsp; What process would artificially generate the data?, or 
+ (3) a specific example you've encountered, &nbsp; where a computational system generated data, but "got things obviously wrong" (you may have experiences several of these examples!) 

In the last case, the automatically-generated data may have made the world's data-landscape worse, not better.  

Alternative and additional perspectives about artificially-generated data are more than welcome... &nbsp; .

As with each week's reading, responses should be thoughtful, but need not be CS35_Participant_2: a 4-5 sentence paragraph is wonderful.

<hr>#### Reading response

The idea of artifical data generation to assist AI/ML training is a very surprising one to me. However, I wasn't too surprised that AI generated data could improve performance of AI technology in self-driving cars. In that context, artificial generation of data could allow the self-driving technology to 'experience' and respond to many dangerous but uncommon situations. I think the use of artificial data generation is more surprising and potentially dangerous when applied to AI tasks that involve any sort of value judgement, such as the AI used to identify suitable job candidates. There, I could definitely see that using AI to generate additional data off of a pre-existing data set would simply reinforce existing biases within the data set--I can't imagine AI generation of data creating any valuable data points in this realm. 
