{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### cs35 Week6: Reading and response \n",
    "\n",
    "_On the Uses and Misuses of Models_   &nbsp;&nbsp; (hw6pr0.ipynb)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Reading for hw6...     (hw6pr0.ipynb)\n",
    "\n",
    "This week's reading has two options:\n",
    "+ [Option 1] Georgia Meyer's review of <u>Escape from Model Land</u>, which addresses the troubles of over-trusting models -- and provides a path for balancing the skepticism and promise of models' _\"knowledge\"_  \n",
    "  + [Here is the link to the original review](https://www.lse.ac.uk/DSI/Research/Blog-posts/Book-review-Escape-from-Model-Land) &nbsp;&nbsp; and &nbsp;&nbsp; [here is a local copy](https://drive.google.com/file/d/1SCuPWPyHEQ2N5eycg48pcV6Rkg8CLzSe/view?usp=drive_link), &nbsp;&nbsp; just in case <br><br>\n",
    "+ [Option 2] Kate Harbath's short history of Cambridge Analytica, perhaps the most costly - and expensive - example of _modeling misuse_\n",
    "  + [Here is the link to the original article](https://bipartisanpolicy.org/blog/cambridge-analytica-controversy/#) &nbsp;&nbsp; and &nbsp;&nbsp; [here is a local copy](https://drive.google.com/file/d/1k0DeDBH0EBdVfApY1O205FXMDbsashzj/view?usp=drive_link), &nbsp;&nbsp; just in case <br><br>\n",
    "+ [Option 1+2] Feel free to read and respond to both (optional and ec, up to +10)\n",
    "\n",
    "\n",
    "#### The prompt(s)\n",
    "\n",
    "Using the article you choose - and your own experience - what are your thoughts on the ***trustworthiness*** of the models that modern approaches can and have created?   \n",
    "\n",
    "Possible jumping-off points include your thoughts on ...\n",
    "+ (1) the responsibility (and accountability) of the humans who **design and create** models. How should the source data affect models' scope and use?  For example, CA's models used _social media scraping_ ... <br><br>\n",
    "+ (2) the responsibility (and accountability) of the humans who **deploy and use** models. To what extent does it matter what the model is a model ***of*** ? For example, CA's models were models _of people_ ... <br><br>\n",
    "+ (3) an example you've encountered where an artificially-learned model was mis-deployed. This could be a non-artificially-learned model, for that matter! Was the responsibility for mis-deployment focused/individually-based? or was it diffuse/community-based? \n",
    "\n",
    "<br>\n",
    "\n",
    "Alternative directions on the tensions between model-trust and human-trust are more than welcome!  \n",
    "\n",
    "As with each week's reading, responses should be thoughtful, but need not be CS35_Participant_2: a 4-5 sentence paragraph is wonderful.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading response\n",
    "\n",
    "Feel free to use this cell for your response(s).\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "I think it is crucially important what a model is a model of, in terms of the level of responsibility and care which should be taken with the data by people deploying and using models. Although modeling of people's behavior for the purpose of targeted ads is very pervasive nowadays, I believe that this is a dangerous area for model developers, and much care should be taken to ensure that people are aware of the ways in which their data is being used, and who has access to it. I think in a way people can sometimes be unfazed by the idea that a model is being trained to predict their behavior and reactions, but the repercussions of the potential to slightly alter the behavior or beliefs of an individual can have large scale effects, as is exemplified with Cambridge Analytica. I think that people who build models to predict human behavior should be especially responsible when source data is provided through social media or other platforms where data can be collected technically with consent, but in practice often unbeknownst to the subjects. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ccb4bb6bd67730c9185e6c24c983362cd7b4575b595bfae100d8d91e48f4f1e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
